// This file is generated by PolyFHE
#include <cuda.h>
#include <cuda_runtime.h>
#include <chrono>
#include <iostream>
#include <numeric>
#include <vector>
#include <stdio.h>
#include "polyfhe/kernel/device_context.hpp"
#include "polyfhe/kernel/polynomial.cuh"
#include "polyfhe/kernel/ntt.hpp"
#include "polyfhe/kernel/ntt-phantom.hpp"
#include "phantom-fhe/include/phantom.h"
#include "phantom-fhe/include/uintmodmath.cuh"
// Define kernel for subgraph[0], type: Elem
__global__ void Mult_4_Mult_1_Add_2(Params *params, uint64_t *edge_Init_0_4_Mult_4_0, uint64_t *edge_Init_0_5_Mult_4_1, uint64_t *edge_Init_0_6_Mult_1_0, uint64_t *edge_Init_0_7_Mult_1_1, uint64_t *edge_Add_2_0_End_3_0){
    extern __shared__ uint64_t shared[];
    const int start_limb = 0;
    const int end_limb = 18;
    for (int idx = threadIdx.x + blockIdx.x * blockDim.x;idx < params->N * (end_limb - start_limb);idx += blockDim.x * gridDim.x){
        const int l_idx = idx / params->N + start_limb;
        const int n_idx = l_idx * params->N + idx % params->N;
        const uint64_t q = params->qVec[l_idx];
        uint64_t res;
        // Mult_4
        res = xxx_multiply_and_barrett_reduce_uint64(edge_Init_0_4_Mult_4_0[n_idx] , edge_Init_0_5_Mult_4_1[n_idx], q, params->modulus_const_ratio + l_idx * 2);
         shared[0 + threadIdx.x] = res;
        // Mult_1
        res = xxx_multiply_and_barrett_reduce_uint64(edge_Init_0_6_Mult_1_0[n_idx] , edge_Init_0_7_Mult_1_1[n_idx], q, params->modulus_const_ratio + l_idx * 2);
         shared[128 + threadIdx.x] = res;
        // Add_2
        res = shared[0 + threadIdx.x] + shared[128 + threadIdx.x];
        if (res >= q) res -= q;
        edge_Add_2_0_End_3_0[n_idx] = res;
    }
}


// Define kernel for subgraph[1], type: Elem
__global__ void Mult_5(Params *params, uint64_t *edge_Init_0_2_Mult_5_0, uint64_t *edge_Init_0_3_Mult_5_1, uint64_t *edge_Mult_5_0_End_3_10){
    const int start_limb = 0;
    const int end_limb = 18;
    for (int idx = threadIdx.x + blockIdx.x * blockDim.x;idx < params->N * (end_limb - start_limb);idx += blockDim.x * gridDim.x){
        const int l_idx = idx / params->N + start_limb;
        const int n_idx = l_idx * params->N + idx % params->N;
        const uint64_t q = params->qVec[l_idx];
        uint64_t res;
        // Mult_5
        res = xxx_multiply_and_barrett_reduce_uint64(edge_Init_0_2_Mult_5_0[n_idx] , edge_Init_0_3_Mult_5_1[n_idx], q, params->modulus_const_ratio + l_idx * 2);
         edge_Mult_5_0_End_3_10[n_idx] = res;
    }
}


// Define kernel for subgraph[2], type: ElemLimb2
__global__ void Mult_6_iNTTPhase2_7(Params *params, uint64_t *edge_Init_0_0_Mult_6_0, uint64_t *edge_Init_0_1_Mult_6_1, uint64_t *edge_Mult_6_0_End_3_11, uint64_t *edge_iNTTPhase2_7_0_iNTTPhase1_8_0){
    extern __shared__ uint64_t shared[];
    uint64_t reg[8];
    const int start_limb = 0;
    const int end_limb = 18;
    const size_t n_tower = params->N / 8;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (end_limb - start_limb) * n_tower; tid += blockDim.x * gridDim.x){
        size_t batch_idx = tid / n_tower;

        // Load data to register
        uint64_t *in = edge_Init_0_0_Mult_6_0;
        #pragma unroll
        for (int l = 0; l < 8; l++){
            reg[l] = *(in + blockIdx.x * blockDim.x * 8 + threadIdx.x * 8 + l);
        }
        __syncthreads();

        // Mult_6
        const size_t idx = blockIdx.x * blockDim.x * 8 + threadIdx.x * 8;
        #pragma unroll
        for (int l = 0; l < 8; l++){
            uint64_t res;
            res = xxx_multiply_and_barrett_reduce_uint64(edge_Init_0_0_Mult_6_0[idx + l], edge_Init_0_1_Mult_6_1[idx + l], params->qVec[batch_idx], params->modulus_const_ratio + batch_idx * 2);
            reg[l] = res;
        }
        #pragma unroll
        for (int l = 0; l < 4; l++){
            asm("st.cs.global.v2.u64 [%0], {%1, %2};" :  : "l"(edge_Mult_6_0_End_3_11 + idx + 2 * l),"l"(reg[2 * l]),"l"(reg[2 * l + 1]));
        }

        // iNTTPhase2_7
        d_poly_inwt_radix8_phase2(params, 18, 0, shared, reg, tid);

        // Store data from register
        const size_t n_group = params->n2 / 8;
        const size_t idx_base = blockIdx.x * blockDim.x * params->per_thread_ntt_size + (threadIdx.x / n_group) * n_group * params->per_thread_ntt_size + (threadIdx.x % n_group);
        uint64_t *out = edge_iNTTPhase2_7_0_iNTTPhase1_8_0;
        #pragma unroll
        for (int l = 0; l < 8; l++){
            *(out + idx_base + n_group * l) = reg[l];
        }
        __syncthreads();
    }
}


// Define kernel for subgraph[3], type: ElemLimb1
__global__ void iNTTPhase1_8_MultConst_9(Params *params, uint64_t *edge_iNTTPhase2_7_0_iNTTPhase1_8_0, uint64_t *edge_MultConst_9_0_BConv_18_0, uint64_t *edge_MultConst_9_1_BConv_17_0, uint64_t *edge_MultConst_9_2_BConv_16_0, uint64_t *edge_MultConst_9_3_BConv_15_0, uint64_t *edge_MultConst_9_4_BConv_14_0, uint64_t *edge_MultConst_9_5_BConv_13_0, uint64_t *edge_MultConst_9_6_BConv_12_0, uint64_t *edge_MultConst_9_7_BConv_11_0, uint64_t *edge_MultConst_9_8_BConv_10_0, uint64_t *partQlHatInv_mod_Ql_concat, uint64_t *partQlHatInv_mod_Ql_concat_shoup){
    extern __shared__ uint64_t shared[];
    uint64_t reg[8];
    const int start_limb = 0;
    const int end_limb = 18;
    uint64_t *in = edge_iNTTPhase2_7_0_iNTTPhase1_8_0;
    for (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i < (params->N / 8 * (end_limb - start_limb)); i += blockDim.x * gridDim.x){
        const size_t n_twr = params->N / 8;
        const size_t n_idx = i % n_twr;
        const size_t twr_idx = i / n_twr;
        const size_t group = params->n1 / 8;
        const size_t pad_tid = threadIdx.x % params->pad;
        const size_t pad_idx = threadIdx.x / params->pad;
        const size_t n_init = n_twr / group * pad_idx + pad_tid + params->pad * (n_idx / (group * params->pad));
        uint64_t *out;
        // iNTTPhase1_8
        d_poly_inplace_inwt_radix8_phase1(in, params, params->L, 0, shared, reg, i);
        // MultConst_9
        #pragma unroll
        for (int l = 0; l < 8; l++){
            reg[l] = phantom::arith::multiply_and_reduce_shoup(reg[l], partQlHatInv_mod_Ql_concat[twr_idx], partQlHatInv_mod_Ql_concat_shoup[twr_idx], params->qVec[twr_idx]);
        }

        // Store data from register
        const size_t idx_out = twr_idx * params->N + n_init;
        out = edge_MultConst_9_0_BConv_18_0;
        #pragma unroll
        for (int l = 0; l < 8; l++) {
            *(out + idx_out + n_twr * l) = reg[l];
        }
        __syncthreads();
    }
}


// Define kernel for subgraph[4], type: ElemSlot
__global__ void BConv_10(Params *params, uint64_t *edge_MultConst_9_8_BConv_10_0, uint64_t *edge_BConv_10_0_End_3_9, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_10_0_End_3_9;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_10
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_8_BConv_10_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[5], type: ElemSlot
__global__ void BConv_11(Params *params, uint64_t *edge_MultConst_9_7_BConv_11_0, uint64_t *edge_BConv_11_0_End_3_8, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_11_0_End_3_8;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_11
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_7_BConv_11_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[6], type: ElemSlot
__global__ void BConv_12(Params *params, uint64_t *edge_MultConst_9_6_BConv_12_0, uint64_t *edge_BConv_12_0_End_3_7, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_12_0_End_3_7;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_12
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_6_BConv_12_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[7], type: ElemSlot
__global__ void BConv_13(Params *params, uint64_t *edge_MultConst_9_5_BConv_13_0, uint64_t *edge_BConv_13_0_End_3_6, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_13_0_End_3_6;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_13
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_5_BConv_13_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[8], type: ElemSlot
__global__ void BConv_14(Params *params, uint64_t *edge_MultConst_9_4_BConv_14_0, uint64_t *edge_BConv_14_0_End_3_5, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_14_0_End_3_5;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_14
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_4_BConv_14_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[9], type: ElemSlot
__global__ void BConv_15(Params *params, uint64_t *edge_MultConst_9_3_BConv_15_0, uint64_t *edge_BConv_15_0_End_3_4, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_15_0_End_3_4;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_15
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_3_BConv_15_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[10], type: ElemSlot
__global__ void BConv_16(Params *params, uint64_t *edge_MultConst_9_2_BConv_16_0, uint64_t *edge_BConv_16_0_End_3_3, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_16_0_End_3_3;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_16
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_2_BConv_16_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[11], type: ElemSlot
__global__ void BConv_17(Params *params, uint64_t *edge_MultConst_9_1_BConv_17_0, uint64_t *edge_BConv_17_0_End_3_2, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_17_0_End_3_2;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_17
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_1_BConv_17_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


// Define kernel for subgraph[12], type: ElemSlot
__global__ void BConv_18(Params *params, uint64_t *edge_MultConst_9_0_BConv_18_0, uint64_t *edge_BConv_18_0_End_3_1, const uint64_t *qiHat_mod_pj, const DModulus *ibase, uint64_t ibase_size, const DModulus *obase, uint64_t obase_size, size_t startPartIdx, size_t size_PartQl){
    extern __shared__ uint64_t shared[];
    for (size_t i = threadIdx.x; i < obase_size * ibase_size; i += blockDim.x){
        shared[i] = qiHat_mod_pj[i];
    }
    __syncthreads();
    uint64_t *out = edge_BConv_18_0_End_3_1;
    const int unroll_number = 2;
    for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < (params->N * obase_size + unroll_number - 1) / unroll_number; tid += blockDim.x * gridDim.x){
        const size_t n_idx = unroll_number * (tid / obase_size);
        const size_t l_idx = tid % obase_size;
        uint64_t res1, res2;
        // BConv_18
        BConvOpNoReg(params, &res1, &res2, edge_MultConst_9_0_BConv_18_0 + params->N * startPartIdx, shared, n_idx, l_idx, ibase, ibase_size, obase, obase_size, startPartIdx, size_PartQl);
        const size_t l_out_idx = l_idx + ((l_idx >= startPartIdx) ? size_PartQl : 0);
        asm("st.cs.global.v2.u64 [%0], {%1, %2};":: "l"(out + l_out_idx * params->N + n_idx),"l"(res1), "l"(res2));
    }
}


void entry_kernel(Params *params_d, Params *params_h, PhantomContext &context, uint64_t *in0, uint64_t *in1, uint64_t *out0, uint64_t *out1, bool if_benchmark){
    phantom::DRNSTool *rns_tool = params_h->rns_tools[1];

    // =====================================
    // Input arguments
    // =====================================
    // Edge: Init_0 -> Mult_6
    uint64_t *edge_Init_0_0_Mult_6_0_d = in0 + 589824;
    // Edge: Init_0 -> Mult_6
    uint64_t *edge_Init_0_1_Mult_6_1_d = in1 + 589824;
    // Edge: Init_0 -> Mult_5
    uint64_t *edge_Init_0_2_Mult_5_0_d = in0 + 0;
    // Edge: Init_0 -> Mult_5
    uint64_t *edge_Init_0_3_Mult_5_1_d = in1 + 0;
    // Edge: Init_0 -> Mult_4
    uint64_t *edge_Init_0_4_Mult_4_0_d = in0 + 0;
    // Edge: Init_0 -> Mult_4
    uint64_t *edge_Init_0_5_Mult_4_1_d = in1 + 589824;
    // Edge: Init_0 -> Mult_1
    uint64_t *edge_Init_0_6_Mult_1_0_d = in0 + 589824;
    // Edge: Init_0 -> Mult_1
    uint64_t *edge_Init_0_7_Mult_1_1_d = in1 + 0;

    // =====================================
    // Output arguments
    // =====================================
    // Edge: Add_2 -> End_3
    uint64_t *edge_Add_2_0_End_3_0_d = out0 + 589824;
    // Edge: BConv_18 -> End_3
    uint64_t *edge_BConv_18_0_End_3_1_d = out1 + 0;
    // Edge: BConv_17 -> End_3
    uint64_t *edge_BConv_17_0_End_3_2_d = out1 + 655360;
    // Edge: BConv_16 -> End_3
    uint64_t *edge_BConv_16_0_End_3_3_d = out1 + 1310720;
    // Edge: BConv_15 -> End_3
    uint64_t *edge_BConv_15_0_End_3_4_d = out1 + 1966080;
    // Edge: BConv_14 -> End_3
    uint64_t *edge_BConv_14_0_End_3_5_d = out1 + 2621440;
    // Edge: BConv_13 -> End_3
    uint64_t *edge_BConv_13_0_End_3_6_d = out1 + 3276800;
    // Edge: BConv_12 -> End_3
    uint64_t *edge_BConv_12_0_End_3_7_d = out1 + 3932160;
    // Edge: BConv_11 -> End_3
    uint64_t *edge_BConv_11_0_End_3_8_d = out1 + 4587520;
    // Edge: BConv_10 -> End_3
    uint64_t *edge_BConv_10_0_End_3_9_d = out1 + 5242880;
    // Edge: Mult_5 -> End_3
    uint64_t *edge_Mult_5_0_End_3_10_d = out0 + 0;
    // Edge: Mult_6 -> End_3
    uint64_t *edge_Mult_6_0_End_3_11_d = out0 + 1179648;

    // =====================================
    // Edges
    // Define global edges for GPU
    // =====================================
    // Edge: iNTTPhase2_7 -> iNTTPhase1_8
    uint64_t *edge_iNTTPhase2_7_0_iNTTPhase1_8_0_d;
    checkCudaErrors(cudaMalloc((void**)&edge_iNTTPhase2_7_0_iNTTPhase1_8_0_d, 18 * params_h->N * sizeof(uint64_t)));
    // Edge: MultConst_9 -> BConv_18
    uint64_t *edge_MultConst_9_0_BConv_18_0_d;
    checkCudaErrors(cudaMalloc((void**)&edge_MultConst_9_0_BConv_18_0_d, 18 * params_h->N * sizeof(uint64_t)));
    uint64_t *edge_MultConst_9_1_BConv_17_0_d = edge_MultConst_9_0_BConv_18_0_d;
    uint64_t *edge_MultConst_9_2_BConv_16_0_d = edge_MultConst_9_0_BConv_18_0_d;
    uint64_t *edge_MultConst_9_3_BConv_15_0_d = edge_MultConst_9_0_BConv_18_0_d;
    uint64_t *edge_MultConst_9_4_BConv_14_0_d = edge_MultConst_9_0_BConv_18_0_d;
    uint64_t *edge_MultConst_9_5_BConv_13_0_d = edge_MultConst_9_0_BConv_18_0_d;
    uint64_t *edge_MultConst_9_6_BConv_12_0_d = edge_MultConst_9_0_BConv_18_0_d;
    uint64_t *edge_MultConst_9_7_BConv_11_0_d = edge_MultConst_9_0_BConv_18_0_d;
    uint64_t *edge_MultConst_9_8_BConv_10_0_d = edge_MultConst_9_0_BConv_18_0_d;
    // =====================================
    std::cout << "### Warm up and Test" << std::endl;
    std::cout << "N : " << params_h->N << std::endl;
    std::cout << "L : " << params_h->L << std::endl;
    std::cout << "dnum : " << params_h->dnum << std::endl;
    std::cout << "alpha : " << params_h->alpha << std::endl;

    // =====================================
    // Warm up
    // =====================================
    {
        // Call kernel
        // Timer start
        auto start = std::chrono::high_resolution_clock::now();
        phantom::DRNSTool *drns_tool = params_h->rns_tools[1];
        const int beta = std::ceil((params_h->L + 1) / params_h->alpha);
        Mult_4_Mult_1_Add_2<<<4096, 256, 3072>>>(params_d, edge_Init_0_4_Mult_4_0_d, edge_Init_0_5_Mult_4_1_d, edge_Init_0_6_Mult_1_0_d, edge_Init_0_7_Mult_1_1_d, edge_Add_2_0_End_3_0_d);
        Mult_5<<<4096, 256, 0>>>(params_d, edge_Init_0_2_Mult_5_0_d, edge_Init_0_3_Mult_5_1_d, edge_Mult_5_0_End_3_10_d);
        Mult_6_iNTTPhase2_7<<<4096, 128, params_h->per_thread_ntt_size * 128 * sizeof(uint64_t)>>>(params_d, edge_Init_0_0_Mult_6_0_d, edge_Init_0_1_Mult_6_1_d, edge_Mult_6_0_End_3_11_d, edge_iNTTPhase2_7_0_iNTTPhase1_8_0_d);
        checkCudaErrors(cudaDeviceSynchronize());
        iNTTPhase1_8_MultConst_9<<<4096, (params_h->n1 / 8) * params_h->pad, (params_h->n1 + params_h->pad + 1) * params_h->pad * sizeof(uint64_t)>>>(params_d, edge_iNTTPhase2_7_0_iNTTPhase1_8_0_d, edge_MultConst_9_0_BConv_18_0_d, edge_MultConst_9_1_BConv_17_0_d, edge_MultConst_9_2_BConv_16_0_d, edge_MultConst_9_3_BConv_15_0_d, edge_MultConst_9_4_BConv_14_0_d, edge_MultConst_9_5_BConv_13_0_d, edge_MultConst_9_6_BConv_12_0_d, edge_MultConst_9_7_BConv_11_0_d, edge_MultConst_9_8_BConv_10_0_d, rns_tool->partQlHatInv_mod_Ql_concat(), rns_tool->partQlHatInv_mod_Ql_concat_shoup());
        {
            const size_t beta_idx = 8;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_10<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_8_BConv_10_0_d, edge_BConv_10_0_End_3_9_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 7;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_11<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_7_BConv_11_0_d, edge_BConv_11_0_End_3_8_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 6;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_12<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_6_BConv_12_0_d, edge_BConv_12_0_End_3_7_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 5;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_13<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_5_BConv_13_0_d, edge_BConv_13_0_End_3_6_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 4;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_14<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_4_BConv_14_0_d, edge_BConv_14_0_End_3_5_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 3;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_15<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_3_BConv_15_0_d, edge_BConv_15_0_End_3_4_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 2;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_16<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_2_BConv_16_0_d, edge_BConv_16_0_End_3_3_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 1;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_17<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_1_BConv_17_0_d, edge_BConv_17_0_End_3_2_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
        }
        {
            const size_t beta_idx = 0;
            const size_t startPartIdx = params_h->alpha * beta_idx;
            const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
            auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
            auto &ibase = bconv_pre.ibase();
            auto &obase = bconv_pre.obase();
            constexpr int unroll_factor = 2;
            BConv_18<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_0_BConv_18_0_d, edge_BConv_18_0_End_3_1_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            checkCudaErrors(cudaDeviceSynchronize());
        }
        // Timer Stop
        auto end = std::chrono::high_resolution_clock::now();

    }


    // =====================================
    // Benchmark
    // =====================================
    if (if_benchmark){
        std::cout << "### Benchmark" << std::endl;
        std::vector<double> elapsed_times;
        for (int i = 0; i < 7; i++)
        {

            // Call kernel
            // Timer start
            auto start = std::chrono::high_resolution_clock::now();
            phantom::DRNSTool *drns_tool = params_h->rns_tools[1];
            const int beta = std::ceil((params_h->L + 1) / params_h->alpha);
            Mult_4_Mult_1_Add_2<<<4096, 256, 3072>>>(params_d, edge_Init_0_4_Mult_4_0_d, edge_Init_0_5_Mult_4_1_d, edge_Init_0_6_Mult_1_0_d, edge_Init_0_7_Mult_1_1_d, edge_Add_2_0_End_3_0_d);
            Mult_5<<<4096, 256, 0>>>(params_d, edge_Init_0_2_Mult_5_0_d, edge_Init_0_3_Mult_5_1_d, edge_Mult_5_0_End_3_10_d);
            Mult_6_iNTTPhase2_7<<<4096, 128, params_h->per_thread_ntt_size * 128 * sizeof(uint64_t)>>>(params_d, edge_Init_0_0_Mult_6_0_d, edge_Init_0_1_Mult_6_1_d, edge_Mult_6_0_End_3_11_d, edge_iNTTPhase2_7_0_iNTTPhase1_8_0_d);
            checkCudaErrors(cudaDeviceSynchronize());
            iNTTPhase1_8_MultConst_9<<<4096, (params_h->n1 / 8) * params_h->pad, (params_h->n1 + params_h->pad + 1) * params_h->pad * sizeof(uint64_t)>>>(params_d, edge_iNTTPhase2_7_0_iNTTPhase1_8_0_d, edge_MultConst_9_0_BConv_18_0_d, edge_MultConst_9_1_BConv_17_0_d, edge_MultConst_9_2_BConv_16_0_d, edge_MultConst_9_3_BConv_15_0_d, edge_MultConst_9_4_BConv_14_0_d, edge_MultConst_9_5_BConv_13_0_d, edge_MultConst_9_6_BConv_12_0_d, edge_MultConst_9_7_BConv_11_0_d, edge_MultConst_9_8_BConv_10_0_d, rns_tool->partQlHatInv_mod_Ql_concat(), rns_tool->partQlHatInv_mod_Ql_concat_shoup());
            {
                const size_t beta_idx = 8;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_10<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_8_BConv_10_0_d, edge_BConv_10_0_End_3_9_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 7;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_11<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_7_BConv_11_0_d, edge_BConv_11_0_End_3_8_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 6;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_12<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_6_BConv_12_0_d, edge_BConv_12_0_End_3_7_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 5;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_13<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_5_BConv_13_0_d, edge_BConv_13_0_End_3_6_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 4;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_14<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_4_BConv_14_0_d, edge_BConv_14_0_End_3_5_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 3;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_15<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_3_BConv_15_0_d, edge_BConv_15_0_End_3_4_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 2;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_16<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_2_BConv_16_0_d, edge_BConv_16_0_End_3_3_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 1;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_17<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_1_BConv_17_0_d, edge_BConv_17_0_End_3_2_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
            }
            {
                const size_t beta_idx = 0;
                const size_t startPartIdx = params_h->alpha * beta_idx;
                const size_t size_PartQl = (beta_idx == beta - 1)?(params_h->L - params_h->alpha * (beta - 1)): params_h->alpha;
                auto &bconv_pre = drns_tool->v_base_part_Ql_to_compl_part_QlP_conv()[beta_idx];
                auto &ibase = bconv_pre.ibase();
                auto &obase = bconv_pre.obase();
                constexpr int unroll_factor = 2;
                BConv_18<<<params_h->N * obase.size() / 128 / unroll_factor, 128, (128 * 2 + obase.size()) * ibase.size() * sizeof(uint64_t)>>>(params_d, edge_MultConst_9_0_BConv_18_0_d, edge_BConv_18_0_End_3_1_d, bconv_pre.QHatModp(), bconv_pre.ibase().base(), bconv_pre.ibase().size(), bconv_pre.obase().base(), bconv_pre.obase().size(), startPartIdx, size_PartQl);
                checkCudaErrors(cudaDeviceSynchronize());
            }
            // Timer Stop
            auto end = std::chrono::high_resolution_clock::now();


            auto elapsed_usec = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
            std::cout << "Elapsed time: " << elapsed_usec.count() << "us" << std::endl;
            if (i != 0) {elapsed_times.push_back(elapsed_usec.count());}
        }
        std::cout << "Average time[us]: " << std::accumulate(elapsed_times.begin(), elapsed_times.end(), 0.0) / elapsed_times.size() << std::endl;
    }
}
