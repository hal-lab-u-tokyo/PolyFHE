Compiling example code...
nvcc -std=c++17 -O3 -I. -I../../thirdparty -I../../thirdparty/phantom-fhe/include -I../../ -Xlinker -rpath -Xlinker ../../build/thirdparty/phantom-fhe/lib -L../../build/thirdparty/phantom-fhe/lib -lPhantom -lpthread -lnvToolsExt -o build/example.out build/generated.cu example.cu 
ncu --nvtx --nvtx-include "compute/" ./build/example.out
==PROF== Connected to process 39494 (/opt/mount/PolyFHE/example/ckks_HMult/build/example.out)
/
| Encryption parameters :
|   scheme: CKKS
|   poly_modulus_degree: 65536
|   coeff_modulus size: 1580 (60 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 40 + 60 + 60 + 60 + 60 + 60 + 60) bits

1152921504589938689 ,  1099460640769 ,  1099460902913 ,  1099461820417 ,  1099463786497 ,  1099465359361 ,  1099467194369 ,  1099468505089 ,  1099468767233 ,  1099469684737 ,  1099479121921 ,  1099480956929 ,  1099482923009 ,  1099484495873 ,  1099484889089 ,  1099486855169 ,  1099488428033 ,  1099489607681 ,  1099490000897 ,  1099498258433 ,  1099499175937 ,  1099499569153 ,  1099500617729 ,  1099502714881 ,  1099503370241 ,  1099503894529 ,  1099504549889 ,  1099506515969 ,  1099507695617 ,  1099510054913 ,  1152921504592429057 ,  1152921504592822273 ,  1152921504595968001 ,  1152921504597016577 ,  1152921504598720513 ,  1152921504606584833 ,  

\
Input vector 1: length = 32768

    [ 0.0587777 + i * 0.9699076, 0.2317936 + i * 0.0682488, 0.6594031 + i * 0.9996441, ..., 0.3264407 + i * 0.1486907, 0.4706125 + i * 0.9084112, 0.3362332 + i * 0.5747973 ]

Input vector 2: length = 32768

    [ 0.4118914 + i * 0.6631007, 0.6132761 + i * 0.3576946, 0.6743956 + i * 0.6455382, ..., 0.5418337 + i * 0.2585890, 0.6105746 + i * 0.3405159, 0.2123764 + i * 0.7895435 ]

x_plain.chain_index(): 1
x_plain.chain_index(): 1
x_cipher.chain_index(): 1
coeff_mod_size: 30
beta: 5
### Warm up and Test
N : 65536
L : 30
dnum : 5
alpha : 6
### Benchmark
==PROF== Profiling "NTTPhase2_general" - 0: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 1: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 2: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 3: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 4: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 5: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 6: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 7: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 8: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 9: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 10: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 11: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 12: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 13: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 14: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 15: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 16: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 17: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 18: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 19: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 20: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 21: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 22: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 23: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 24: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 25: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 26: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 27: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 28: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 29: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 30: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 31: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 32: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 33: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 34: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 35: 0%....50%....100% - 8 passes
Elapsed time: 6773713us
==PROF== Profiling "NTTPhase2_general" - 36: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 37: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 38: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 39: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 40: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 41: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 42: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 43: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 44: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 45: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 46: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 47: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 48: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 49: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 50: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 51: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 52: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 53: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 54: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 55: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 56: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 57: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 58: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 59: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 60: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 61: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 62: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 63: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 64: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 65: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 66: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 67: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 68: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 69: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 70: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 71: 0%....50%....100% - 8 passes
Elapsed time: 6477624us
==PROF== Profiling "NTTPhase2_general" - 72: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 73: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 74: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 75: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 76: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 77: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 78: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 79: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 80: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 81: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 82: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 83: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 84: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 85: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 86: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 87: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 88: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 89: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 90: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 91: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 92: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 93: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 94: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 95: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 96: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 97: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 98: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 99: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 100: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 101: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 102: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 103: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 104: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 105: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 106: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 107: 0%....50%....100% - 8 passes
Elapsed time: 6478736us
==PROF== Profiling "NTTPhase2_general" - 108: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 109: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 110: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 111: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 112: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 113: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 114: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 115: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 116: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 117: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 118: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 119: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 120: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 121: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 122: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 123: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 124: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 125: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 126: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 127: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 128: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 129: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 130: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 131: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 132: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 133: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 134: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 135: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 136: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 137: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 138: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 139: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 140: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 141: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 142: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 143: 0%....50%....100% - 8 passes
Elapsed time: 6476108us
==PROF== Profiling "NTTPhase2_general" - 144: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 145: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 146: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 147: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 148: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 149: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 150: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 151: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 152: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 153: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 154: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 155: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 156: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 157: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 158: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 159: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 160: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 161: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 162: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 163: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 164: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 165: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 166: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 167: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 168: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 169: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 170: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 171: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 172: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 173: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 174: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 175: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 176: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 177: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 178: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 179: 0%....50%....100% - 8 passes
Elapsed time: 6494595us
==PROF== Profiling "NTTPhase2_general" - 180: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 181: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 182: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 183: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 184: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 185: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 186: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 187: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 188: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 189: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 190: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 191: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 192: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 193: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 194: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 195: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 196: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 197: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 198: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 199: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 200: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 201: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 202: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 203: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 204: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 205: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 206: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 207: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 208: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 209: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 210: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 211: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 212: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 213: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 214: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 215: 0%....50%....100% - 8 passes
Elapsed time: 6461459us
==PROF== Profiling "NTTPhase2_general" - 216: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 217: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 218: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 219: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 220: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 221: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 222: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 223: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 224: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 225: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 226: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 227: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 228: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 229: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 230: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 231: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 232: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 233: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 234: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 235: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 236: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 237: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 238: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 239: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 240: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 241: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 242: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 243: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 244: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 245: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 246: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 247: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 248: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 249: 0%....50%....100% - 8 passes
==PROF== Profiling "NTTPhase2_general" - 250: 0%....50%....100% - 8 passes
==PROF== Profiling "MultKeyAccum_8" - 251: 0%....50%....100% - 8 passes
Elapsed time: 6479150us
Average time[us]: 6.47795e+06
xy_cipher.chain_index(): 1
idx: 0
  OK
idx: 1
  OK
idx: 2
  OK
Modup result
params_h.KL: 36
poly_degree: 65536
beta_idx: 0
beta_idx: 1
  OK
Average elapsed time (Phantom): 5153.5 us
==PROF== Disconnected from process 39494
[39494] example.out@127.0.0.1
  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32834
    Memory Throughput                   %        65.25
    DRAM Throughput                     %        65.25
    Duration                      usecond        14.78
    L1/TEX Cache Throughput             %        27.92
    L2 Cache Throughput                 %        28.25
    SM Active Cycles                cycle     27283.77
    Compute (SM) Throughput             %        16.64
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.97
    Achieved Active Warps Per SM           warp        11.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.05%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1809408
    Average L1 Active Cycles         cycle     27283.77
    Total L1 Elapsed Cycles          cycle      4168878
    Average L2 Active Cycles         cycle     22928.89
    Total L2 Elapsed Cycles          cycle      1041084
    Average SM Active Cycles         cycle     27283.77
    Total SM Elapsed Cycles          cycle      4168878
    Average SMSP Active Cycles       cycle     27016.51
    Total SMSP Elapsed Cycles        cycle     16675512
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.572%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.04% above the average, while the minimum instance value is 20.61% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.692%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.86% above the average, while the minimum instance value is 14.96% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.572%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.04% above the average, while the minimum instance value is 20.61% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32534
    Memory Throughput                   %        65.66
    DRAM Throughput                     %        65.66
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        27.49
    L2 Cache Throughput                 %        28.49
    SM Active Cycles                cycle     27722.01
    Compute (SM) Throughput             %        17.14
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.31
    Achieved Active Warps Per SM           warp        11.67
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.38%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1798144
    Average L1 Active Cycles         cycle     27722.01
    Total L1 Elapsed Cycles          cycle      4047430
    Average L2 Active Cycles         cycle     22930.67
    Total L2 Elapsed Cycles          cycle      1032444
    Average SM Active Cycles         cycle     27722.01
    Total SM Elapsed Cycles          cycle      4047430
    Average SMSP Active Cycles       cycle     27280.35
    Total SMSP Elapsed Cycles        cycle     16189720
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.1%                                                                                            
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.96% above the average, while the minimum instance value is 11.14% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.1%                                                                                            
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.96% above the average, while the minimum instance value is 11.14% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle        32218
    Memory Throughput                   %        66.57
    DRAM Throughput                     %        66.57
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        28.84
    SM Active Cycles                cycle     27207.60
    Compute (SM) Throughput             %        17.17
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.84
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.32%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1773568
    Average L1 Active Cycles         cycle     27207.60
    Total L1 Elapsed Cycles          cycle      4040040
    Average L2 Active Cycles         cycle     22941.81
    Total L2 Elapsed Cycles          cycle      1020024
    Average SM Active Cycles         cycle     27207.60
    Total SM Elapsed Cycles          cycle      4040040
    Average SMSP Active Cycles       cycle     27338.05
    Total SMSP Elapsed Cycles        cycle     16160160
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.36%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.38% above the average, while the minimum instance value is 18.23% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.36%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.38% above the average, while the minimum instance value is 18.23% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.18
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        33206
    Memory Throughput                   %        64.66
    DRAM Throughput                     %        64.66
    Duration                      usecond        14.94
    L1/TEX Cache Throughput             %        27.83
    L2 Cache Throughput                 %        28.07
    SM Active Cycles                cycle     27363.53
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.25
    Achieved Active Warps Per SM           warp        12.12
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.51%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1825792
    Average L1 Active Cycles         cycle     27363.53
    Total L1 Elapsed Cycles          cycle      4073176
    Average L2 Active Cycles         cycle     22816.06
    Total L2 Elapsed Cycles          cycle      1051632
    Average SM Active Cycles         cycle     27363.53
    Total SM Elapsed Cycles          cycle      4073176
    Average SMSP Active Cycles       cycle     27097.94
    Total SMSP Elapsed Cycles        cycle     16292704
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.007%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.31% above the average, while the minimum instance value is 20.41% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.007%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.31% above the average, while the minimum instance value is 20.41% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.09
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9725
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.08
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3977.05
    Compute (SM) Throughput             %         9.16
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.76
    Achieved Active Warps Per SM           warp        12.37
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.47%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       534528
    Average L1 Active Cycles         cycle      3977.05
    Total L1 Elapsed Cycles          cycle      1214566
    Average L2 Active Cycles         cycle        86.61
    Total L2 Elapsed Cycles          cycle       307404
    Average SM Active Cycles         cycle      3977.05
    Total SM Elapsed Cycles          cycle      1214566
    Average SMSP Active Cycles       cycle      3607.25
    Total SMSP Elapsed Cycles        cycle      4858264
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.17%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.49% above the average, while the minimum instance value is 23.13% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.777%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 20.46% above the average, while the minimum instance value is 25.82% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.17%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.49% above the average, while the minimum instance value is 23.13% below the      
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117936
    Memory Throughput                   %        91.34
    DRAM Throughput                     %        91.34
    Duration                      usecond        52.86
    L1/TEX Cache Throughput             %        10.38
    L2 Cache Throughput                 %        39.49
    SM Active Cycles                cycle    111052.39
    Compute (SM) Throughput             %        10.03
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.98
    Achieved Active Warps Per SM           warp        43.67
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494026.67
    Total DRAM Elapsed Cycles        cycle      6490112
    Average L1 Active Cycles         cycle    111052.39
    Total L1 Elapsed Cycles          cycle     15030510
    Average L2 Active Cycles         cycle     98040.64
    Total L2 Elapsed Cycles          cycle      3734316
    Average SM Active Cycles         cycle    111052.39
    Total SM Elapsed Cycles          cycle     15030510
    Average SMSP Active Cycles       cycle    108174.10
    Total SMSP Elapsed Cycles        cycle     60122040
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.154%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.59% above the average, while the minimum instance value is 20.43% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31911
    Memory Throughput                   %        66.57
    DRAM Throughput                     %        66.57
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.81
    L2 Cache Throughput                 %        28.99
    SM Active Cycles                cycle     27400.20
    Compute (SM) Throughput             %        17.17
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.46
    Achieved Active Warps Per SM           warp        11.74
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.08%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1773568
    Average L1 Active Cycles         cycle     27400.20
    Total L1 Elapsed Cycles          cycle      4039578
    Average L2 Active Cycles         cycle        22799
    Total L2 Elapsed Cycles          cycle      1014768
    Average SM Active Cycles         cycle     27400.20
    Total SM Elapsed Cycles          cycle      4039578
    Average SMSP Active Cycles       cycle     26894.59
    Total SMSP Elapsed Cycles        cycle     16158312
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.056%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.93% above the average, while the minimum instance value is 13.61% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        33547
    Memory Throughput                   %        63.77
    DRAM Throughput                     %        63.77
    Duration                      usecond        15.10
    L1/TEX Cache Throughput             %        27.68
    L2 Cache Throughput                 %        27.63
    SM Active Cycles                cycle     27518.09
    Compute (SM) Throughput             %        17.14
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.49
    Achieved Active Warps Per SM           warp        11.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.02%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1851392
    Average L1 Active Cycles         cycle     27518.09
    Total L1 Elapsed Cycles          cycle      4047082
    Average L2 Active Cycles         cycle     22885.83
    Total L2 Elapsed Cycles          cycle      1064448
    Average SM Active Cycles         cycle     27518.09
    Total SM Elapsed Cycles          cycle      4047082
    Average SMSP Active Cycles       cycle     27177.74
    Total SMSP Elapsed Cycles        cycle     16188328
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.589%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.87% above the average, while the minimum instance value is 16.10% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.589%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.87% above the average, while the minimum instance value is 16.10% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        33056
    Memory Throughput                   %        63.95
    DRAM Throughput                     %        63.95
    Duration                      usecond        15.04
    L1/TEX Cache Throughput             %        28.05
    L2 Cache Throughput                 %        27.94
    SM Active Cycles                cycle     27151.16
    Compute (SM) Throughput             %        16.81
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.83
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.34%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1846272
    Average L1 Active Cycles         cycle     27151.16
    Total L1 Elapsed Cycles          cycle      4126966
    Average L2 Active Cycles         cycle     22909.14
    Total L2 Elapsed Cycles          cycle      1052892
    Average SM Active Cycles         cycle     27151.16
    Total SM Elapsed Cycles          cycle      4126966
    Average SMSP Active Cycles       cycle     27047.46
    Total SMSP Elapsed Cycles        cycle     16507864
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.189%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.72% above the average, while the minimum instance value is 14.04% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.067%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.04% above the average, while the minimum instance value is 14.05% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.189%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.72% above the average, while the minimum instance value is 14.04% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.16
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        10012
    Memory Throughput                   %         5.76
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.51
    L1/TEX Cache Throughput             %        13.00
    L2 Cache Throughput                 %         1.84
    SM Active Cycles                cycle      4308.42
    Compute (SM) Throughput             %         8.92
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        23.15
    Achieved Active Warps Per SM           warp        11.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 53.69%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (23.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       338.67
    Total DRAM Elapsed Cycles        cycle       549888
    Average L1 Active Cycles         cycle      4308.42
    Total L1 Elapsed Cycles          cycle      1243502
    Average L2 Active Cycles         cycle        81.92
    Total L2 Elapsed Cycles          cycle       316656
    Average SM Active Cycles         cycle      4308.42
    Total SM Elapsed Cycles          cycle      1243502
    Average SMSP Active Cycles       cycle      3457.13
    Total SMSP Elapsed Cycles        cycle      4974008
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.621%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.44% above the average, while the minimum instance value is 22.57% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.727%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.90% above the average, while the minimum instance value is 27.40% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.621%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.44% above the average, while the minimum instance value is 22.57% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31975
    Memory Throughput                   %        66.37
    DRAM Throughput                     %        66.37
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.98
    L2 Cache Throughput                 %        28.93
    SM Active Cycles                cycle     27218.61
    Compute (SM) Throughput             %        17.06
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.72
    Achieved Active Warps Per SM           warp        11.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1778688
    Average L1 Active Cycles         cycle     27218.61
    Total L1 Elapsed Cycles          cycle      4065686
    Average L2 Active Cycles         cycle     23059.53
    Total L2 Elapsed Cycles          cycle      1016820
    Average SM Active Cycles         cycle     27218.61
    Total SM Elapsed Cycles          cycle      4065686
    Average SMSP Active Cycles       cycle     27195.71
    Total SMSP Elapsed Cycles        cycle     16262744
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.011%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.85% above the average, while the minimum instance value is 16.82% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.341%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.24% above the average, while the minimum instance value is 14.14% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.011%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.85% above the average, while the minimum instance value is 16.82% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117549
    Memory Throughput                   %        91.26
    DRAM Throughput                     %        91.26
    Duration                      usecond        52.67
    L1/TEX Cache Throughput             %        10.58
    L2 Cache Throughput                 %        39.63
    SM Active Cycles                cycle    108966.08
    Compute (SM) Throughput             %        10.00
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.61
    Achieved Active Warps Per SM           warp        43.97
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491625.33
    Total DRAM Elapsed Cycles        cycle      6464512
    Average L1 Active Cycles         cycle    108966.08
    Total L1 Elapsed Cycles          cycle     15068590
    Average L2 Active Cycles         cycle     98224.44
    Total L2 Elapsed Cycles          cycle      3721176
    Average SM Active Cycles         cycle    108966.08
    Total SM Elapsed Cycles          cycle     15068590
    Average SMSP Active Cycles       cycle    107983.72
    Total SMSP Elapsed Cycles        cycle     60274360
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.649%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.16% above the average, while the minimum instance value is 18.73% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32314
    Memory Throughput                   %        66.08
    DRAM Throughput                     %        66.08
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.88
    L2 Cache Throughput                 %        28.70
    SM Active Cycles                cycle     27339.95
    Compute (SM) Throughput             %        17.17
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.61
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.78%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1786880
    Average L1 Active Cycles         cycle     27339.95
    Total L1 Elapsed Cycles          cycle      4040470
    Average L2 Active Cycles         cycle     22869.22
    Total L2 Elapsed Cycles          cycle      1025100
    Average SM Active Cycles         cycle     27339.95
    Total SM Elapsed Cycles          cycle      4040470
    Average SMSP Active Cycles       cycle     27059.58
    Total SMSP Elapsed Cycles        cycle     16161880
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.347%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.33% above the average, while the minimum instance value is 12.98% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.353%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.24% above the average, while the minimum instance value is 13.39% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.347%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.33% above the average, while the minimum instance value is 12.98% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32335
    Memory Throughput                   %        65.36
    DRAM Throughput                     %        65.36
    Duration                      usecond        14.75
    L1/TEX Cache Throughput             %        28.27
    L2 Cache Throughput                 %        28.56
    SM Active Cycles                cycle     26944.38
    Compute (SM) Throughput             %        16.97
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.99
    Achieved Active Warps Per SM           warp        11.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.03%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1806336
    Average L1 Active Cycles         cycle     26944.38
    Total L1 Elapsed Cycles          cycle      4089260
    Average L2 Active Cycles         cycle     22898.11
    Total L2 Elapsed Cycles          cycle      1029924
    Average SM Active Cycles         cycle     26944.38
    Total SM Elapsed Cycles          cycle      4089260
    Average SMSP Active Cycles       cycle     26994.14
    Total SMSP Elapsed Cycles        cycle     16357040
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.56%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.78% above the average, while the minimum instance value is 20.95% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.843%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.10% above the average, while the minimum instance value is 11.94% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.56%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.78% above the average, while the minimum instance value is 20.95% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.13
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9754
    Memory Throughput                   %         5.92
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.85
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4042.17
    Compute (SM) Throughput             %         9.17
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.84
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.31%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       536576
    Average L1 Active Cycles         cycle      4042.17
    Total L1 Elapsed Cycles          cycle      1211314
    Average L2 Active Cycles         cycle        84.83
    Total L2 Elapsed Cycles          cycle       308628
    Average SM Active Cycles         cycle      4042.17
    Total SM Elapsed Cycles          cycle      1211314
    Average SMSP Active Cycles       cycle      3428.02
    Total SMSP Elapsed Cycles        cycle      4845256
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.231%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.27% above the average, while the minimum instance value is 23.58% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.19%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.85% above the average, while the minimum instance value is 28.01% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.231%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.27% above the average, while the minimum instance value is 23.58% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31963
    Memory Throughput                   %        66.18
    DRAM Throughput                     %        66.18
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        28.24
    L2 Cache Throughput                 %        28.90
    SM Active Cycles                cycle        26976
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.67
    Achieved Active Warps Per SM           warp        11.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.65%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1783808
    Average L1 Active Cycles         cycle        26976
    Total L1 Elapsed Cycles          cycle      4074708
    Average L2 Active Cycles         cycle     22825.53
    Total L2 Elapsed Cycles          cycle      1017972
    Average SM Active Cycles         cycle        26976
    Total SM Elapsed Cycles          cycle      4074708
    Average SMSP Active Cycles       cycle     26957.97
    Total SMSP Elapsed Cycles        cycle     16298832
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.101%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.20% above the average, while the minimum instance value is 18.05% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.054%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.97% above the average, while the minimum instance value is 26.44% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.101%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.20% above the average, while the minimum instance value is 18.05% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        31946
    Memory Throughput                   %        67.07
    DRAM Throughput                     %        67.07
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.89
    L2 Cache Throughput                 %        29.05
    SM Active Cycles                cycle     27317.64
    Compute (SM) Throughput             %        17.05
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.60
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.8%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1760256
    Average L1 Active Cycles         cycle     27317.64
    Total L1 Elapsed Cycles          cycle      4069272
    Average L2 Active Cycles         cycle     22672.08
    Total L2 Elapsed Cycles          cycle      1012536
    Average SM Active Cycles         cycle     27317.64
    Total SM Elapsed Cycles          cycle      4069272
    Average SMSP Active Cycles       cycle     27078.97
    Total SMSP Elapsed Cycles        cycle     16277088
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.057%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.89% above the average, while the minimum instance value is 20.39% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.057%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.89% above the average, while the minimum instance value is 20.39% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117585
    Memory Throughput                   %        91.45
    DRAM Throughput                     %        91.45
    Duration                      usecond        52.67
    L1/TEX Cache Throughput             %        10.55
    L2 Cache Throughput                 %        39.62
    SM Active Cycles                cycle    109247.16
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.31
    Achieved Active Warps Per SM           warp        44.31
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    492830.67
    Total DRAM Elapsed Cycles        cycle      6466560
    Average L1 Active Cycles         cycle    109247.16
    Total L1 Elapsed Cycles          cycle     14985586
    Average L2 Active Cycles         cycle     98104.75
    Total L2 Elapsed Cycles          cycle      3722256
    Average SM Active Cycles         cycle    109247.16
    Total SM Elapsed Cycles          cycle     14985586
    Average SMSP Active Cycles       cycle    108355.69
    Total SMSP Elapsed Cycles        cycle     59942344
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31671
    Memory Throughput                   %        66.84
    DRAM Throughput                     %        66.84
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        28.16
    L2 Cache Throughput                 %        29.16
    SM Active Cycles                cycle     27065.66
    Compute (SM) Throughput             %        17.27
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.87
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.25%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1766400
    Average L1 Active Cycles         cycle     27065.66
    Total L1 Elapsed Cycles          cycle      4017252
    Average L2 Active Cycles         cycle     22987.19
    Total L2 Elapsed Cycles          cycle      1008792
    Average SM Active Cycles         cycle     27065.66
    Total SM Elapsed Cycles          cycle      4017252
    Average SMSP Active Cycles       cycle     27122.88
    Total SMSP Elapsed Cycles        cycle     16069008
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.047%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.84% above the average, while the minimum instance value is 15.52% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.07
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9707
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.10
    L2 Cache Throughput                 %         1.92
    SM Active Cycles                cycle      3971.27
    Compute (SM) Throughput             %         9.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.34
    Achieved Active Warps Per SM           warp        12.16
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.33%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       333.33
    Total DRAM Elapsed Cycles        cycle       533504
    Average L1 Active Cycles         cycle      3971.27
    Total L1 Elapsed Cycles          cycle      1213984
    Average L2 Active Cycles         cycle        83.31
    Total L2 Elapsed Cycles          cycle       307008
    Average SM Active Cycles         cycle      3971.27
    Total SM Elapsed Cycles          cycle      1213984
    Average SMSP Active Cycles       cycle      3434.11
    Total SMSP Elapsed Cycles        cycle      4855936
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.562%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.45% above the average, while the minimum instance value is 23.85% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.298%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 20.16% above the average, while the minimum instance value is 27.43% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.562%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.45% above the average, while the minimum instance value is 23.85% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31739
    Memory Throughput                   %        66.53
    DRAM Throughput                     %        66.53
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        28.15
    L2 Cache Throughput                 %        29.08
    SM Active Cycles                cycle     27058.30
    Compute (SM) Throughput             %        17.12
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp        11.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.42%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     27058.30
    Total L1 Elapsed Cycles          cycle      4051842
    Average L2 Active Cycles         cycle     22899.33
    Total L2 Elapsed Cycles          cycle      1011600
    Average SM Active Cycles         cycle     27058.30
    Total SM Elapsed Cycles          cycle      4051842
    Average SMSP Active Cycles       cycle     27220.96
    Total SMSP Elapsed Cycles        cycle     16207368
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.74%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.71% above the average, while the minimum instance value is 12.31% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.74%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.71% above the average, while the minimum instance value is 12.31% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32544
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.58
    L2 Cache Throughput                 %        28.52
    SM Active Cycles                cycle     27637.70
    Compute (SM) Throughput             %        16.91
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.59
    Achieved Active Warps Per SM           warp        11.80
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.82%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27637.70
    Total L1 Elapsed Cycles          cycle      4103052
    Average L2 Active Cycles         cycle        23018
    Total L2 Elapsed Cycles          cycle      1031436
    Average SM Active Cycles         cycle     27637.70
    Total SM Elapsed Cycles          cycle      4103052
    Average SMSP Active Cycles       cycle     27272.31
    Total SMSP Elapsed Cycles        cycle     16412208
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.518%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.56% above the average, while the minimum instance value is 15.03% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.451%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.58% above the average, while the minimum instance value is 21.22% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.518%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.56% above the average, while the minimum instance value is 15.03% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31950
    Memory Throughput                   %        66.96
    DRAM Throughput                     %        66.96
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.81
    L2 Cache Throughput                 %        29.03
    SM Active Cycles                cycle     27384.76
    Compute (SM) Throughput             %        16.93
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.54
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.91%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98388
    Total DRAM Elapsed Cycles        cycle      1763328
    Average L1 Active Cycles         cycle     27384.76
    Total L1 Elapsed Cycles          cycle      4098872
    Average L2 Active Cycles         cycle     22995.42
    Total L2 Elapsed Cycles          cycle      1013364
    Average SM Active Cycles         cycle     27384.76
    Total SM Elapsed Cycles          cycle      4098872
    Average SMSP Active Cycles       cycle     27155.31
    Total SMSP Elapsed Cycles        cycle     16395488
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.462%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.39% above the average, while the minimum instance value is 17.89% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.373%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.52% above the average, while the minimum instance value is 19.27% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.462%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.39% above the average, while the minimum instance value is 17.89% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       118360
    Memory Throughput                   %        90.95
    DRAM Throughput                     %        90.95
    Duration                      usecond        53.12
    L1/TEX Cache Throughput             %        10.48
    L2 Cache Throughput                 %        39.32
    SM Active Cycles                cycle    110051.19
    Compute (SM) Throughput             %         9.98
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.29
    Achieved Active Warps Per SM           warp        44.30
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       494152
    Total DRAM Elapsed Cycles        cycle      6519808
    Average L1 Active Cycles         cycle    110051.19
    Total L1 Elapsed Cycles          cycle     15096040
    Average L2 Active Cycles         cycle     98082.69
    Total L2 Elapsed Cycles          cycle      3750372
    Average SM Active Cycles         cycle    110051.19
    Total SM Elapsed Cycles          cycle     15096040
    Average SMSP Active Cycles       cycle    109450.43
    Total SMSP Elapsed Cycles        cycle     60384160
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.09
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9790
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.45
    L1/TEX Cache Throughput             %        13.70
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4086.16
    Compute (SM) Throughput             %         9.17
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        26.89
    Achieved Active Warps Per SM           warp        12.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 46.22%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       538624
    Average L1 Active Cycles         cycle      4086.16
    Total L1 Elapsed Cycles          cycle      1215688
    Average L2 Active Cycles         cycle        85.64
    Total L2 Elapsed Cycles          cycle       309672
    Average SM Active Cycles         cycle      4086.16
    Total SM Elapsed Cycles          cycle      1215688
    Average SMSP Active Cycles       cycle      3447.31
    Total SMSP Elapsed Cycles        cycle      4862752
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.335%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.37% above the average, while the minimum instance value is 23.69% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.883%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.96% above the average, while the minimum instance value is 26.58% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.335%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.37% above the average, while the minimum instance value is 23.69% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31991
    Memory Throughput                   %        66.45
    DRAM Throughput                     %        66.45
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.89
    L2 Cache Throughput                 %        28.91
    SM Active Cycles                cycle     27310.82
    Compute (SM) Throughput             %        16.55
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.57
    Achieved Active Warps Per SM           warp        11.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.86%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1776640
    Average L1 Active Cycles         cycle     27310.82
    Total L1 Elapsed Cycles          cycle      4191090
    Average L2 Active Cycles         cycle     23082.25
    Total L2 Elapsed Cycles          cycle      1017324
    Average SM Active Cycles         cycle     27310.82
    Total SM Elapsed Cycles          cycle      4191090
    Average SMSP Active Cycles       cycle     27166.70
    Total SMSP Elapsed Cycles        cycle     16764360
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.276%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.33% above the average, while the minimum instance value is 11.79% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.065%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.10% above the average, while the minimum instance value is 12.18% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.276%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.33% above the average, while the minimum instance value is 11.79% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32603
    Memory Throughput                   %        65.21
    DRAM Throughput                     %        65.21
    Duration                      usecond        14.78
    L1/TEX Cache Throughput             %        28.07
    L2 Cache Throughput                 %        28.38
    SM Active Cycles                cycle     27126.91
    Compute (SM) Throughput             %        17.24
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.76
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.48%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1810432
    Average L1 Active Cycles         cycle     27126.91
    Total L1 Elapsed Cycles          cycle      4025036
    Average L2 Active Cycles         cycle     22809.94
    Total L2 Elapsed Cycles          cycle      1036404
    Average SM Active Cycles         cycle     27126.91
    Total SM Elapsed Cycles          cycle      4025036
    Average SMSP Active Cycles       cycle     26993.84
    Total SMSP Elapsed Cycles        cycle     16100144
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.745%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.82% above the average, while the minimum instance value is 16.09% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.745%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.82% above the average, while the minimum instance value is 16.09% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32529
    Memory Throughput                   %        65.88
    DRAM Throughput                     %        65.88
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.54
    L2 Cache Throughput                 %        28.55
    SM Active Cycles                cycle     27655.77
    Compute (SM) Throughput             %        17.28
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.63
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.73%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1792000
    Average L1 Active Cycles         cycle     27655.77
    Total L1 Elapsed Cycles          cycle      4014548
    Average L2 Active Cycles         cycle     22847.11
    Total L2 Elapsed Cycles          cycle      1030356
    Average SM Active Cycles         cycle     27655.77
    Total SM Elapsed Cycles          cycle      4014548
    Average SMSP Active Cycles       cycle     27216.88
    Total SMSP Elapsed Cycles        cycle     16058192
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.468%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.20% above the average, while the minimum instance value is 12.69% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.191%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.29% above the average, while the minimum instance value is 12.16% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.468%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.20% above the average, while the minimum instance value is 12.69% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32345
    Memory Throughput                   %        65.36
    DRAM Throughput                     %        65.36
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        28.03
    L2 Cache Throughput                 %        28.55
    SM Active Cycles                cycle     27189.73
    Compute (SM) Throughput             %        16.42
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.99
    Achieved Active Warps Per SM           warp        11.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.03%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1806336
    Average L1 Active Cycles         cycle     27189.73
    Total L1 Elapsed Cycles          cycle      4225806
    Average L2 Active Cycles         cycle     22965.94
    Total L2 Elapsed Cycles          cycle      1030284
    Average SM Active Cycles         cycle     27189.73
    Total SM Elapsed Cycles          cycle      4225806
    Average SMSP Active Cycles       cycle     27325.06
    Total SMSP Elapsed Cycles        cycle     16903224
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.732%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.17% above the average, while the minimum instance value is 12.26% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.732%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.17% above the average, while the minimum instance value is 12.26% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117548
    Memory Throughput                   %        91.11
    DRAM Throughput                     %        91.11
    Duration                      usecond        52.70
    L1/TEX Cache Throughput             %        10.60
    L2 Cache Throughput                 %        39.60
    SM Active Cycles                cycle    108726.13
    Compute (SM) Throughput             %        10.02
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.86
    Achieved Active Warps Per SM           warp        44.57
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491693.33
    Total DRAM Elapsed Cycles        cycle      6475776
    Average L1 Active Cycles         cycle    108726.13
    Total L1 Elapsed Cycles          cycle     15036724
    Average L2 Active Cycles         cycle     97901.39
    Total L2 Elapsed Cycles          cycle      3723480
    Average SM Active Cycles         cycle    108726.13
    Total SM Elapsed Cycles          cycle     15036724
    Average SMSP Active Cycles       cycle    108408.01
    Total SMSP Elapsed Cycles        cycle     60146896
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.18
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32789
    Memory Throughput                   %        65.36
    DRAM Throughput                     %        65.36
    Duration                      usecond        14.78
    L1/TEX Cache Throughput             %        27.28
    L2 Cache Throughput                 %        28.31
    SM Active Cycles                cycle     27923.41
    Compute (SM) Throughput             %        16.58
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.24
    Achieved Active Warps Per SM           warp        11.64
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.52%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1806336
    Average L1 Active Cycles         cycle     27923.41
    Total L1 Elapsed Cycles          cycle      4185178
    Average L2 Active Cycles         cycle     23111.36
    Total L2 Elapsed Cycles          cycle      1039068
    Average SM Active Cycles         cycle     27923.41
    Total SM Elapsed Cycles          cycle      4185178
    Average SMSP Active Cycles       cycle     27051.43
    Total SMSP Elapsed Cycles        cycle     16740712
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.533%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.48% above the average, while the minimum instance value is 15.47% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.469%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.82% above the average, while the minimum instance value is 17.68% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.533%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.48% above the average, while the minimum instance value is 15.47% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32018
    Memory Throughput                   %        66.26
    DRAM Throughput                     %        66.26
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.87
    L2 Cache Throughput                 %        28.87
    SM Active Cycles                cycle     27342.15
    Compute (SM) Throughput             %        16.56
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.52
    Achieved Active Warps Per SM           warp        11.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.96%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1781760
    Average L1 Active Cycles         cycle     27342.15
    Total L1 Elapsed Cycles          cycle      4188564
    Average L2 Active Cycles         cycle     22944.78
    Total L2 Elapsed Cycles          cycle      1018764
    Average SM Active Cycles         cycle     27342.15
    Total SM Elapsed Cycles          cycle      4188564
    Average SMSP Active Cycles       cycle     26905.35
    Total SMSP Elapsed Cycles        cycle     16754256
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.828%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.09% above the average, while the minimum instance value is 12.94% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32699
    Memory Throughput                   %        65.55
    DRAM Throughput                     %        65.55
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        27.52
    L2 Cache Throughput                 %        28.38
    SM Active Cycles                cycle     27675.02
    Compute (SM) Throughput             %        16.90
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.89
    Achieved Active Warps Per SM           warp        11.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.21%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98388
    Total DRAM Elapsed Cycles        cycle      1801216
    Average L1 Active Cycles         cycle     27675.02
    Total L1 Elapsed Cycles          cycle      4105098
    Average L2 Active Cycles         cycle     23093.25
    Total L2 Elapsed Cycles          cycle      1036332
    Average SM Active Cycles         cycle     27675.02
    Total SM Elapsed Cycles          cycle      4105098
    Average SMSP Active Cycles       cycle     27183.11
    Total SMSP Elapsed Cycles        cycle     16420392
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.804%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.89% above the average, while the minimum instance value is 16.87% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.35%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.67% above the average, while the minimum instance value is 18.17% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.804%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.89% above the average, while the minimum instance value is 16.87% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31757
    Memory Throughput                   %        66.41
    DRAM Throughput                     %        66.41
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.91
    L2 Cache Throughput                 %        29.04
    SM Active Cycles                cycle     27288.42
    Compute (SM) Throughput             %        16.52
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.87
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.27%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1777664
    Average L1 Active Cycles         cycle     27288.42
    Total L1 Elapsed Cycles          cycle      4198794
    Average L2 Active Cycles         cycle     23053.19
    Total L2 Elapsed Cycles          cycle      1013076
    Average SM Active Cycles         cycle     27288.42
    Total SM Elapsed Cycles          cycle      4198794
    Average SMSP Active Cycles       cycle     27236.02
    Total SMSP Elapsed Cycles        cycle     16795176
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.144%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.20% above the average, while the minimum instance value is 16.19% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31942
    Memory Throughput                   %        66.03
    DRAM Throughput                     %        66.03
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.97
    L2 Cache Throughput                 %        28.90
    SM Active Cycles                cycle     27239.41
    Compute (SM) Throughput             %        16.70
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.75
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.51%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1787904
    Average L1 Active Cycles         cycle     27239.41
    Total L1 Elapsed Cycles          cycle      4155042
    Average L2 Active Cycles         cycle     23081.08
    Total L2 Elapsed Cycles          cycle      1017972
    Average SM Active Cycles         cycle     27239.41
    Total SM Elapsed Cycles          cycle      4155042
    Average SMSP Active Cycles       cycle     27318.99
    Total SMSP Elapsed Cycles        cycle     16620168
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.795%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.91% above the average, while the minimum instance value is 17.12% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.898%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.01% above the average, while the minimum instance value is 14.14% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.795%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.91% above the average, while the minimum instance value is 17.12% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117514
    Memory Throughput                   %        91.18
    DRAM Throughput                     %        91.18
    Duration                      usecond        52.74
    L1/TEX Cache Throughput             %        10.57
    L2 Cache Throughput                 %        39.61
    SM Active Cycles                cycle    109061.24
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.54
    Achieved Active Warps Per SM           warp        43.94
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491812
    Total DRAM Elapsed Cycles        cycle      6472704
    Average L1 Active Cycles         cycle    109061.24
    Total L1 Elapsed Cycles          cycle     14984354
    Average L2 Active Cycles         cycle     97892.06
    Total L2 Elapsed Cycles          cycle      3723192
    Average SM Active Cycles         cycle    109061.24
    Total SM Elapsed Cycles          cycle     14984354
    Average SMSP Active Cycles       cycle    108298.70
    Total SMSP Elapsed Cycles        cycle     59937416
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32959
    Memory Throughput                   %        64.92
    DRAM Throughput                     %        64.92
    Duration                      usecond        14.85
    L1/TEX Cache Throughput             %        27.62
    L2 Cache Throughput                 %        28.16
    SM Active Cycles                cycle     27581.11
    Compute (SM) Throughput             %        17.00
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.50
    Achieved Active Warps Per SM           warp        11.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51%                                                                                       
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1818624
    Average L1 Active Cycles         cycle     27581.11
    Total L1 Elapsed Cycles          cycle      4080158
    Average L2 Active Cycles         cycle     22827.61
    Total L2 Elapsed Cycles          cycle      1044576
    Average SM Active Cycles         cycle     27581.11
    Total SM Elapsed Cycles          cycle      4080158
    Average SMSP Active Cycles       cycle     27266.24
    Total SMSP Elapsed Cycles        cycle     16320632
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.275%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.41% above the average, while the minimum instance value is 16.30% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.951%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.96% above the average, while the minimum instance value is 15.99% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.275%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.41% above the average, while the minimum instance value is 16.30% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32466
    Memory Throughput                   %        66.03
    DRAM Throughput                     %        66.03
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.60
    L2 Cache Throughput                 %        28.60
    SM Active Cycles                cycle     27589.55
    Compute (SM) Throughput             %        17.21
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.68
    Achieved Active Warps Per SM           warp        11.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.63%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1787904
    Average L1 Active Cycles         cycle     27589.55
    Total L1 Elapsed Cycles          cycle      4032138
    Average L2 Active Cycles         cycle     22933.42
    Total L2 Elapsed Cycles          cycle      1028592
    Average SM Active Cycles         cycle     27589.55
    Total SM Elapsed Cycles          cycle      4032138
    Average SMSP Active Cycles       cycle     27378.18
    Total SMSP Elapsed Cycles        cycle     16128552
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.538%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.32% above the average, while the minimum instance value is 13.75% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.538%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.32% above the average, while the minimum instance value is 13.75% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31577
    Memory Throughput                   %        66.84
    DRAM Throughput                     %        66.84
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.94
    L2 Cache Throughput                 %        29.24
    SM Active Cycles                cycle     27247.18
    Compute (SM) Throughput             %        17.17
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.87
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.26%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1766400
    Average L1 Active Cycles         cycle     27247.18
    Total L1 Elapsed Cycles          cycle      4040016
    Average L2 Active Cycles         cycle     22769.28
    Total L2 Elapsed Cycles          cycle      1006200
    Average SM Active Cycles         cycle     27247.18
    Total SM Elapsed Cycles          cycle      4040016
    Average SMSP Active Cycles       cycle     27144.05
    Total SMSP Elapsed Cycles        cycle     16160064
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.135%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.46% above the average, while the minimum instance value is 14.57% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31954
    Memory Throughput                   %        66.14
    DRAM Throughput                     %        66.14
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        28.06
    L2 Cache Throughput                 %        28.90
    SM Active Cycles                cycle     27152.41
    Compute (SM) Throughput             %        17.05
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.37
    Achieved Active Warps Per SM           warp        11.70
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.26%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27152.41
    Total L1 Elapsed Cycles          cycle      4068360
    Average L2 Active Cycles         cycle     23045.97
    Total L2 Elapsed Cycles          cycle      1017792
    Average SM Active Cycles         cycle     27152.41
    Total SM Elapsed Cycles          cycle      4068360
    Average SMSP Active Cycles       cycle     27178.82
    Total SMSP Elapsed Cycles        cycle     16273440
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.08%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.12% above the average, while the minimum instance value is 18.62% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.574%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.86% above the average, while the minimum instance value is 18.58% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.08%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.12% above the average, while the minimum instance value is 18.62% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.11
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9751
    Memory Throughput                   %         5.87
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.90
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      4029.91
    Compute (SM) Throughput             %         9.08
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp        11.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.43%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      4029.91
    Total L1 Elapsed Cycles          cycle      1221824
    Average L2 Active Cycles         cycle        87.69
    Total L2 Elapsed Cycles          cycle       308376
    Average SM Active Cycles         cycle      4029.91
    Total SM Elapsed Cycles          cycle      1221824
    Average SMSP Active Cycles       cycle      3470.51
    Total SMSP Elapsed Cycles        cycle      4887296
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.474%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.07% above the average, while the minimum instance value is 24.19% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.724%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.49% above the average, while the minimum instance value is 26.44% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.474%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.07% above the average, while the minimum instance value is 24.19% below the      
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118478
    Memory Throughput                   %        91.00
    DRAM Throughput                     %        91.00
    Duration                      usecond        53.06
    L1/TEX Cache Throughput             %        10.37
    L2 Cache Throughput                 %        39.32
    SM Active Cycles                cycle    111185.34
    Compute (SM) Throughput             %        10.07
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.22
    Achieved Active Warps Per SM           warp        43.78
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494098.67
    Total DRAM Elapsed Cycles        cycle      6515712
    Average L1 Active Cycles         cycle    111185.34
    Total L1 Elapsed Cycles          cycle     14964970
    Average L2 Active Cycles         cycle     97956.53
    Total L2 Elapsed Cycles          cycle      3750300
    Average SM Active Cycles         cycle    111185.34
    Total SM Elapsed Cycles          cycle     14964970
    Average SMSP Active Cycles       cycle    109423.05
    Total SMSP Elapsed Cycles        cycle     59859880
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.18
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32530
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.41
    L2 Cache Throughput                 %        28.50
    SM Active Cycles                cycle     27800.22
    Compute (SM) Throughput             %        17.17
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.28
    Achieved Active Warps Per SM           warp        11.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.45%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27800.22
    Total L1 Elapsed Cycles          cycle      4040218
    Average L2 Active Cycles         cycle     22844.03
    Total L2 Elapsed Cycles          cycle      1032084
    Average SM Active Cycles         cycle     27800.22
    Total SM Elapsed Cycles          cycle      4040218
    Average SMSP Active Cycles       cycle     27026.63
    Total SMSP Elapsed Cycles        cycle     16160872
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.238%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.95% above the average, while the minimum instance value is 10.65% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.859%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.01% above the average, while the minimum instance value is 12.40% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.238%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.95% above the average, while the minimum instance value is 10.65% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31953
    Memory Throughput                   %        66.14
    DRAM Throughput                     %        66.14
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        29.02
    SM Active Cycles                cycle     27213.27
    Compute (SM) Throughput             %        17.14
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.29
    Achieved Active Warps Per SM           warp        12.14
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.43%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27213.27
    Total L1 Elapsed Cycles          cycle      4048630
    Average L2 Active Cycles         cycle     22973.50
    Total L2 Elapsed Cycles          cycle      1017252
    Average SM Active Cycles         cycle     27213.27
    Total SM Elapsed Cycles          cycle      4048630
    Average SMSP Active Cycles       cycle     27074.02
    Total SMSP Elapsed Cycles        cycle     16194520
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.406%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.28% above the average, while the minimum instance value is 14.98% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.492%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.58% above the average, while the minimum instance value is 23.06% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.406%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.28% above the average, while the minimum instance value is 14.98% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32509
    Memory Throughput                   %        65.14
    DRAM Throughput                     %        65.14
    Duration                      usecond        14.82
    L1/TEX Cache Throughput             %        28.03
    L2 Cache Throughput                 %        28.42
    SM Active Cycles                cycle     27177.08
    Compute (SM) Throughput             %        17.20
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.76
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.47%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1812480
    Average L1 Active Cycles         cycle     27177.08
    Total L1 Elapsed Cycles          cycle      4034238
    Average L2 Active Cycles         cycle     22942.97
    Total L2 Elapsed Cycles          cycle      1034928
    Average SM Active Cycles         cycle     27177.08
    Total SM Elapsed Cycles          cycle      4034238
    Average SMSP Active Cycles       cycle     27044.28
    Total SMSP Elapsed Cycles        cycle     16136952
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.112%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.25% above the average, while the minimum instance value is 20.46% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.068%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.24% above the average, while the minimum instance value is 19.25% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.112%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.25% above the average, while the minimum instance value is 20.46% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.13
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9759
    Memory Throughput                   %         5.86
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.93
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4019.88
    Compute (SM) Throughput             %         9.08
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.77
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.46%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       333.33
    Total DRAM Elapsed Cycles        cycle       536576
    Average L1 Active Cycles         cycle      4019.88
    Total L1 Elapsed Cycles          cycle      1223988
    Average L2 Active Cycles         cycle        85.33
    Total L2 Elapsed Cycles          cycle       308952
    Average SM Active Cycles         cycle      4019.88
    Total SM Elapsed Cycles          cycle      1223988
    Average SMSP Active Cycles       cycle      3470.26
    Total SMSP Elapsed Cycles        cycle      4895952
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.247%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.62% above the average, while the minimum instance value is 24.30% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.721%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.52% above the average, while the minimum instance value is 27.44% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.247%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.62% above the average, while the minimum instance value is 24.30% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32482
    Memory Throughput                   %        66.14
    DRAM Throughput                     %        66.14
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.70
    L2 Cache Throughput                 %        28.58
    SM Active Cycles                cycle     27499.89
    Compute (SM) Throughput             %        17.12
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.86
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.29%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27499.89
    Total L1 Elapsed Cycles          cycle      4051794
    Average L2 Active Cycles         cycle     22930.44
    Total L2 Elapsed Cycles          cycle      1029096
    Average SM Active Cycles         cycle     27499.89
    Total SM Elapsed Cycles          cycle      4051794
    Average SMSP Active Cycles       cycle     27078.42
    Total SMSP Elapsed Cycles        cycle     16207176
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.468%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.45% above the average, while the minimum instance value is 13.64% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.626%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.75% above the average, while the minimum instance value is 14.50% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.468%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.45% above the average, while the minimum instance value is 13.64% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117176
    Memory Throughput                   %        91.57
    DRAM Throughput                     %        91.57
    Duration                      usecond        52.48
    L1/TEX Cache Throughput             %        10.58
    L2 Cache Throughput                 %        39.75
    SM Active Cycles                cycle    108937.79
    Compute (SM) Throughput             %         9.94
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.67
    Achieved Active Warps Per SM           warp        44.00
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491632
    Total DRAM Elapsed Cycles        cycle      6443008
    Average L1 Active Cycles         cycle    108937.79
    Total L1 Elapsed Cycles          cycle     15171764
    Average L2 Active Cycles         cycle     98065.58
    Total L2 Elapsed Cycles          cycle      3709296
    Average SM Active Cycles         cycle    108937.79
    Total SM Elapsed Cycles          cycle     15171764
    Average SMSP Active Cycles       cycle    108495.19
    Total SMSP Elapsed Cycles        cycle     60687056
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32129
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        28.77
    SM Active Cycles                cycle     27204.41
    Compute (SM) Throughput             %        16.73
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.93
    Achieved Active Warps Per SM           warp        11.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.14%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27204.41
    Total L1 Elapsed Cycles          cycle      4147662
    Average L2 Active Cycles         cycle     22951.81
    Total L2 Elapsed Cycles          cycle      1022544
    Average SM Active Cycles         cycle     27204.41
    Total SM Elapsed Cycles          cycle      4147662
    Average SMSP Active Cycles       cycle     27014.45
    Total SMSP Elapsed Cycles        cycle     16590648
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.239%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.24% above the average, while the minimum instance value is 13.41% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.518%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.02% above the average, while the minimum instance value is 17.45% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.239%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.24% above the average, while the minimum instance value is 13.41% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31444
    Memory Throughput                   %        67.19
    DRAM Throughput                     %        67.19
    Duration                      usecond        14.34
    L1/TEX Cache Throughput             %        28.05
    L2 Cache Throughput                 %        29.35
    SM Active Cycles                cycle     27153.84
    Compute (SM) Throughput             %        17.06
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.70
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.6%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1757184
    Average L1 Active Cycles         cycle     27153.84
    Total L1 Elapsed Cycles          cycle      4067222
    Average L2 Active Cycles         cycle     22839.31
    Total L2 Elapsed Cycles          cycle      1002168
    Average SM Active Cycles         cycle     27153.84
    Total SM Elapsed Cycles          cycle      4067222
    Average SMSP Active Cycles       cycle     26921.14
    Total SMSP Elapsed Cycles        cycle     16268888
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.867%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 10.47% above the average, while the minimum instance value is 15.90% below the average.     

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.14
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9752
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.96
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4012.49
    Compute (SM) Throughput             %         9.15
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp        11.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.43%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       330.67
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      4012.49
    Total L1 Elapsed Cycles          cycle      1214156
    Average L2 Active Cycles         cycle        83.47
    Total L2 Elapsed Cycles          cycle       308484
    Average SM Active Cycles         cycle      4012.49
    Total SM Elapsed Cycles          cycle      1214156
    Average SMSP Active Cycles       cycle      3460.74
    Total SMSP Elapsed Cycles        cycle      4856624
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.388%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.83% above the average, while the minimum instance value is 23.94% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.866%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.82% above the average, while the minimum instance value is 26.55% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.388%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.83% above the average, while the minimum instance value is 23.94% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31926
    Memory Throughput                   %        66.99
    DRAM Throughput                     %        66.99
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.85
    L2 Cache Throughput                 %        29.05
    SM Active Cycles                cycle     27361.18
    Compute (SM) Throughput             %        16.89
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.71
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.57%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1762304
    Average L1 Active Cycles         cycle     27361.18
    Total L1 Elapsed Cycles          cycle      4107930
    Average L2 Active Cycles         cycle     22825.08
    Total L2 Elapsed Cycles          cycle      1012536
    Average SM Active Cycles         cycle     27361.18
    Total SM Elapsed Cycles          cycle      4107930
    Average SMSP Active Cycles       cycle     27011.48
    Total SMSP Elapsed Cycles        cycle     16431720
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.524%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.48% above the average, while the minimum instance value is 22.60% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.628%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.69% above the average, while the minimum instance value is 15.31% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.524%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.48% above the average, while the minimum instance value is 22.60% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        31850
    Memory Throughput                   %        67.27
    DRAM Throughput                     %        67.27
    Duration                      usecond        14.30
    L1/TEX Cache Throughput             %        27.86
    L2 Cache Throughput                 %        29.16
    SM Active Cycles                cycle     27351.08
    Compute (SM) Throughput             %        17.22
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.88
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.23%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1755136
    Average L1 Active Cycles         cycle     27351.08
    Total L1 Elapsed Cycles          cycle      4029498
    Average L2 Active Cycles         cycle     22884.03
    Total L2 Elapsed Cycles          cycle      1008828
    Average SM Active Cycles         cycle     27351.08
    Total SM Elapsed Cycles          cycle      4029498
    Average SMSP Active Cycles       cycle     27121.84
    Total SMSP Elapsed Cycles        cycle     16117992
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.281%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.08% above the average, while the minimum instance value is 15.46% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.343%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.20% above the average, while the minimum instance value is 23.14% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.281%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.08% above the average, while the minimum instance value is 15.46% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117672
    Memory Throughput                   %        91.24
    DRAM Throughput                     %        91.24
    Duration                      usecond        52.80
    L1/TEX Cache Throughput             %        10.54
    L2 Cache Throughput                 %        39.56
    SM Active Cycles                cycle    109354.77
    Compute (SM) Throughput             %        10.04
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.22
    Achieved Active Warps Per SM           warp        44.26
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    492781.33
    Total DRAM Elapsed Cycles        cycle      6480896
    Average L1 Active Cycles         cycle    109354.77
    Total L1 Elapsed Cycles          cycle     15016494
    Average L2 Active Cycles         cycle        98149
    Total L2 Elapsed Cycles          cycle      3727440
    Average SM Active Cycles         cycle    109354.77
    Total SM Elapsed Cycles          cycle     15016494
    Average SMSP Active Cycles       cycle    108259.20
    Total SMSP Elapsed Cycles        cycle     60065976
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.199%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.63% above the average, while the minimum instance value is 20.45% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32003
    Memory Throughput                   %        66.07
    DRAM Throughput                     %        66.07
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.22
    L2 Cache Throughput                 %        28.87
    SM Active Cycles                cycle     26999.68
    Compute (SM) Throughput             %        16.87
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.77
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.47%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1786880
    Average L1 Active Cycles         cycle     26999.68
    Total L1 Elapsed Cycles          cycle      4111368
    Average L2 Active Cycles         cycle     22983.36
    Total L2 Elapsed Cycles          cycle      1018980
    Average SM Active Cycles         cycle     26999.68
    Total SM Elapsed Cycles          cycle      4111368
    Average SMSP Active Cycles       cycle     27264.26
    Total SMSP Elapsed Cycles        cycle     16445472
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.741%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.83% above the average, while the minimum instance value is 16.48% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.664%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.85% above the average, while the minimum instance value is 18.17% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.741%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.83% above the average, while the minimum instance value is 16.48% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.13
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9746
    Memory Throughput                   %         5.88
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.01
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3996.61
    Compute (SM) Throughput             %         9.11
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.96
    Achieved Active Warps Per SM           warp        11.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.08%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       333.33
    Total DRAM Elapsed Cycles        cycle       536576
    Average L1 Active Cycles         cycle      3996.61
    Total L1 Elapsed Cycles          cycle      1219028
    Average L2 Active Cycles         cycle        88.44
    Total L2 Elapsed Cycles          cycle       308304
    Average SM Active Cycles         cycle      3996.61
    Total SM Elapsed Cycles          cycle      1219028
    Average SMSP Active Cycles       cycle      3460.38
    Total SMSP Elapsed Cycles        cycle      4876112
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.966%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 18.98% above the average, while the minimum instance value is 24.44% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.681%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.39% above the average, while the minimum instance value is 27.09% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.966%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 18.98% above the average, while the minimum instance value is 24.44% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32445
    Memory Throughput                   %        65.47
    DRAM Throughput                     %        65.47
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        27.97
    L2 Cache Throughput                 %        28.52
    SM Active Cycles                cycle     27235.67
    Compute (SM) Throughput             %        17.08
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.94
    Achieved Active Warps Per SM           warp        11.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.12%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1803264
    Average L1 Active Cycles         cycle     27235.67
    Total L1 Elapsed Cycles          cycle      4061152
    Average L2 Active Cycles         cycle     22977.69
    Total L2 Elapsed Cycles          cycle      1031292
    Average SM Active Cycles         cycle     27235.67
    Total SM Elapsed Cycles          cycle      4061152
    Average SMSP Active Cycles       cycle     27231.03
    Total SMSP Elapsed Cycles        cycle     16244608
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.918%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.06% above the average, while the minimum instance value is 17.24% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.028%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.02% above the average, while the minimum instance value is 13.12% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.918%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.06% above the average, while the minimum instance value is 17.24% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32232
    Memory Throughput                   %        66.26
    DRAM Throughput                     %        66.26
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.81
    L2 Cache Throughput                 %        28.76
    SM Active Cycles                cycle     27393.80
    Compute (SM) Throughput             %        16.56
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.65
    Achieved Active Warps Per SM           warp        11.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.7%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1781760
    Average L1 Active Cycles         cycle     27393.80
    Total L1 Elapsed Cycles          cycle      4188338
    Average L2 Active Cycles         cycle     22890.83
    Total L2 Elapsed Cycles          cycle      1022688
    Average SM Active Cycles         cycle     27393.80
    Total SM Elapsed Cycles          cycle      4188338
    Average SMSP Active Cycles       cycle     26922.29
    Total SMSP Elapsed Cycles        cycle     16753352
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.699%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.81% above the average, while the minimum instance value is 23.75% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.785%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.25% above the average, while the minimum instance value is 18.24% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.699%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.81% above the average, while the minimum instance value is 23.75% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32118
    Memory Throughput                   %        65.85
    DRAM Throughput                     %        65.85
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.93
    L2 Cache Throughput                 %        28.79
    SM Active Cycles                cycle     27276.59
    Compute (SM) Throughput             %        16.93
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.90
    Achieved Active Warps Per SM           warp        11.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.19%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98392
    Total DRAM Elapsed Cycles        cycle      1793024
    Average L1 Active Cycles         cycle     27276.59
    Total L1 Elapsed Cycles          cycle      4099002
    Average L2 Active Cycles         cycle     23085.67
    Total L2 Elapsed Cycles          cycle      1021932
    Average SM Active Cycles         cycle     27276.59
    Total SM Elapsed Cycles          cycle      4099002
    Average SMSP Active Cycles       cycle     27735.86
    Total SMSP Elapsed Cycles        cycle     16396008
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.485%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.44% above the average, while the minimum instance value is 17.54% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.662%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.54% above the average, while the minimum instance value is 12.36% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.485%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.44% above the average, while the minimum instance value is 17.54% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       118157
    Memory Throughput                   %        91.14
    DRAM Throughput                     %        91.14
    Duration                      usecond        53.02
    L1/TEX Cache Throughput             %        10.42
    L2 Cache Throughput                 %        39.40
    SM Active Cycles                cycle    110620.96
    Compute (SM) Throughput             %        10.10
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.17
    Achieved Active Warps Per SM           warp        43.76
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       494344
    Total DRAM Elapsed Cycles        cycle      6508544
    Average L1 Active Cycles         cycle    110620.96
    Total L1 Elapsed Cycles          cycle     14918650
    Average L2 Active Cycles         cycle     98080.67
    Total L2 Elapsed Cycles          cycle      3742524
    Average SM Active Cycles         cycle    110620.96
    Total SM Elapsed Cycles          cycle     14918650
    Average SMSP Active Cycles       cycle    109062.61
    Total SMSP Elapsed Cycles        cycle     59674600
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.09
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9736
    Memory Throughput                   %         5.93
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.06
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3983.47
    Compute (SM) Throughput             %         9.18
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.86
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.28%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       534528
    Average L1 Active Cycles         cycle      3983.47
    Total L1 Elapsed Cycles          cycle      1207866
    Average L2 Active Cycles         cycle        83.47
    Total L2 Elapsed Cycles          cycle       307980
    Average SM Active Cycles         cycle      3983.47
    Total SM Elapsed Cycles          cycle      1207866
    Average SMSP Active Cycles       cycle      3466.42
    Total SMSP Elapsed Cycles        cycle      4831464
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.345%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.77% above the average, while the minimum instance value is 23.96% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.162%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.50% above the average, while the minimum instance value is 27.10% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.345%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.77% above the average, while the minimum instance value is 23.96% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        33341
    Memory Throughput                   %        64.26
    DRAM Throughput                     %        64.26
    Duration                      usecond        14.98
    L1/TEX Cache Throughput             %        27.68
    L2 Cache Throughput                 %        27.84
    SM Active Cycles                cycle     27520.32
    Compute (SM) Throughput             %        16.98
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.71
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.58%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1837056
    Average L1 Active Cycles         cycle     27520.32
    Total L1 Elapsed Cycles          cycle      4084788
    Average L2 Active Cycles         cycle     22917.44
    Total L2 Elapsed Cycles          cycle      1056564
    Average SM Active Cycles         cycle     27520.32
    Total SM Elapsed Cycles          cycle      4084788
    Average SMSP Active Cycles       cycle     27085.34
    Total SMSP Elapsed Cycles        cycle     16339152
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.012%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.29% above the average, while the minimum instance value is 26.74% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.433%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.76% above the average, while the minimum instance value is 22.51% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.012%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.29% above the average, while the minimum instance value is 26.74% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32174
    Memory Throughput                   %        66.57
    DRAM Throughput                     %        66.57
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.72
    L2 Cache Throughput                 %        28.85
    SM Active Cycles                cycle     27477.99
    Compute (SM) Throughput             %        17.01
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.73
    Achieved Active Warps Per SM           warp        11.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.54%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1773568
    Average L1 Active Cycles         cycle     27477.99
    Total L1 Elapsed Cycles          cycle      4078340
    Average L2 Active Cycles         cycle     22951.69
    Total L2 Elapsed Cycles          cycle      1019700
    Average SM Active Cycles         cycle     27477.99
    Total SM Elapsed Cycles          cycle      4078340
    Average SMSP Active Cycles       cycle     27139.31
    Total SMSP Elapsed Cycles        cycle     16313360
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.936%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.88% above the average, while the minimum instance value is 15.81% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.102%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.51% above the average, while the minimum instance value is 14.01% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.936%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.88% above the average, while the minimum instance value is 15.81% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31846
    Memory Throughput                   %        66.41
    DRAM Throughput                     %        66.41
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        28.08
    L2 Cache Throughput                 %        29.00
    SM Active Cycles                cycle     27115.41
    Compute (SM) Throughput             %        17.27
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.18
    Achieved Active Warps Per SM           warp        12.08
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.65%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1777664
    Average L1 Active Cycles         cycle     27115.41
    Total L1 Elapsed Cycles          cycle      4016954
    Average L2 Active Cycles         cycle     22927.92
    Total L2 Elapsed Cycles          cycle      1014444
    Average SM Active Cycles         cycle     27115.41
    Total SM Elapsed Cycles          cycle      4016954
    Average SMSP Active Cycles       cycle     27141.34
    Total SMSP Elapsed Cycles        cycle     16067816
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31600
    Memory Throughput                   %        66.84
    DRAM Throughput                     %        66.84
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        28.17
    L2 Cache Throughput                 %        29.21
    SM Active Cycles                cycle     27033.81
    Compute (SM) Throughput             %        17.08
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.90
    Achieved Active Warps Per SM           warp        11.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.19%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1766400
    Average L1 Active Cycles         cycle     27033.81
    Total L1 Elapsed Cycles          cycle      4061654
    Average L2 Active Cycles         cycle     22836.64
    Total L2 Elapsed Cycles          cycle      1006956
    Average SM Active Cycles         cycle     27033.81
    Total SM Elapsed Cycles          cycle      4061654
    Average SMSP Active Cycles       cycle     27135.26
    Total SMSP Elapsed Cycles        cycle     16246616
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.111%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.00% above the average, while the minimum instance value is 13.71% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.111%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.00% above the average, while the minimum instance value is 13.71% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       116850
    Memory Throughput                   %        91.63
    DRAM Throughput                     %        91.63
    Duration                      usecond        52.42
    L1/TEX Cache Throughput             %        10.59
    L2 Cache Throughput                 %        39.83
    SM Active Cycles                cycle    108914.89
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.61
    Achieved Active Warps Per SM           warp        44.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491674.67
    Total DRAM Elapsed Cycles        cycle      6438912
    Average L1 Active Cycles         cycle    108914.89
    Total L1 Elapsed Cycles          cycle     14979414
    Average L2 Active Cycles         cycle     98215.06
    Total L2 Elapsed Cycles          cycle      3701844
    Average SM Active Cycles         cycle    108914.89
    Total SM Elapsed Cycles          cycle     14979414
    Average SMSP Active Cycles       cycle    108644.44
    Total SMSP Elapsed Cycles        cycle     59917656
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32514
    Memory Throughput                   %        65.32
    DRAM Throughput                     %        65.32
    Duration                      usecond        14.75
    L1/TEX Cache Throughput             %        28.02
    L2 Cache Throughput                 %        28.45
    SM Active Cycles                cycle     27174.43
    Compute (SM) Throughput             %        16.93
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp        11.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.4%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1807360
    Average L1 Active Cycles         cycle     27174.43
    Total L1 Elapsed Cycles          cycle      4099020
    Average L2 Active Cycles         cycle     22944.86
    Total L2 Elapsed Cycles          cycle      1033992
    Average SM Active Cycles         cycle     27174.43
    Total SM Elapsed Cycles          cycle      4099020
    Average SMSP Active Cycles       cycle     27099.87
    Total SMSP Elapsed Cycles        cycle     16396080
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.615%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.80% above the average, while the minimum instance value is 18.35% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.615%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.80% above the average, while the minimum instance value is 18.35% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32238
    Memory Throughput                   %        66.53
    DRAM Throughput                     %        66.53
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.77
    L2 Cache Throughput                 %        28.80
    SM Active Cycles                cycle     27439.16
    Compute (SM) Throughput             %        16.38
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.67
    Achieved Active Warps Per SM           warp        11.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.66%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     27439.16
    Total L1 Elapsed Cycles          cycle      4236302
    Average L2 Active Cycles         cycle     22933.17
    Total L2 Elapsed Cycles          cycle      1021500
    Average SM Active Cycles         cycle     27439.16
    Total SM Elapsed Cycles          cycle      4236302
    Average SMSP Active Cycles       cycle     26965.11
    Total SMSP Elapsed Cycles        cycle     16945208
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.089%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.34% above the average, while the minimum instance value is 15.15% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.236%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.65% above the average, while the minimum instance value is 16.93% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.089%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.34% above the average, while the minimum instance value is 15.15% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31933
    Memory Throughput                   %        66.11
    DRAM Throughput                     %        66.11
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.00
    L2 Cache Throughput                 %        28.91
    SM Active Cycles                cycle     27224.25
    Compute (SM) Throughput             %        17.02
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.85
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.31%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1785856
    Average L1 Active Cycles         cycle     27224.25
    Total L1 Elapsed Cycles          cycle      4077296
    Average L2 Active Cycles         cycle     23062.14
    Total L2 Elapsed Cycles          cycle      1017540
    Average SM Active Cycles         cycle     27224.25
    Total SM Elapsed Cycles          cycle      4077296
    Average SMSP Active Cycles       cycle     27180.80
    Total SMSP Elapsed Cycles        cycle     16309184
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.807%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.79% above the average, while the minimum instance value is 16.60% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.35%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.44% above the average, while the minimum instance value is 14.68% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.807%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.79% above the average, while the minimum instance value is 16.60% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31959
    Memory Throughput                   %        65.99
    DRAM Throughput                     %        65.99
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.26
    L2 Cache Throughput                 %        28.89
    SM Active Cycles                cycle     26966.04
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1788928
    Average L1 Active Cycles         cycle     26966.04
    Total L1 Elapsed Cycles          cycle      4073334
    Average L2 Active Cycles         cycle     22938.89
    Total L2 Elapsed Cycles          cycle      1018296
    Average SM Active Cycles         cycle     26966.04
    Total SM Elapsed Cycles          cycle      4073334
    Average SMSP Active Cycles       cycle     27333.45
    Total SMSP Elapsed Cycles        cycle     16293336
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.146%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.25% above the average, while the minimum instance value is 22.22% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.661%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.59% above the average, while the minimum instance value is 17.93% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.146%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.25% above the average, while the minimum instance value is 22.22% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32437
    Memory Throughput                   %        65.47
    DRAM Throughput                     %        65.47
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        28.06
    L2 Cache Throughput                 %        28.52
    SM Active Cycles                cycle     27165.14
    Compute (SM) Throughput             %        17.15
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.72
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1803264
    Average L1 Active Cycles         cycle     27165.14
    Total L1 Elapsed Cycles          cycle      4045310
    Average L2 Active Cycles         cycle     23134.03
    Total L2 Elapsed Cycles          cycle      1031652
    Average SM Active Cycles         cycle     27165.14
    Total SM Elapsed Cycles          cycle      4045310
    Average SMSP Active Cycles       cycle     27236.29
    Total SMSP Elapsed Cycles        cycle     16181240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.792%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.90% above the average, while the minimum instance value is 17.82% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.997%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.12% above the average, while the minimum instance value is 17.07% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.792%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.90% above the average, while the minimum instance value is 17.82% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117191
    Memory Throughput                   %        91.57
    DRAM Throughput                     %        91.57
    Duration                      usecond        52.48
    L1/TEX Cache Throughput             %        10.48
    L2 Cache Throughput                 %        39.74
    SM Active Cycles                cycle    110049.17
    Compute (SM) Throughput             %        10.01
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.35
    Achieved Active Warps Per SM           warp        43.85
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491813.33
    Total DRAM Elapsed Cycles        cycle      6445056
    Average L1 Active Cycles         cycle    110049.17
    Total L1 Elapsed Cycles          cycle     15056486
    Average L2 Active Cycles         cycle     97919.39
    Total L2 Elapsed Cycles          cycle      3710340
    Average SM Active Cycles         cycle    110049.17
    Total SM Elapsed Cycles          cycle     15056486
    Average SMSP Active Cycles       cycle    108801.75
    Total SMSP Elapsed Cycles        cycle     60225944
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31834
    Memory Throughput                   %        67.04
    DRAM Throughput                     %        67.04
    Duration                      usecond        14.37
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        29.13
    SM Active Cycles                cycle     27214.04
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.76
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.48%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1761280
    Average L1 Active Cycles         cycle     27214.04
    Total L1 Elapsed Cycles          cycle      4072902
    Average L2 Active Cycles         cycle     22850.50
    Total L2 Elapsed Cycles          cycle      1009944
    Average SM Active Cycles         cycle     27214.04
    Total SM Elapsed Cycles          cycle      4072902
    Average SMSP Active Cycles       cycle     26936.04
    Total SMSP Elapsed Cycles        cycle     16291608
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.165%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.04% above the average, while the minimum instance value is 16.34% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.139%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.07% above the average, while the minimum instance value is 14.52% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.165%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.04% above the average, while the minimum instance value is 16.34% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31679
    Memory Throughput                   %        66.72
    DRAM Throughput                     %        66.72
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        28.05
    L2 Cache Throughput                 %        29.13
    SM Active Cycles                cycle     27159.71
    Compute (SM) Throughput             %        17.07
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.85
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.31%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1769472
    Average L1 Active Cycles         cycle     27159.71
    Total L1 Elapsed Cycles          cycle      4064258
    Average L2 Active Cycles         cycle     23092.11
    Total L2 Elapsed Cycles          cycle      1009872
    Average SM Active Cycles         cycle     27159.71
    Total SM Elapsed Cycles          cycle      4064258
    Average SMSP Active Cycles       cycle     27440.39
    Total SMSP Elapsed Cycles        cycle     16257032
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.042%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.89% above the average, while the minimum instance value is 13.35% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.744%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.65% above the average, while the minimum instance value is 14.53% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.042%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.89% above the average, while the minimum instance value is 13.35% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31716
    Memory Throughput                   %        66.68
    DRAM Throughput                     %        66.68
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        28.16
    L2 Cache Throughput                 %        29.14
    SM Active Cycles                cycle     27058.88
    Compute (SM) Throughput             %        17.20
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp        11.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.44%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1770496
    Average L1 Active Cycles         cycle     27058.88
    Total L1 Elapsed Cycles          cycle      4032772
    Average L2 Active Cycles         cycle     22834.42
    Total L2 Elapsed Cycles          cycle      1009548
    Average SM Active Cycles         cycle     27058.88
    Total SM Elapsed Cycles          cycle      4032772
    Average SMSP Active Cycles       cycle     27149.51
    Total SMSP Elapsed Cycles        cycle     16131088
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.491%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.53% above the average, while the minimum instance value is 16.56% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31691
    Memory Throughput                   %        66.68
    DRAM Throughput                     %        66.68
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        27.97
    L2 Cache Throughput                 %        29.14
    SM Active Cycles                cycle     27238.89
    Compute (SM) Throughput             %        17.07
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.54
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.92%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1770496
    Average L1 Active Cycles         cycle     27238.89
    Total L1 Elapsed Cycles          cycle      4064282
    Average L2 Active Cycles         cycle     22802.17
    Total L2 Elapsed Cycles          cycle      1009332
    Average SM Active Cycles         cycle     27238.89
    Total SM Elapsed Cycles          cycle      4064282
    Average SMSP Active Cycles       cycle     27191.04
    Total SMSP Elapsed Cycles        cycle     16257128
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.11
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9744
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.04
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3987.63
    Compute (SM) Throughput             %         9.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.71
    Achieved Active Warps Per SM           warp        12.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.58%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      3987.63
    Total L1 Elapsed Cycles          cycle      1215242
    Average L2 Active Cycles         cycle        82.14
    Total L2 Elapsed Cycles          cycle       308448
    Average SM Active Cycles         cycle      3987.63
    Total SM Elapsed Cycles          cycle      1215242
    Average SMSP Active Cycles       cycle      3464.93
    Total SMSP Elapsed Cycles        cycle      4860968
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.591%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.45% above the average, while the minimum instance value is 24.14% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.636%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.18% above the average, while the minimum instance value is 27.24% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.591%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.45% above the average, while the minimum instance value is 24.14% below the      
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118219
    Memory Throughput                   %        91.25
    DRAM Throughput                     %        91.25
    Duration                      usecond        52.96
    L1/TEX Cache Throughput             %        10.34
    L2 Cache Throughput                 %        39.41
    SM Active Cycles                cycle    111492.62
    Compute (SM) Throughput             %        10.00
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.71
    Achieved Active Warps Per SM           warp        43.54
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494297.33
    Total DRAM Elapsed Cycles        cycle      6500352
    Average L1 Active Cycles         cycle    111492.62
    Total L1 Elapsed Cycles          cycle     15066898
    Average L2 Active Cycles         cycle     98158.78
    Total L2 Elapsed Cycles          cycle      3742092
    Average SM Active Cycles         cycle    111492.62
    Total SM Elapsed Cycles          cycle     15066898
    Average SMSP Active Cycles       cycle    108778.42
    Total SMSP Elapsed Cycles        cycle     60267592
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32491
    Memory Throughput                   %        65.03
    DRAM Throughput                     %        65.03
    Duration                      usecond        14.82
    L1/TEX Cache Throughput             %        27.64
    L2 Cache Throughput                 %        28.42
    SM Active Cycles                cycle     27555.70
    Compute (SM) Throughput             %        17.26
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.72
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98385.33
    Total DRAM Elapsed Cycles        cycle      1815552
    Average L1 Active Cycles         cycle     27555.70
    Total L1 Elapsed Cycles          cycle      4018614
    Average L2 Active Cycles         cycle     22936.50
    Total L2 Elapsed Cycles          cycle      1034928
    Average SM Active Cycles         cycle     27555.70
    Total SM Elapsed Cycles          cycle      4018614
    Average SMSP Active Cycles       cycle     27202.62
    Total SMSP Elapsed Cycles        cycle     16074456
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.876%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.70% above the average, while the minimum instance value is 15.94% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.194%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.15% above the average, while the minimum instance value is 22.40% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.876%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.70% above the average, while the minimum instance value is 15.94% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31850
    Memory Throughput                   %        66.39
    DRAM Throughput                     %        66.39
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.98
    L2 Cache Throughput                 %        28.99
    SM Active Cycles                cycle     27224.25
    Compute (SM) Throughput             %        17.10
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.64
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.73%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98405.33
    Total DRAM Elapsed Cycles        cycle      1778688
    Average L1 Active Cycles         cycle     27224.25
    Total L1 Elapsed Cycles          cycle      4057678
    Average L2 Active Cycles         cycle     23012.36
    Total L2 Elapsed Cycles          cycle      1014804
    Average SM Active Cycles         cycle     27224.25
    Total SM Elapsed Cycles          cycle      4057678
    Average SMSP Active Cycles       cycle     26929.57
    Total SMSP Elapsed Cycles        cycle     16230712
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.734%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.75% above the average, while the minimum instance value is 23.21% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31943
    Memory Throughput                   %        66.45
    DRAM Throughput                     %        66.45
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.90
    L2 Cache Throughput                 %        28.97
    SM Active Cycles                cycle     27302.13
    Compute (SM) Throughput             %        17.13
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.28
    Achieved Active Warps Per SM           warp        12.14
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.44%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1776640
    Average L1 Active Cycles         cycle     27302.13
    Total L1 Elapsed Cycles          cycle      4050546
    Average L2 Active Cycles         cycle     22890.17
    Total L2 Elapsed Cycles          cycle      1015308
    Average SM Active Cycles         cycle     27302.13
    Total SM Elapsed Cycles          cycle      4050546
    Average SMSP Active Cycles       cycle     27031.80
    Total SMSP Elapsed Cycles        cycle     16202184
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.787%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.77% above the average, while the minimum instance value is 15.06% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.16
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle         9725
    Memory Throughput                   %         5.81
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.38
    L1/TEX Cache Throughput             %        14.01
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3998.34
    Compute (SM) Throughput             %         8.99
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.95
    Achieved Active Warps Per SM           warp        11.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.09%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       534528
    Average L1 Active Cycles         cycle      3998.34
    Total L1 Elapsed Cycles          cycle      1233322
    Average L2 Active Cycles         cycle        83.31
    Total L2 Elapsed Cycles          cycle       307368
    Average SM Active Cycles         cycle      3998.34
    Total SM Elapsed Cycles          cycle      1233322
    Average SMSP Active Cycles       cycle      3451.35
    Total SMSP Elapsed Cycles        cycle      4933288
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.16%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.66% above the average, while the minimum instance value is 24.22% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.854%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.13% above the average, while the minimum instance value is 27.56% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.16%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.66% above the average, while the minimum instance value is 24.22% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32348
    Memory Throughput                   %        66.26
    DRAM Throughput                     %        66.26
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.61
    L2 Cache Throughput                 %        28.70
    SM Active Cycles                cycle     27601.06
    Compute (SM) Throughput             %        16.85
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.69
    Achieved Active Warps Per SM           warp        11.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.61%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1781760
    Average L1 Active Cycles         cycle     27601.06
    Total L1 Elapsed Cycles          cycle      4117618
    Average L2 Active Cycles         cycle     22795.36
    Total L2 Elapsed Cycles          cycle      1025100
    Average SM Active Cycles         cycle     27601.06
    Total SM Elapsed Cycles          cycle      4117618
    Average SMSP Active Cycles       cycle     27058.86
    Total SMSP Elapsed Cycles        cycle     16470472
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.327%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.21% above the average, while the minimum instance value is 13.31% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.003%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.95% above the average, while the minimum instance value is 12.46% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.327%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.21% above the average, while the minimum instance value is 13.31% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117435
    Memory Throughput                   %        91.36
    DRAM Throughput                     %        91.36
    Duration                      usecond        52.58
    L1/TEX Cache Throughput             %        10.53
    L2 Cache Throughput                 %        39.67
    SM Active Cycles                cycle    109534.89
    Compute (SM) Throughput             %        10.05
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.04
    Achieved Active Warps Per SM           warp        43.70
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491632
    Total DRAM Elapsed Cycles        cycle      6457344
    Average L1 Active Cycles         cycle    109534.89
    Total L1 Elapsed Cycles          cycle     15001538
    Average L2 Active Cycles         cycle     98039.58
    Total L2 Elapsed Cycles          cycle      3716964
    Average SM Active Cycles         cycle    109534.89
    Total SM Elapsed Cycles          cycle     15001538
    Average SMSP Active Cycles       cycle    108312.62
    Total SMSP Elapsed Cycles        cycle     60006152
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.124%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.54% above the average, while the minimum instance value is 22.39% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31511
    Memory Throughput                   %        66.99
    DRAM Throughput                     %        66.99
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        28.21
    L2 Cache Throughput                 %        29.27
    SM Active Cycles                cycle     27019.74
    Compute (SM) Throughput             %        16.78
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.19
    Achieved Active Warps Per SM           warp        12.09
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.62%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1762304
    Average L1 Active Cycles         cycle     27019.74
    Total L1 Elapsed Cycles          cycle      4133766
    Average L2 Active Cycles         cycle     22998.06
    Total L2 Elapsed Cycles          cycle      1004940
    Average SM Active Cycles         cycle     27019.74
    Total SM Elapsed Cycles          cycle      4133766
    Average SMSP Active Cycles       cycle     27337.65
    Total SMSP Elapsed Cycles        cycle     16535064
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.726%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.76% above the average, while the minimum instance value is 13.34% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31502
    Memory Throughput                   %        67.38
    DRAM Throughput                     %        67.38
    Duration                      usecond        14.30
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        29.35
    SM Active Cycles                cycle     27207.77
    Compute (SM) Throughput             %        17.23
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.85
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.29%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1752064
    Average L1 Active Cycles         cycle     27207.77
    Total L1 Elapsed Cycles          cycle      4025438
    Average L2 Active Cycles         cycle     22750.61
    Total L2 Elapsed Cycles          cycle      1002168
    Average SM Active Cycles         cycle     27207.77
    Total SM Elapsed Cycles          cycle      4025438
    Average SMSP Active Cycles       cycle     26811.91
    Total SMSP Elapsed Cycles        cycle     16101752
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.16
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9783
    Memory Throughput                   %         5.89
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.82
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4051.16
    Compute (SM) Throughput             %         9.12
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.63
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.74%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       538624
    Average L1 Active Cycles         cycle      4051.16
    Total L1 Elapsed Cycles          cycle      1216630
    Average L2 Active Cycles         cycle        82.72
    Total L2 Elapsed Cycles          cycle       309636
    Average SM Active Cycles         cycle      4051.16
    Total SM Elapsed Cycles          cycle      1216630
    Average SMSP Active Cycles       cycle      3432.96
    Total SMSP Elapsed Cycles        cycle      4866520
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.666%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.33% above the average, while the minimum instance value is 23.11% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.93%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.19% above the average, while the minimum instance value is 27.70% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.666%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.33% above the average, while the minimum instance value is 23.11% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32463
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        28.01
    L2 Cache Throughput                 %        28.55
    SM Active Cycles                cycle     27196.23
    Compute (SM) Throughput             %        17.12
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.45%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27196.23
    Total L1 Elapsed Cycles          cycle      4053094
    Average L2 Active Cycles         cycle     23020.97
    Total L2 Elapsed Cycles          cycle      1030140
    Average SM Active Cycles         cycle     27196.23
    Total SM Elapsed Cycles          cycle      4053094
    Average SMSP Active Cycles       cycle     26914.71
    Total SMSP Elapsed Cycles        cycle     16212376
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.817%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.94% above the average, while the minimum instance value is 20.42% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.248%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.35% above the average, while the minimum instance value is 23.45% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.817%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.94% above the average, while the minimum instance value is 20.42% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31784
    Memory Throughput                   %        66.42
    DRAM Throughput                     %        66.42
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        28.25
    L2 Cache Throughput                 %        29.04
    SM Active Cycles                cycle     26954.02
    Compute (SM) Throughput             %        17.30
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.98
    Achieved Active Warps Per SM           warp        11.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.04%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1777664
    Average L1 Active Cycles         cycle     26954.02
    Total L1 Elapsed Cycles          cycle      4011282
    Average L2 Active Cycles         cycle     22893.31
    Total L2 Elapsed Cycles          cycle      1013040
    Average SM Active Cycles         cycle     26954.02
    Total SM Elapsed Cycles          cycle      4011282
    Average SMSP Active Cycles       cycle     27127.26
    Total SMSP Elapsed Cycles        cycle     16045128
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.345%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.21% above the average, while the minimum instance value is 16.10% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.002%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.78% above the average, while the minimum instance value is 17.90% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.345%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.21% above the average, while the minimum instance value is 16.10% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117718
    Memory Throughput                   %        91.24
    DRAM Throughput                     %        91.24
    Duration                      usecond        52.80
    L1/TEX Cache Throughput             %        10.53
    L2 Cache Throughput                 %        39.55
    SM Active Cycles                cycle    109541.28
    Compute (SM) Throughput             %        10.07
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.78
    Achieved Active Warps Per SM           warp        44.05
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       492844
    Total DRAM Elapsed Cycles        cycle      6481920
    Average L1 Active Cycles         cycle    109541.28
    Total L1 Elapsed Cycles          cycle     14974068
    Average L2 Active Cycles         cycle     98068.11
    Total L2 Elapsed Cycles          cycle      3727980
    Average SM Active Cycles         cycle    109541.28
    Total SM Elapsed Cycles          cycle     14974068
    Average SMSP Active Cycles       cycle    109071.68
    Total SMSP Elapsed Cycles        cycle     59896272
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31909
    Memory Throughput                   %        66.26
    DRAM Throughput                     %        66.26
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        28.09
    L2 Cache Throughput                 %        28.95
    SM Active Cycles                cycle     27110.36
    Compute (SM) Throughput             %        16.95
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.91
    Achieved Active Warps Per SM           warp        11.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.18%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1781760
    Average L1 Active Cycles         cycle     27110.36
    Total L1 Elapsed Cycles          cycle      4092332
    Average L2 Active Cycles         cycle     22975.86
    Total L2 Elapsed Cycles          cycle      1015992
    Average SM Active Cycles         cycle     27110.36
    Total SM Elapsed Cycles          cycle      4092332
    Average SMSP Active Cycles       cycle     27021.40
    Total SMSP Elapsed Cycles        cycle     16369328
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.369%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.51% above the average, while the minimum instance value is 17.02% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.175%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.49% above the average, while the minimum instance value is 21.60% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.369%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.51% above the average, while the minimum instance value is 17.02% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.11
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9744
    Memory Throughput                   %         5.91
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.91
    L2 Cache Throughput                 %         1.91
    SM Active Cycles                cycle      4025.55
    Compute (SM) Throughput             %         9.19
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        26.81
    Achieved Active Warps Per SM           warp        12.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 46.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       333.33
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      4025.55
    Total L1 Elapsed Cycles          cycle      1213268
    Average L2 Active Cycles         cycle        89.75
    Total L2 Elapsed Cycles          cycle       308268
    Average SM Active Cycles         cycle      4025.55
    Total SM Elapsed Cycles          cycle      1213268
    Average SMSP Active Cycles       cycle      3657.82
    Total SMSP Elapsed Cycles        cycle      4853072
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.548%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.13% above the average, while the minimum instance value is 24.18% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.604%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 17.11% above the average, while the minimum instance value is 25.58% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.548%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.13% above the average, while the minimum instance value is 24.18% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32002
    Memory Throughput                   %        66.73
    DRAM Throughput                     %        66.73
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        27.70
    L2 Cache Throughput                 %        28.97
    SM Active Cycles                cycle     27497.83
    Compute (SM) Throughput             %        17.18
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.73
    Achieved Active Warps Per SM           warp        11.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.53%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1769472
    Average L1 Active Cycles         cycle     27497.83
    Total L1 Elapsed Cycles          cycle      4037852
    Average L2 Active Cycles         cycle     22953.47
    Total L2 Elapsed Cycles          cycle      1015272
    Average SM Active Cycles         cycle     27497.83
    Total SM Elapsed Cycles          cycle      4037852
    Average SMSP Active Cycles       cycle     27093.05
    Total SMSP Elapsed Cycles        cycle     16151408
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.182%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.95% above the average, while the minimum instance value is 17.32% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.863%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.83% above the average, while the minimum instance value is 15.96% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.182%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.95% above the average, while the minimum instance value is 17.32% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32198
    Memory Throughput                   %        65.69
    DRAM Throughput                     %        65.69
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        28.11
    L2 Cache Throughput                 %        28.68
    SM Active Cycles                cycle     27105.70
    Compute (SM) Throughput             %        17.02
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.15
    Achieved Active Warps Per SM           warp        12.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.7%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1797120
    Average L1 Active Cycles         cycle     27105.70
    Total L1 Elapsed Cycles          cycle      4077118
    Average L2 Active Cycles         cycle     22977.92
    Total L2 Elapsed Cycles          cycle      1025820
    Average SM Active Cycles         cycle     27105.70
    Total SM Elapsed Cycles          cycle      4077118
    Average SMSP Active Cycles       cycle     27250.40
    Total SMSP Elapsed Cycles        cycle     16308472
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.682%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.68% above the average, while the minimum instance value is 21.38% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.254%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.48% above the average, while the minimum instance value is 15.56% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.682%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.68% above the average, while the minimum instance value is 21.38% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31894
    Memory Throughput                   %        66.30
    DRAM Throughput                     %        66.30
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.91
    L2 Cache Throughput                 %        28.95
    SM Active Cycles                cycle     27296.88
    Compute (SM) Throughput             %        16.92
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.62
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.77%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1780736
    Average L1 Active Cycles         cycle     27296.88
    Total L1 Elapsed Cycles          cycle      4099734
    Average L2 Active Cycles         cycle     23263.06
    Total L2 Elapsed Cycles          cycle      1016028
    Average SM Active Cycles         cycle     27296.88
    Total SM Elapsed Cycles          cycle      4099734
    Average SMSP Active Cycles       cycle     27486.11
    Total SMSP Elapsed Cycles        cycle     16398936
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.81%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.82% above the average, while the minimum instance value is 11.75% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.546%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.46% above the average, while the minimum instance value is 14.43% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.81%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.82% above the average, while the minimum instance value is 11.75% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118678
    Memory Throughput                   %        90.81
    DRAM Throughput                     %        90.81
    Duration                      usecond        53.18
    L1/TEX Cache Throughput             %        10.45
    L2 Cache Throughput                 %        39.25
    SM Active Cycles                cycle    110288.58
    Compute (SM) Throughput             %        10.02
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.28
    Achieved Active Warps Per SM           warp        43.81
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494077.33
    Total DRAM Elapsed Cycles        cycle      6529024
    Average L1 Active Cycles         cycle    110288.58
    Total L1 Elapsed Cycles          cycle     15048054
    Average L2 Active Cycles         cycle     98200.53
    Total L2 Elapsed Cycles          cycle      3757284
    Average SM Active Cycles         cycle    110288.58
    Total SM Elapsed Cycles          cycle     15048054
    Average SMSP Active Cycles       cycle    109311.96
    Total SMSP Elapsed Cycles        cycle     60192216
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle         9757
    Memory Throughput                   %         5.88
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.38
    L1/TEX Cache Throughput             %        13.92
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4021.94
    Compute (SM) Throughput             %         9.11
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.56
    Achieved Active Warps Per SM           warp        11.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.88%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      4021.94
    Total L1 Elapsed Cycles          cycle      1218206
    Average L2 Active Cycles         cycle        85.14
    Total L2 Elapsed Cycles          cycle       308700
    Average SM Active Cycles         cycle      4021.94
    Total SM Elapsed Cycles          cycle      1218206
    Average SMSP Active Cycles       cycle      3461.16
    Total SMSP Elapsed Cycles        cycle      4872824
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.328%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.71% above the average, while the minimum instance value is 23.57% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.06%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.41% above the average, while the minimum instance value is 27.48% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.328%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.71% above the average, while the minimum instance value is 23.57% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32392
    Memory Throughput                   %        65.96
    DRAM Throughput                     %        65.96
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.76
    L2 Cache Throughput                 %        28.61
    SM Active Cycles                cycle     27444.23
    Compute (SM) Throughput             %        16.54
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.55
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.91%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1789952
    Average L1 Active Cycles         cycle     27444.23
    Total L1 Elapsed Cycles          cycle      4193506
    Average L2 Active Cycles         cycle     22892.31
    Total L2 Elapsed Cycles          cycle      1027980
    Average SM Active Cycles         cycle     27444.23
    Total SM Elapsed Cycles          cycle      4193506
    Average SMSP Active Cycles       cycle     27182.41
    Total SMSP Elapsed Cycles        cycle     16774024
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.856%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.99% above the average, while the minimum instance value is 16.15% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.856%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.99% above the average, while the minimum instance value is 16.15% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32211
    Memory Throughput                   %        65.59
    DRAM Throughput                     %        65.59
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        28.08
    L2 Cache Throughput                 %        28.67
    SM Active Cycles                cycle     27124.86
    Compute (SM) Throughput             %        17.23
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.08
    Achieved Active Warps Per SM           warp        12.04
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.83%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98392
    Total DRAM Elapsed Cycles        cycle      1800192
    Average L1 Active Cycles         cycle     27124.86
    Total L1 Elapsed Cycles          cycle      4026732
    Average L2 Active Cycles         cycle     22769.06
    Total L2 Elapsed Cycles          cycle      1026252
    Average SM Active Cycles         cycle     27124.86
    Total SM Elapsed Cycles          cycle      4026732
    Average SMSP Active Cycles       cycle     27166.04
    Total SMSP Elapsed Cycles        cycle     16106928
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.273%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.27% above the average, while the minimum instance value is 12.60% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.273%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.27% above the average, while the minimum instance value is 12.60% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31604
    Memory Throughput                   %        66.84
    DRAM Throughput                     %        66.84
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.92
    L2 Cache Throughput                 %        29.22
    SM Active Cycles                cycle     27291.95
    Compute (SM) Throughput             %        16.80
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.50
    Achieved Active Warps Per SM           warp        11.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51%                                                                                       
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1766400
    Average L1 Active Cycles         cycle     27291.95
    Total L1 Elapsed Cycles          cycle      4129050
    Average L2 Active Cycles         cycle     22923.78
    Total L2 Elapsed Cycles          cycle      1006704
    Average SM Active Cycles         cycle     27291.95
    Total SM Elapsed Cycles          cycle      4129050
    Average SMSP Active Cycles       cycle     27129.11
    Total SMSP Elapsed Cycles        cycle     16516200
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.401%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.61% above the average, while the minimum instance value is 14.50% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31744
    Memory Throughput                   %        66.56
    DRAM Throughput                     %        66.56
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        28.40
    L2 Cache Throughput                 %        29.08
    SM Active Cycles                cycle     26820.08
    Compute (SM) Throughput             %        16.86
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.07
    Achieved Active Warps Per SM           warp        12.03
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.86%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1773568
    Average L1 Active Cycles         cycle     26820.08
    Total L1 Elapsed Cycles          cycle      4114776
    Average L2 Active Cycles         cycle     22895.11
    Total L2 Elapsed Cycles          cycle      1011600
    Average SM Active Cycles         cycle     26820.08
    Total SM Elapsed Cycles          cycle      4114776
    Average SMSP Active Cycles       cycle     27081.96
    Total SMSP Elapsed Cycles        cycle     16459104
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.492%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.58% above the average, while the minimum instance value is 17.47% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.182%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.15% above the average, while the minimum instance value is 17.68% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.492%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.58% above the average, while the minimum instance value is 17.47% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118146
    Memory Throughput                   %        90.81
    DRAM Throughput                     %        90.81
    Duration                      usecond        52.90
    L1/TEX Cache Throughput             %        10.50
    L2 Cache Throughput                 %        39.43
    SM Active Cycles                cycle    109804.47
    Compute (SM) Throughput             %        10.02
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.56
    Achieved Active Warps Per SM           warp        44.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491696
    Total DRAM Elapsed Cycles        cycle      6497280
    Average L1 Active Cycles         cycle    109804.47
    Total L1 Elapsed Cycles          cycle     15049596
    Average L2 Active Cycles         cycle     98102.89
    Total L2 Elapsed Cycles          cycle      3739572
    Average SM Active Cycles         cycle    109804.47
    Total SM Elapsed Cycles          cycle     15049596
    Average SMSP Active Cycles       cycle    108443.01
    Total SMSP Elapsed Cycles        cycle     60198384
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32562
    Memory Throughput                   %        65.62
    DRAM Throughput                     %        65.62
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.71
    L2 Cache Throughput                 %        28.47
    SM Active Cycles                cycle     27500.25
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.52
    Achieved Active Warps Per SM           warp        11.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.97%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1799168
    Average L1 Active Cycles         cycle     27500.25
    Total L1 Elapsed Cycles          cycle      4073754
    Average L2 Active Cycles         cycle     23070.61
    Total L2 Elapsed Cycles          cycle      1033056
    Average SM Active Cycles         cycle     27500.25
    Total SM Elapsed Cycles          cycle      4073754
    Average SMSP Active Cycles       cycle     27179.87
    Total SMSP Elapsed Cycles        cycle     16295016
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.919%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.01% above the average, while the minimum instance value is 20.48% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.166%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.22% above the average, while the minimum instance value is 18.04% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.919%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.01% above the average, while the minimum instance value is 20.48% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32160
    Memory Throughput                   %        65.58
    DRAM Throughput                     %        65.58
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        28.69
    SM Active Cycles                cycle     27210.51
    Compute (SM) Throughput             %        16.66
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.98
    Achieved Active Warps Per SM           warp        11.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.05%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1800192
    Average L1 Active Cycles         cycle     27210.51
    Total L1 Elapsed Cycles          cycle      4165382
    Average L2 Active Cycles         cycle     23083.69
    Total L2 Elapsed Cycles          cycle      1025316
    Average SM Active Cycles         cycle     27210.51
    Total SM Elapsed Cycles          cycle      4165382
    Average SMSP Active Cycles       cycle     27299.85
    Total SMSP Elapsed Cycles        cycle     16661528
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.461%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.73% above the average, while the minimum instance value is 20.27% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.464%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.51% above the average, while the minimum instance value is 19.61% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.461%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.73% above the average, while the minimum instance value is 20.27% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.18
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32472
    Memory Throughput                   %        65.06
    DRAM Throughput                     %        65.06
    Duration                      usecond        14.85
    L1/TEX Cache Throughput             %        27.81
    L2 Cache Throughput                 %        28.43
    SM Active Cycles                cycle     27405.33
    Compute (SM) Throughput             %        16.88
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.64
    Achieved Active Warps Per SM           warp        11.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.72%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1814528
    Average L1 Active Cycles         cycle     27405.33
    Total L1 Elapsed Cycles          cycle      4108946
    Average L2 Active Cycles         cycle     23053.33
    Total L2 Elapsed Cycles          cycle      1034820
    Average SM Active Cycles         cycle     27405.33
    Total SM Elapsed Cycles          cycle      4108946
    Average SMSP Active Cycles       cycle     27384.70
    Total SMSP Elapsed Cycles        cycle     16435784
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.011%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.04% above the average, while the minimum instance value is 19.73% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.736%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 10.24% above the average, while the minimum instance value is 15.18% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.011%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.04% above the average, while the minimum instance value is 19.73% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32236
    Memory Throughput                   %        65.80
    DRAM Throughput                     %        65.80
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        27.82
    L2 Cache Throughput                 %        28.68
    SM Active Cycles                cycle     27394.29
    Compute (SM) Throughput             %        16.99
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.48
    Achieved Active Warps Per SM           warp        11.75
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.04%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27394.29
    Total L1 Elapsed Cycles          cycle      4082358
    Average L2 Active Cycles         cycle     22952.92
    Total L2 Elapsed Cycles          cycle      1025640
    Average SM Active Cycles         cycle     27394.29
    Total SM Elapsed Cycles          cycle      4082358
    Average SMSP Active Cycles       cycle     27109.16
    Total SMSP Elapsed Cycles        cycle     16329432
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.762%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.71% above the average, while the minimum instance value is 17.99% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.062%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.13% above the average, while the minimum instance value is 20.41% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.762%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.71% above the average, while the minimum instance value is 17.99% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32064
    Memory Throughput                   %        66.22
    DRAM Throughput                     %        66.22
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.91
    L2 Cache Throughput                 %        28.84
    SM Active Cycles                cycle     27295.23
    Compute (SM) Throughput             %        17.10
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.33
    Achieved Active Warps Per SM           warp        12.16
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.34%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1782784
    Average L1 Active Cycles         cycle     27295.23
    Total L1 Elapsed Cycles          cycle      4056652
    Average L2 Active Cycles         cycle     23031.61
    Total L2 Elapsed Cycles          cycle      1019808
    Average SM Active Cycles         cycle     27295.23
    Total SM Elapsed Cycles          cycle      4056652
    Average SMSP Active Cycles       cycle     27052.10
    Total SMSP Elapsed Cycles        cycle     16226608
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.027%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.84% above the average, while the minimum instance value is 12.91% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.993%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.02% above the average, while the minimum instance value is 20.90% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.027%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.84% above the average, while the minimum instance value is 12.91% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117619
    Memory Throughput                   %        91.22
    DRAM Throughput                     %        91.22
    Duration                      usecond        52.67
    L1/TEX Cache Throughput             %        10.53
    L2 Cache Throughput                 %        39.60
    SM Active Cycles                cycle    109507.88
    Compute (SM) Throughput             %        10.07
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.87
    Achieved Active Warps Per SM           warp        44.10
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491804
    Total DRAM Elapsed Cycles        cycle      6469632
    Average L1 Active Cycles         cycle    109507.88
    Total L1 Elapsed Cycles          cycle     14970664
    Average L2 Active Cycles         cycle     97998.42
    Total L2 Elapsed Cycles          cycle      3723588
    Average SM Active Cycles         cycle    109507.88
    Total SM Elapsed Cycles          cycle     14970664
    Average SMSP Active Cycles       cycle    108491.82
    Total SMSP Elapsed Cycles        cycle     59882656
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31724
    Memory Throughput                   %        66.57
    DRAM Throughput                     %        66.57
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        28.20
    L2 Cache Throughput                 %        29.12
    SM Active Cycles                cycle     27008.89
    Compute (SM) Throughput             %        17.08
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.99
    Achieved Active Warps Per SM           warp        11.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.02%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1773568
    Average L1 Active Cycles         cycle     27008.89
    Total L1 Elapsed Cycles          cycle      4060756
    Average L2 Active Cycles         cycle     23042.47
    Total L2 Elapsed Cycles          cycle      1010268
    Average SM Active Cycles         cycle     27008.89
    Total SM Elapsed Cycles          cycle      4060756
    Average SMSP Active Cycles       cycle     27345.29
    Total SMSP Elapsed Cycles        cycle     16243024
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.826%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.84% above the average, while the minimum instance value is 19.24% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.364%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.22% above the average, while the minimum instance value is 18.43% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.826%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.84% above the average, while the minimum instance value is 19.24% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31987
    Memory Throughput                   %        66.15
    DRAM Throughput                     %        66.15
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.00
    L2 Cache Throughput                 %        28.85
    SM Active Cycles                cycle     27209.89
    Compute (SM) Throughput             %        16.84
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.60
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.81%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27209.89
    Total L1 Elapsed Cycles          cycle      4120786
    Average L2 Active Cycles         cycle     22971.64
    Total L2 Elapsed Cycles          cycle      1019592
    Average SM Active Cycles         cycle     27209.89
    Total SM Elapsed Cycles          cycle      4120786
    Average SMSP Active Cycles       cycle     27440.38
    Total SMSP Elapsed Cycles        cycle     16483144
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.212%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.17% above the average, while the minimum instance value is 12.78% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.212%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.17% above the average, while the minimum instance value is 12.78% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31880
    Memory Throughput                   %        66.34
    DRAM Throughput                     %        66.34
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.82
    L2 Cache Throughput                 %        28.95
    SM Active Cycles                cycle     27378.87
    Compute (SM) Throughput             %        16.90
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.53
    Achieved Active Warps Per SM           warp        11.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.94%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1779712
    Average L1 Active Cycles         cycle     27378.87
    Total L1 Elapsed Cycles          cycle      4103918
    Average L2 Active Cycles         cycle     22973.17
    Total L2 Elapsed Cycles          cycle      1016028
    Average SM Active Cycles         cycle     27378.87
    Total SM Elapsed Cycles          cycle      4103918
    Average SMSP Active Cycles       cycle     27098.14
    Total SMSP Elapsed Cycles        cycle     16415672
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.212%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.35% above the average, while the minimum instance value is 13.23% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32088
    Memory Throughput                   %        66.60
    DRAM Throughput                     %        66.60
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.55
    L2 Cache Throughput                 %        28.89
    SM Active Cycles                cycle     27645.04
    Compute (SM) Throughput             %        17.46
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.36
    Achieved Active Warps Per SM           warp        11.69
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.28%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1772544
    Average L1 Active Cycles         cycle     27645.04
    Total L1 Elapsed Cycles          cycle      3972924
    Average L2 Active Cycles         cycle        22889
    Total L2 Elapsed Cycles          cycle      1018080
    Average SM Active Cycles         cycle     27645.04
    Total SM Elapsed Cycles          cycle      3972924
    Average SMSP Active Cycles       cycle     27240.29
    Total SMSP Elapsed Cycles        cycle     15891696
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.297%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.95% above the average, while the minimum instance value is 18.89% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.566%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.34% above the average, while the minimum instance value is 12.14% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.297%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.95% above the average, while the minimum instance value is 18.89% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.09
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9734
    Memory Throughput                   %         5.91
    DRAM Throughput                     %         0.76
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.09
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3974.09
    Compute (SM) Throughput             %         9.16
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.37
    Achieved Active Warps Per SM           warp        12.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.27%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          340
    Total DRAM Elapsed Cycles        cycle       534528
    Average L1 Active Cycles         cycle      3974.09
    Total L1 Elapsed Cycles          cycle      1212200
    Average L2 Active Cycles         cycle        87.28
    Total L2 Elapsed Cycles          cycle       307836
    Average SM Active Cycles         cycle      3974.09
    Total SM Elapsed Cycles          cycle      1212200
    Average SMSP Active Cycles       cycle      3472.07
    Total SMSP Elapsed Cycles        cycle      4848800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.402%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.02% above the average, while the minimum instance value is 23.25% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.526%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 17.80% above the average, while the minimum instance value is 27.62% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.402%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.02% above the average, while the minimum instance value is 23.25% below the      
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117914
    Memory Throughput                   %        91.26
    DRAM Throughput                     %        91.26
    Duration                      usecond        52.93
    L1/TEX Cache Throughput             %        10.41
    L2 Cache Throughput                 %        39.47
    SM Active Cycles                cycle    110725.58
    Compute (SM) Throughput             %        10.09
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.68
    Achieved Active Warps Per SM           warp        44.01
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494098.67
    Total DRAM Elapsed Cycles        cycle      6497280
    Average L1 Active Cycles         cycle    110725.58
    Total L1 Elapsed Cycles          cycle     14940826
    Average L2 Active Cycles         cycle     98009.86
    Total L2 Elapsed Cycles          cycle      3735864
    Average SM Active Cycles         cycle    110725.58
    Total SM Elapsed Cycles          cycle     14940826
    Average SMSP Active Cycles       cycle    109539.71
    Total SMSP Elapsed Cycles        cycle     59763304
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32848
    Memory Throughput                   %        64.44
    DRAM Throughput                     %        64.44
    Duration                      usecond        14.98
    L1/TEX Cache Throughput             %        28.02
    L2 Cache Throughput                 %        28.10
    SM Active Cycles                cycle     27172.92
    Compute (SM) Throughput             %        17.26
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.72
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.57%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1831936
    Average L1 Active Cycles         cycle     27172.92
    Total L1 Elapsed Cycles          cycle      4019944
    Average L2 Active Cycles         cycle     22992.75
    Total L2 Elapsed Cycles          cycle      1046808
    Average SM Active Cycles         cycle     27172.92
    Total SM Elapsed Cycles          cycle      4019944
    Average SMSP Active Cycles       cycle     27235.58
    Total SMSP Elapsed Cycles        cycle     16079776
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.532%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.71% above the average, while the minimum instance value is 22.15% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.373%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.35% above the average, while the minimum instance value is 15.05% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.532%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.71% above the average, while the minimum instance value is 22.15% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32140
    Memory Throughput                   %        66.11
    DRAM Throughput                     %        66.11
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.96
    L2 Cache Throughput                 %        28.81
    SM Active Cycles                cycle     27259.74
    Compute (SM) Throughput             %        17.05
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.56
    Achieved Active Warps Per SM           warp        11.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.87%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1785856
    Average L1 Active Cycles         cycle     27259.74
    Total L1 Elapsed Cycles          cycle      4069652
    Average L2 Active Cycles         cycle     23067.83
    Total L2 Elapsed Cycles          cycle      1020852
    Average SM Active Cycles         cycle     27259.74
    Total SM Elapsed Cycles          cycle      4069652
    Average SMSP Active Cycles       cycle     27248.17
    Total SMSP Elapsed Cycles        cycle     16278608
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.549%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.47% above the average, while the minimum instance value is 17.56% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.266%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.14% above the average, while the minimum instance value is 16.97% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.549%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.47% above the average, while the minimum instance value is 17.56% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31803
    Memory Throughput                   %        66.76
    DRAM Throughput                     %        66.76
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        27.92
    L2 Cache Throughput                 %        29.10
    SM Active Cycles                cycle     27289.17
    Compute (SM) Throughput             %        17.11
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp        11.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.42%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1768448
    Average L1 Active Cycles         cycle     27289.17
    Total L1 Elapsed Cycles          cycle      4055128
    Average L2 Active Cycles         cycle     22967.47
    Total L2 Elapsed Cycles          cycle      1010988
    Average SM Active Cycles         cycle     27289.17
    Total SM Elapsed Cycles          cycle      4055128
    Average SMSP Active Cycles       cycle     26989.36
    Total SMSP Elapsed Cycles        cycle     16220512
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.95%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.98% above the average, while the minimum instance value is 21.35% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.07
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9780
    Memory Throughput                   %         5.91
    DRAM Throughput                     %         0.76
    Duration                      usecond         4.45
    L1/TEX Cache Throughput             %        13.93
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4020.35
    Compute (SM) Throughput             %         9.16
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.75
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.51%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       338.67
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      4020.35
    Total L1 Elapsed Cycles          cycle      1212202
    Average L2 Active Cycles         cycle        86.81
    Total L2 Elapsed Cycles          cycle       309456
    Average SM Active Cycles         cycle      4020.35
    Total SM Elapsed Cycles          cycle      1212202
    Average SMSP Active Cycles       cycle      3484.87
    Total SMSP Elapsed Cycles        cycle      4848808
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.716%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.53% above the average, while the minimum instance value is 23.74% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.086%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.26% above the average, while the minimum instance value is 26.28% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.716%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.53% above the average, while the minimum instance value is 23.74% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32711
    Memory Throughput                   %        64.70
    DRAM Throughput                     %        64.70
    Duration                      usecond        14.91
    L1/TEX Cache Throughput             %        27.87
    L2 Cache Throughput                 %        28.23
    SM Active Cycles                cycle     27325.04
    Compute (SM) Throughput             %        16.98
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.85
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.3%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1824768
    Average L1 Active Cycles         cycle     27325.04
    Total L1 Elapsed Cycles          cycle      4086764
    Average L2 Active Cycles         cycle     23044.28
    Total L2 Elapsed Cycles          cycle      1042020
    Average SM Active Cycles         cycle     27325.04
    Total SM Elapsed Cycles          cycle      4086764
    Average SMSP Active Cycles       cycle     27350.51
    Total SMSP Elapsed Cycles        cycle     16347056
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.232%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.45% above the average, while the minimum instance value is 13.51% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.61%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.55% above the average, while the minimum instance value is 16.08% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.232%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.45% above the average, while the minimum instance value is 13.51% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       118315
    Memory Throughput                   %        90.55
    DRAM Throughput                     %        90.55
    Duration                      usecond        53.09
    L1/TEX Cache Throughput             %        10.59
    L2 Cache Throughput                 %        39.35
    SM Active Cycles                cycle    108848.02
    Compute (SM) Throughput             %         9.97
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.86
    Achieved Active Warps Per SM           warp        44.09
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491644
    Total DRAM Elapsed Cycles        cycle      6515712
    Average L1 Active Cycles         cycle    108848.02
    Total L1 Elapsed Cycles          cycle     15118732
    Average L2 Active Cycles         cycle     98035.56
    Total L2 Elapsed Cycles          cycle      3747240
    Average SM Active Cycles         cycle    108848.02
    Total SM Elapsed Cycles          cycle     15118732
    Average SMSP Active Cycles       cycle    108174.98
    Total SMSP Elapsed Cycles        cycle     60474928
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.025%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.45% above the average, while the minimum instance value is 18.28% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.111%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.67% above the average, while the minimum instance value is 21.29% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.025%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.45% above the average, while the minimum instance value is 18.28% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31795
    Memory Throughput                   %        66.49
    DRAM Throughput                     %        66.49
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        28.06
    L2 Cache Throughput                 %        29.04
    SM Active Cycles                cycle     27157.38
    Compute (SM) Throughput             %        16.98
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.55
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.9%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1775616
    Average L1 Active Cycles         cycle     27157.38
    Total L1 Elapsed Cycles          cycle      4085670
    Average L2 Active Cycles         cycle     22811.08
    Total L2 Elapsed Cycles          cycle      1013040
    Average SM Active Cycles         cycle     27157.38
    Total SM Elapsed Cycles          cycle      4085670
    Average SMSP Active Cycles       cycle     26900.99
    Total SMSP Elapsed Cycles        cycle     16342680
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.344%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.90% above the average, while the minimum instance value is 17.62% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32953
    Memory Throughput                   %        64.84
    DRAM Throughput                     %        64.84
    Duration                      usecond        14.88
    L1/TEX Cache Throughput             %        27.80
    L2 Cache Throughput                 %        28.13
    SM Active Cycles                cycle     27401.36
    Compute (SM) Throughput             %        17.21
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.54
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.92%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1820672
    Average L1 Active Cycles         cycle     27401.36
    Total L1 Elapsed Cycles          cycle      4030310
    Average L2 Active Cycles         cycle     22781.78
    Total L2 Elapsed Cycles          cycle      1045764
    Average SM Active Cycles         cycle     27401.36
    Total SM Elapsed Cycles          cycle      4030310
    Average SMSP Active Cycles       cycle     26831.60
    Total SMSP Elapsed Cycles        cycle     16121240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.369%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.62% above the average, while the minimum instance value is 24.69% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.766%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.77% above the average, while the minimum instance value is 23.51% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.369%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.62% above the average, while the minimum instance value is 24.69% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.18
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle         9732
    Memory Throughput                   %         5.92
    DRAM Throughput                     %         0.76
    Duration                      usecond         4.38
    L1/TEX Cache Throughput             %        14.04
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3989.91
    Compute (SM) Throughput             %         9.15
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.44%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       338.67
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      3989.91
    Total L1 Elapsed Cycles          cycle      1211812
    Average L2 Active Cycles         cycle        83.17
    Total L2 Elapsed Cycles          cycle       307764
    Average SM Active Cycles         cycle      3989.91
    Total SM Elapsed Cycles          cycle      1211812
    Average SMSP Active Cycles       cycle      3482.52
    Total SMSP Elapsed Cycles        cycle      4847248
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.215%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.49% above the average, while the minimum instance value is 23.86% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.917%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.80% above the average, while the minimum instance value is 26.81% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.215%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.49% above the average, while the minimum instance value is 23.86% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31810
    Memory Throughput                   %        66.49
    DRAM Throughput                     %        66.49
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        28.37
    L2 Cache Throughput                 %        29.06
    SM Active Cycles                cycle     26868.06
    Compute (SM) Throughput             %        16.93
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.14
    Achieved Active Warps Per SM           warp        12.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.73%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1775616
    Average L1 Active Cycles         cycle     26868.06
    Total L1 Elapsed Cycles          cycle      4097926
    Average L2 Active Cycles         cycle     22777.67
    Total L2 Elapsed Cycles          cycle      1012320
    Average SM Active Cycles         cycle     26868.06
    Total SM Elapsed Cycles          cycle      4097926
    Average SMSP Active Cycles       cycle     27039.99
    Total SMSP Elapsed Cycles        cycle     16391704
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.291%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.30% above the average, while the minimum instance value is 18.52% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.291%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.30% above the average, while the minimum instance value is 18.52% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31753
    Memory Throughput                   %        66.53
    DRAM Throughput                     %        66.53
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        28.07
    L2 Cache Throughput                 %        29.07
    SM Active Cycles                cycle     27131.32
    Compute (SM) Throughput             %        16.85
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.60
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.8%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     27131.32
    Total L1 Elapsed Cycles          cycle      4118490
    Average L2 Active Cycles         cycle     22766.39
    Total L2 Elapsed Cycles          cycle      1012032
    Average SM Active Cycles         cycle     27131.32
    Total SM Elapsed Cycles          cycle      4118490
    Average SMSP Active Cycles       cycle     26995.47
    Total SMSP Elapsed Cycles        cycle     16473960
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.393%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.40% above the average, while the minimum instance value is 19.31% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.352%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.38% above the average, while the minimum instance value is 19.71% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.393%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.40% above the average, while the minimum instance value is 19.31% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       119041
    Memory Throughput                   %        90.18
    DRAM Throughput                     %        90.18
    Duration                      usecond        53.41
    L1/TEX Cache Throughput             %        10.62
    L2 Cache Throughput                 %        39.11
    SM Active Cycles                cycle    108547.29
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.73
    Achieved Active Warps Per SM           warp        44.51
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    492837.33
    Total DRAM Elapsed Cycles        cycle      6557696
    Average L1 Active Cycles         cycle    108547.29
    Total L1 Elapsed Cycles          cycle     14976856
    Average L2 Active Cycles         cycle     98020.19
    Total L2 Elapsed Cycles          cycle      3770172
    Average SM Active Cycles         cycle    108547.29
    Total SM Elapsed Cycles          cycle     14976856
    Average SMSP Active Cycles       cycle    108193.82
    Total SMSP Elapsed Cycles        cycle     59907424
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.732%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.18% above the average, while the minimum instance value is 22.06% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.732%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.18% above the average, while the minimum instance value is 22.06% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31872
    Memory Throughput                   %        66.68
    DRAM Throughput                     %        66.68
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        28.15
    L2 Cache Throughput                 %        29.04
    SM Active Cycles                cycle     27062.19
    Compute (SM) Throughput             %        16.95
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.93
    Achieved Active Warps Per SM           warp        11.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.14%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1770496
    Average L1 Active Cycles         cycle     27062.19
    Total L1 Elapsed Cycles          cycle      4092260
    Average L2 Active Cycles         cycle     22839.44
    Total L2 Elapsed Cycles          cycle      1012824
    Average SM Active Cycles         cycle     27062.19
    Total SM Elapsed Cycles          cycle      4092260
    Average SMSP Active Cycles       cycle     26659.05
    Total SMSP Elapsed Cycles        cycle     16369040
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.38%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.36% above the average, while the minimum instance value is 21.02% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.881%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.05% above the average, while the minimum instance value is 20.40% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.38%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.36% above the average, while the minimum instance value is 21.02% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.11
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9747
    Memory Throughput                   %         5.91
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.94
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      4017.31
    Compute (SM) Throughput             %         9.16
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.84
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.33%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      4017.31
    Total L1 Elapsed Cycles          cycle      1212748
    Average L2 Active Cycles         cycle        81.47
    Total L2 Elapsed Cycles          cycle       308448
    Average SM Active Cycles         cycle      4017.31
    Total SM Elapsed Cycles          cycle      1212748
    Average SMSP Active Cycles       cycle      3434.74
    Total SMSP Elapsed Cycles        cycle      4850992
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.496%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.04% above the average, while the minimum instance value is 23.73% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.765%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 21.42% above the average, while the minimum instance value is 28.93% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.496%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.04% above the average, while the minimum instance value is 23.73% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31724
    Memory Throughput                   %        66.57
    DRAM Throughput                     %        66.57
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.94
    L2 Cache Throughput                 %        29.09
    SM Active Cycles                cycle     27261.24
    Compute (SM) Throughput             %        17.01
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.91
    Achieved Active Warps Per SM           warp        11.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.17%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1773568
    Average L1 Active Cycles         cycle     27261.24
    Total L1 Elapsed Cycles          cycle      4078370
    Average L2 Active Cycles         cycle     22910.47
    Total L2 Elapsed Cycles          cycle      1011168
    Average SM Active Cycles         cycle     27261.24
    Total SM Elapsed Cycles          cycle      4078370
    Average SMSP Active Cycles       cycle     27184.50
    Total SMSP Elapsed Cycles        cycle     16313480
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.646%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.62% above the average, while the minimum instance value is 18.30% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32738
    Memory Throughput                   %        64.66
    DRAM Throughput                     %        64.66
    Duration                      usecond        14.91
    L1/TEX Cache Throughput             %        28.10
    L2 Cache Throughput                 %        28.22
    SM Active Cycles                cycle     27117.34
    Compute (SM) Throughput             %        16.52
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.66
    Achieved Active Warps Per SM           warp        11.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.68%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1825792
    Average L1 Active Cycles         cycle     27117.34
    Total L1 Elapsed Cycles          cycle      4200212
    Average L2 Active Cycles         cycle     22962.06
    Total L2 Elapsed Cycles          cycle      1042416
    Average SM Active Cycles         cycle     27117.34
    Total SM Elapsed Cycles          cycle      4200212
    Average SMSP Active Cycles       cycle     27199.45
    Total SMSP Elapsed Cycles        cycle     16800848
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.475%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.04% above the average, while the minimum instance value is 12.02% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.689%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.07% above the average, while the minimum instance value is 17.12% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.475%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.04% above the average, while the minimum instance value is 12.02% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31990
    Memory Throughput                   %        66.15
    DRAM Throughput                     %        66.15
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.98
    L2 Cache Throughput                 %        28.90
    SM Active Cycles                cycle     27231.16
    Compute (SM) Throughput             %        16.91
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.58
    Achieved Active Warps Per SM           warp        11.80
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.84%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27231.16
    Total L1 Elapsed Cycles          cycle      4102892
    Average L2 Active Cycles         cycle     23082.56
    Total L2 Elapsed Cycles          cycle      1017972
    Average SM Active Cycles         cycle     27231.16
    Total SM Elapsed Cycles          cycle      4102892
    Average SMSP Active Cycles       cycle     27213.47
    Total SMSP Elapsed Cycles        cycle     16411568
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.249%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.54% above the average, while the minimum instance value is 15.90% below the average.      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118300
    Memory Throughput                   %        91.16
    DRAM Throughput                     %        91.16
    Duration                      usecond        52.99
    L1/TEX Cache Throughput             %        10.45
    L2 Cache Throughput                 %        39.37
    SM Active Cycles                cycle    110337.94
    Compute (SM) Throughput             %        10.09
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.55
    Achieved Active Warps Per SM           warp        43.94
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       494192
    Total DRAM Elapsed Cycles        cycle      6505472
    Average L1 Active Cycles         cycle    110337.94
    Total L1 Elapsed Cycles          cycle     14942902
    Average L2 Active Cycles         cycle     98022.81
    Total L2 Elapsed Cycles          cycle      3745296
    Average SM Active Cycles         cycle    110337.94
    Total SM Elapsed Cycles          cycle     14942902
    Average SMSP Active Cycles       cycle    109248.99
    Total SMSP Elapsed Cycles        cycle     59771608
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.09
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9730
    Memory Throughput                   %         5.91
    DRAM Throughput                     %         0.77
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.03
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3992.84
    Compute (SM) Throughput             %         9.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.96
    Achieved Active Warps Per SM           warp        11.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.07%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       341.33
    Total DRAM Elapsed Cycles        cycle       534528
    Average L1 Active Cycles         cycle      3992.84
    Total L1 Elapsed Cycles          cycle      1212522
    Average L2 Active Cycles         cycle        82.36
    Total L2 Elapsed Cycles          cycle       307944
    Average SM Active Cycles         cycle      3992.84
    Total SM Elapsed Cycles          cycle      1212522
    Average SMSP Active Cycles       cycle      3444.30
    Total SMSP Elapsed Cycles        cycle      4850088
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.116%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.25% above the average, while the minimum instance value is 23.49% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.35%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 20.22% above the average, while the minimum instance value is 27.56% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.116%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.25% above the average, while the minimum instance value is 23.49% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32927
    Memory Throughput                   %        64.30
    DRAM Throughput                     %        64.30
    Duration                      usecond        15.01
    L1/TEX Cache Throughput             %        28.10
    L2 Cache Throughput                 %        28.05
    SM Active Cycles                cycle     27115.77
    Compute (SM) Throughput             %        17.06
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.01
    Achieved Active Warps Per SM           warp        12.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.99%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1836032
    Average L1 Active Cycles         cycle     27115.77
    Total L1 Elapsed Cycles          cycle      4067278
    Average L2 Active Cycles         cycle     23008.39
    Total L2 Elapsed Cycles          cycle      1048644
    Average SM Active Cycles         cycle     27115.77
    Total SM Elapsed Cycles          cycle      4067278
    Average SMSP Active Cycles       cycle     27207.33
    Total SMSP Elapsed Cycles        cycle     16269112
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.006%                                                                                          
          One or more SMs have a much higher number of active cycles than the average number of active cycles.          
          Additionally, other SMs have a much lower number of active cycles than the average number of active cycles.   
          Maximum instance value is 9.38% above the average, while the minimum instance value is 11.26% below the       
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.02%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.03% above the average, while the minimum instance value is 11.38% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.006%                                                                                          
          One or more L1 Slices have a much higher number of active cycles than the average number of active cycles.    
          Additionally, other L1 Slices have a much lower number of active cycles than the average number of active     
          cycles. Maximum instance value is 9.38% above the average, while the minimum instance value is 11.26% below   
          the average.                                                                                                  

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32034
    Memory Throughput                   %        66.07
    DRAM Throughput                     %        66.07
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.02
    L2 Cache Throughput                 %        28.85
    SM Active Cycles                cycle     27186.30
    Compute (SM) Throughput             %        16.79
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.74
    Achieved Active Warps Per SM           warp        11.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.52%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1786880
    Average L1 Active Cycles         cycle     27186.30
    Total L1 Elapsed Cycles          cycle      4131026
    Average L2 Active Cycles         cycle     22951.53
    Total L2 Elapsed Cycles          cycle      1019628
    Average SM Active Cycles         cycle     27186.30
    Total SM Elapsed Cycles          cycle      4131026
    Average SMSP Active Cycles       cycle     27304.66
    Total SMSP Elapsed Cycles        cycle     16524104
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.928%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.01% above the average, while the minimum instance value is 15.11% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31759
    Memory Throughput                   %        66.68
    DRAM Throughput                     %        66.68
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        29.09
    SM Active Cycles                cycle     27214.76
    Compute (SM) Throughput             %        17.25
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.70
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.59%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1770496
    Average L1 Active Cycles         cycle     27214.76
    Total L1 Elapsed Cycles          cycle      4021874
    Average L2 Active Cycles         cycle     22925.39
    Total L2 Elapsed Cycles          cycle      1011024
    Average SM Active Cycles         cycle     27214.76
    Total SM Elapsed Cycles          cycle      4021874
    Average SMSP Active Cycles       cycle     27157.36
    Total SMSP Elapsed Cycles        cycle     16087496
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32605
    Memory Throughput                   %        65.51
    DRAM Throughput                     %        65.51
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        27.90
    L2 Cache Throughput                 %        28.43
    SM Active Cycles                cycle     27294.59
    Compute (SM) Throughput             %        17.08
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.01
    Achieved Active Warps Per SM           warp        12.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.98%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1802240
    Average L1 Active Cycles         cycle     27294.59
    Total L1 Elapsed Cycles          cycle      4062808
    Average L2 Active Cycles         cycle     23002.19
    Total L2 Elapsed Cycles          cycle      1034496
    Average SM Active Cycles         cycle     27294.59
    Total SM Elapsed Cycles          cycle      4062808
    Average SMSP Active Cycles       cycle     27172.87
    Total SMSP Elapsed Cycles        cycle     16251232
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.588%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.66% above the average, while the minimum instance value is 12.77% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.788%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.93% above the average, while the minimum instance value is 15.36% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.588%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.66% above the average, while the minimum instance value is 12.77% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117189
    Memory Throughput                   %        91.55
    DRAM Throughput                     %        91.55
    Duration                      usecond        52.48
    L1/TEX Cache Throughput             %        10.60
    L2 Cache Throughput                 %        39.75
    SM Active Cycles                cycle    108788.43
    Compute (SM) Throughput             %        10.03
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        93.17
    Achieved Active Warps Per SM           warp        44.72
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491721.33
    Total DRAM Elapsed Cycles        cycle      6445056
    Average L1 Active Cycles         cycle    108788.43
    Total L1 Elapsed Cycles          cycle     15033564
    Average L2 Active Cycles         cycle     97995.17
    Total L2 Elapsed Cycles          cycle      3709224
    Average SM Active Cycles         cycle    108788.43
    Total SM Elapsed Cycles          cycle     15033564
    Average SMSP Active Cycles       cycle    108208.76
    Total SMSP Elapsed Cycles        cycle     60134256
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31924
    Memory Throughput                   %        66.08
    DRAM Throughput                     %        66.08
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        28.89
    SM Active Cycles                cycle     27218.62
    Compute (SM) Throughput             %        16.85
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.01
    Achieved Active Warps Per SM           warp        12.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.99%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98392
    Total DRAM Elapsed Cycles        cycle      1786880
    Average L1 Active Cycles         cycle     27218.62
    Total L1 Elapsed Cycles          cycle      4116236
    Average L2 Active Cycles         cycle     23149.36
    Total L2 Elapsed Cycles          cycle      1018440
    Average SM Active Cycles         cycle     27218.62
    Total SM Elapsed Cycles          cycle      4116236
    Average SMSP Active Cycles       cycle     27195.05
    Total SMSP Elapsed Cycles        cycle     16464944
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.279%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.24% above the average, while the minimum instance value is 21.90% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.848%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.28% above the average, while the minimum instance value is 19.51% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.279%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.24% above the average, while the minimum instance value is 21.90% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32477
    Memory Throughput                   %        65.03
    DRAM Throughput                     %        65.03
    Duration                      usecond        14.82
    L1/TEX Cache Throughput             %        27.83
    L2 Cache Throughput                 %        28.43
    SM Active Cycles                cycle     27370.45
    Compute (SM) Throughput             %        16.80
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.52
    Achieved Active Warps Per SM           warp        11.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.96%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1815552
    Average L1 Active Cycles         cycle     27370.45
    Total L1 Elapsed Cycles          cycle      4129650
    Average L2 Active Cycles         cycle     23158.14
    Total L2 Elapsed Cycles          cycle      1034604
    Average SM Active Cycles         cycle     27370.45
    Total SM Elapsed Cycles          cycle      4129650
    Average SMSP Active Cycles       cycle     27290.96
    Total SMSP Elapsed Cycles        cycle     16518600
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.793%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.01% above the average, while the minimum instance value is 17.18% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.337%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.49% above the average, while the minimum instance value is 20.57% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.793%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.01% above the average, while the minimum instance value is 17.18% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31838
    Memory Throughput                   %        66.30
    DRAM Throughput                     %        66.30
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        29.01
    SM Active Cycles                cycle     27224.55
    Compute (SM) Throughput             %        17.15
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.55
    Achieved Active Warps Per SM           warp        11.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.89%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1780736
    Average L1 Active Cycles         cycle     27224.55
    Total L1 Elapsed Cycles          cycle      4046322
    Average L2 Active Cycles         cycle     22994.44
    Total L2 Elapsed Cycles          cycle      1014048
    Average SM Active Cycles         cycle     27224.55
    Total SM Elapsed Cycles          cycle      4046322
    Average SMSP Active Cycles       cycle     27136.24
    Total SMSP Elapsed Cycles        cycle     16185288
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.713%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.63% above the average, while the minimum instance value is 13.47% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.072%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.07% above the average, while the minimum instance value is 13.14% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.713%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.63% above the average, while the minimum instance value is 13.47% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        33114
    Memory Throughput                   %        64.81
    DRAM Throughput                     %        64.81
    Duration                      usecond        14.88
    L1/TEX Cache Throughput             %        27.80
    L2 Cache Throughput                 %        28.04
    SM Active Cycles                cycle        27407
    Compute (SM) Throughput             %        16.89
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1821696
    Average L1 Active Cycles         cycle        27407
    Total L1 Elapsed Cycles          cycle      4106902
    Average L2 Active Cycles         cycle     23140.42
    Total L2 Elapsed Cycles          cycle      1049148
    Average SM Active Cycles         cycle        27407
    Total SM Elapsed Cycles          cycle      4106902
    Average SMSP Active Cycles       cycle     27444.27
    Total SMSP Elapsed Cycles        cycle     16427608
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.622%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 10.09% above the average, while the minimum instance value is 23.13% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.208%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.26% above the average, while the minimum instance value is 19.57% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.622%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 10.09% above the average, while the minimum instance value is 23.13% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32557
    Memory Throughput                   %        65.62
    DRAM Throughput                     %        65.62
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.75
    L2 Cache Throughput                 %        28.47
    SM Active Cycles                cycle     27457.17
    Compute (SM) Throughput             %        17.27
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.70
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.6%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1799168
    Average L1 Active Cycles         cycle     27457.17
    Total L1 Elapsed Cycles          cycle      4016830
    Average L2 Active Cycles         cycle     22908.83
    Total L2 Elapsed Cycles          cycle      1033236
    Average SM Active Cycles         cycle     27457.17
    Total SM Elapsed Cycles          cycle      4016830
    Average SMSP Active Cycles       cycle     26958.23
    Total SMSP Elapsed Cycles        cycle     16067320
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.673%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.63% above the average, while the minimum instance value is 21.42% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.278%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.14% above the average, while the minimum instance value is 14.90% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.673%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.63% above the average, while the minimum instance value is 21.42% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117043
    Memory Throughput                   %        91.48
    DRAM Throughput                     %        91.48
    Duration                      usecond        52.58
    L1/TEX Cache Throughput             %        10.59
    L2 Cache Throughput                 %        39.76
    SM Active Cycles                cycle    108841.18
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.47
    Achieved Active Warps Per SM           warp        44.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491806.67
    Total DRAM Elapsed Cycles        cycle      6451200
    Average L1 Active Cycles         cycle    108841.18
    Total L1 Elapsed Cycles          cycle     14977944
    Average L2 Active Cycles         cycle     98014.17
    Total L2 Elapsed Cycles          cycle      3708648
    Average SM Active Cycles         cycle    108841.18
    Total SM Elapsed Cycles          cycle     14977944
    Average SMSP Active Cycles       cycle    108624.08
    Total SMSP Elapsed Cycles        cycle     59911776
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31630
    Memory Throughput                   %        66.84
    DRAM Throughput                     %        66.84
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        28.31
    L2 Cache Throughput                 %        29.20
    SM Active Cycles                cycle     26902.88
    Compute (SM) Throughput             %        16.93
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.35%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1766400
    Average L1 Active Cycles         cycle     26902.88
    Total L1 Elapsed Cycles          cycle      4097554
    Average L2 Active Cycles         cycle     22932.69
    Total L2 Elapsed Cycles          cycle      1007532
    Average SM Active Cycles         cycle     26902.88
    Total SM Elapsed Cycles          cycle      4097554
    Average SMSP Active Cycles       cycle     27324.65
    Total SMSP Elapsed Cycles        cycle     16390216
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.02%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.97% above the average, while the minimum instance value is 19.86% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.397%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.84% above the average, while the minimum instance value is 14.97% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.02%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.97% above the average, while the minimum instance value is 19.86% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31964
    Memory Throughput                   %        66.54
    DRAM Throughput                     %        66.54
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.86
    L2 Cache Throughput                 %        28.96
    SM Active Cycles                cycle     27325.48
    Compute (SM) Throughput             %        17.15
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.59
    Achieved Active Warps Per SM           warp        11.80
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.81%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98396
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     27325.48
    Total L1 Elapsed Cycles          cycle      4045338
    Average L2 Active Cycles         cycle     22906.11
    Total L2 Elapsed Cycles          cycle      1015560
    Average SM Active Cycles         cycle     27325.48
    Total SM Elapsed Cycles          cycle      4045338
    Average SMSP Active Cycles       cycle     26991.71
    Total SMSP Elapsed Cycles        cycle     16181352
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.161%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.97% above the average, while the minimum instance value is 13.58% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.667%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.64% above the average, while the minimum instance value is 17.46% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.161%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.97% above the average, while the minimum instance value is 13.58% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31965
    Memory Throughput                   %        66.84
    DRAM Throughput                     %        66.84
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        27.69
    L2 Cache Throughput                 %        29.01
    SM Active Cycles                cycle     27513.52
    Compute (SM) Throughput             %        17.16
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.68
    Achieved Active Warps Per SM           warp        11.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.64%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1766400
    Average L1 Active Cycles         cycle     27513.52
    Total L1 Elapsed Cycles          cycle      4043572
    Average L2 Active Cycles         cycle     23031.50
    Total L2 Elapsed Cycles          cycle      1014120
    Average SM Active Cycles         cycle     27513.52
    Total SM Elapsed Cycles          cycle      4043572
    Average SMSP Active Cycles       cycle     27397.66
    Total SMSP Elapsed Cycles        cycle     16174288
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.6%                                                                                            
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.46% above the average, while the minimum instance value is 10.08% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32251
    Memory Throughput                   %        66.26
    DRAM Throughput                     %        66.26
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.75
    L2 Cache Throughput                 %        28.74
    SM Active Cycles                cycle     27438.68
    Compute (SM) Throughput             %        17.33
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.49
    Achieved Active Warps Per SM           warp        11.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.02%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1781760
    Average L1 Active Cycles         cycle     27438.68
    Total L1 Elapsed Cycles          cycle      4004324
    Average L2 Active Cycles         cycle     22916.11
    Total L2 Elapsed Cycles          cycle      1023480
    Average SM Active Cycles         cycle     27438.68
    Total SM Elapsed Cycles          cycle      4004324
    Average SMSP Active Cycles       cycle     27003.88
    Total SMSP Elapsed Cycles        cycle     16017296
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.285%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.03% above the average, while the minimum instance value is 18.22% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.011%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.12% above the average, while the minimum instance value is 14.80% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.285%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.03% above the average, while the minimum instance value is 18.22% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.11
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9756
    Memory Throughput                   %         5.80
    DRAM Throughput                     %         0.76
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.92
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4022.70
    Compute (SM) Throughput             %         8.99
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.88
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.23%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          340
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      4022.70
    Total L1 Elapsed Cycles          cycle      1236098
    Average L2 Active Cycles         cycle       140.58
    Total L2 Elapsed Cycles          cycle       308628
    Average SM Active Cycles         cycle      4022.70
    Total SM Elapsed Cycles          cycle      1236098
    Average SMSP Active Cycles       cycle      3461.23
    Total SMSP Elapsed Cycles        cycle      4944392
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.919%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.01% above the average, while the minimum instance value is 23.58% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.741%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.81% above the average, while the minimum instance value is 28.12% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.919%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.01% above the average, while the minimum instance value is 23.58% below the      
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117667
    Memory Throughput                   %        91.49
    DRAM Throughput                     %        91.49
    Duration                      usecond        52.80
    L1/TEX Cache Throughput             %        10.44
    L2 Cache Throughput                 %        39.56
    SM Active Cycles                cycle    110462.92
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.99
    Achieved Active Warps Per SM           warp        43.67
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494286.67
    Total DRAM Elapsed Cycles        cycle      6482944
    Average L1 Active Cycles         cycle    110462.92
    Total L1 Elapsed Cycles          cycle     14983974
    Average L2 Active Cycles         cycle     97975.22
    Total L2 Elapsed Cycles          cycle      3727116
    Average SM Active Cycles         cycle    110462.92
    Total SM Elapsed Cycles          cycle     14983974
    Average SMSP Active Cycles       cycle    109229.98
    Total SMSP Elapsed Cycles        cycle     59935896
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31983
    Memory Throughput                   %        66.11
    DRAM Throughput                     %        66.11
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        28.86
    SM Active Cycles                cycle     27219.23
    Compute (SM) Throughput             %        17.15
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.32
    Achieved Active Warps Per SM           warp        11.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.35%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1785856
    Average L1 Active Cycles         cycle     27219.23
    Total L1 Elapsed Cycles          cycle      4045154
    Average L2 Active Cycles         cycle     22880.58
    Total L2 Elapsed Cycles          cycle      1019196
    Average SM Active Cycles         cycle     27219.23
    Total SM Elapsed Cycles          cycle      4045154
    Average SMSP Active Cycles       cycle     27069.35
    Total SMSP Elapsed Cycles        cycle     16180616
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.345%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.21% above the average, while the minimum instance value is 16.43% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.39%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.29% above the average, while the minimum instance value is 17.22% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.345%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.21% above the average, while the minimum instance value is 16.43% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32515
    Memory Throughput                   %        65.73
    DRAM Throughput                     %        65.73
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.84
    L2 Cache Throughput                 %        28.51
    SM Active Cycles                cycle     27377.40
    Compute (SM) Throughput             %        17.10
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.64
    Achieved Active Warps Per SM           warp        11.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.72%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1796096
    Average L1 Active Cycles         cycle     27377.40
    Total L1 Elapsed Cycles          cycle      4056266
    Average L2 Active Cycles         cycle     22859.83
    Total L2 Elapsed Cycles          cycle      1031724
    Average SM Active Cycles         cycle     27377.40
    Total SM Elapsed Cycles          cycle      4056266
    Average SMSP Active Cycles       cycle     27044.35
    Total SMSP Elapsed Cycles        cycle     16225064
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.382%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.39% above the average, while the minimum instance value is 13.94% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.626%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.59% above the average, while the minimum instance value is 16.23% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.382%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.39% above the average, while the minimum instance value is 13.94% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32336
    Memory Throughput                   %        66.15
    DRAM Throughput                     %        66.15
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.61
    L2 Cache Throughput                 %        28.68
    SM Active Cycles                cycle     27588.76
    Compute (SM) Throughput             %        17.12
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.57
    Achieved Active Warps Per SM           warp        11.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.86%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27588.76
    Total L1 Elapsed Cycles          cycle      4052234
    Average L2 Active Cycles         cycle     22987.53
    Total L2 Elapsed Cycles          cycle      1025532
    Average SM Active Cycles         cycle     27588.76
    Total SM Elapsed Cycles          cycle      4052234
    Average SMSP Active Cycles       cycle     27103.61
    Total SMSP Elapsed Cycles        cycle     16208936
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.809%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.67% above the average, while the minimum instance value is 15.33% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.244%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.29% above the average, while the minimum instance value is 20.80% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.809%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.67% above the average, while the minimum instance value is 15.33% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.07
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9701
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.06
    L2 Cache Throughput                 %         1.91
    SM Active Cycles                cycle      3983.04
    Compute (SM) Throughput             %         9.13
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.09
    Achieved Active Warps Per SM           warp        12.04
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.82%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       330.67
    Total DRAM Elapsed Cycles        cycle       533504
    Average L1 Active Cycles         cycle      3983.04
    Total L1 Elapsed Cycles          cycle      1214758
    Average L2 Active Cycles         cycle        82.75
    Total L2 Elapsed Cycles          cycle       306792
    Average SM Active Cycles         cycle      3983.04
    Total SM Elapsed Cycles          cycle      1214758
    Average SMSP Active Cycles       cycle      3446.10
    Total SMSP Elapsed Cycles        cycle      4859032
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.158%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.44% above the average, while the minimum instance value is 23.30% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.972%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.20% above the average, while the minimum instance value is 27.19% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.158%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.44% above the average, while the minimum instance value is 23.30% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31675
    Memory Throughput                   %        66.80
    DRAM Throughput                     %        66.80
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        28.10
    L2 Cache Throughput                 %        29.16
    SM Active Cycles                cycle     27113.08
    Compute (SM) Throughput             %        17.00
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.66
    Achieved Active Warps Per SM           warp        11.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.68%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1767424
    Average L1 Active Cycles         cycle     27113.08
    Total L1 Elapsed Cycles          cycle      4081200
    Average L2 Active Cycles         cycle     23087.50
    Total L2 Elapsed Cycles          cycle      1008720
    Average SM Active Cycles         cycle     27113.08
    Total SM Elapsed Cycles          cycle      4081200
    Average SMSP Active Cycles       cycle     27312.07
    Total SMSP Elapsed Cycles        cycle     16324800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.11%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.13% above the average, while the minimum instance value is 11.68% below the average.      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117401
    Memory Throughput                   %        91.32
    DRAM Throughput                     %        91.32
    Duration                      usecond        52.61
    L1/TEX Cache Throughput             %        10.55
    L2 Cache Throughput                 %        39.67
    SM Active Cycles                cycle    109293.62
    Compute (SM) Throughput             %        10.00
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.63
    Achieved Active Warps Per SM           warp        43.98
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491626.67
    Total DRAM Elapsed Cycles        cycle      6460416
    Average L1 Active Cycles         cycle    109293.62
    Total L1 Elapsed Cycles          cycle     15069178
    Average L2 Active Cycles         cycle     98031.92
    Total L2 Elapsed Cycles          cycle      3716748
    Average SM Active Cycles         cycle    109293.62
    Total SM Elapsed Cycles          cycle     15069178
    Average SMSP Active Cycles       cycle    108817.78
    Total SMSP Elapsed Cycles        cycle     60276712
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32280
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        28.11
    L2 Cache Throughput                 %        28.67
    SM Active Cycles                cycle     27120.62
    Compute (SM) Throughput             %        17.22
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.36%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27120.62
    Total L1 Elapsed Cycles          cycle      4027700
    Average L2 Active Cycles         cycle     22817.69
    Total L2 Elapsed Cycles          cycle      1025964
    Average SM Active Cycles         cycle     27120.62
    Total SM Elapsed Cycles          cycle      4027700
    Average SMSP Active Cycles       cycle     26866.71
    Total SMSP Elapsed Cycles        cycle     16110800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.571%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.62% above the average, while the minimum instance value is 16.69% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.562%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.51% above the average, while the minimum instance value is 12.97% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.571%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.62% above the average, while the minimum instance value is 16.69% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        31961
    Memory Throughput                   %        67.03
    DRAM Throughput                     %        67.03
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.70
    L2 Cache Throughput                 %        29.05
    SM Active Cycles                cycle     27511.57
    Compute (SM) Throughput             %        17.23
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.62
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.75%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1761280
    Average L1 Active Cycles         cycle     27511.57
    Total L1 Elapsed Cycles          cycle      4027080
    Average L2 Active Cycles         cycle     22757.25
    Total L2 Elapsed Cycles          cycle      1012716
    Average SM Active Cycles         cycle     27511.57
    Total SM Elapsed Cycles          cycle      4027080
    Average SMSP Active Cycles       cycle     27031.47
    Total SMSP Elapsed Cycles        cycle     16108320
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.212%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.07% above the average, while the minimum instance value is 16.97% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.14
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9745
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.93
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      4021.09
    Compute (SM) Throughput             %         9.13
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.38%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       337.33
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      4021.09
    Total L1 Elapsed Cycles          cycle      1214680
    Average L2 Active Cycles         cycle        87.92
    Total L2 Elapsed Cycles          cycle       308052
    Average SM Active Cycles         cycle      4021.09
    Total SM Elapsed Cycles          cycle      1214680
    Average SMSP Active Cycles       cycle      3481.75
    Total SMSP Elapsed Cycles        cycle      4858720
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.097%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.11% above the average, while the minimum instance value is 23.33% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.188%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.59% above the average, while the minimum instance value is 24.75% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.097%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.11% above the average, while the minimum instance value is 23.33% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32107
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        28.09
    L2 Cache Throughput                 %        28.76
    SM Active Cycles                cycle     27124.23
    Compute (SM) Throughput             %        16.95
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.74
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.51%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27124.23
    Total L1 Elapsed Cycles          cycle      4092106
    Average L2 Active Cycles         cycle     22861.64
    Total L2 Elapsed Cycles          cycle      1022760
    Average SM Active Cycles         cycle     27124.23
    Total SM Elapsed Cycles          cycle      4092106
    Average SMSP Active Cycles       cycle     27054.74
    Total SMSP Elapsed Cycles        cycle     16368424
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.314%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.44% above the average, while the minimum instance value is 19.78% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.827%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.25% above the average, while the minimum instance value is 18.47% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.314%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.44% above the average, while the minimum instance value is 19.78% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32200
    Memory Throughput                   %        66.03
    DRAM Throughput                     %        66.03
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.19
    L2 Cache Throughput                 %        28.74
    SM Active Cycles                cycle     27022.83
    Compute (SM) Throughput             %        16.92
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.87
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.25%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1787904
    Average L1 Active Cycles         cycle     27022.83
    Total L1 Elapsed Cycles          cycle      4101408
    Average L2 Active Cycles         cycle     22752.53
    Total L2 Elapsed Cycles          cycle      1023444
    Average SM Active Cycles         cycle     27022.83
    Total SM Elapsed Cycles          cycle      4101408
    Average SMSP Active Cycles       cycle     27016.21
    Total SMSP Elapsed Cycles        cycle     16405632
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.413%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.60% above the average, while the minimum instance value is 17.61% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.995%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.11% above the average, while the minimum instance value is 15.05% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.413%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.60% above the average, while the minimum instance value is 17.61% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118874
    Memory Throughput                   %        90.47
    DRAM Throughput                     %        90.47
    Duration                      usecond        53.25
    L1/TEX Cache Throughput             %        10.57
    L2 Cache Throughput                 %        39.19
    SM Active Cycles                cycle    109031.11
    Compute (SM) Throughput             %        10.08
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.18
    Achieved Active Warps Per SM           warp        44.25
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    492853.33
    Total DRAM Elapsed Cycles        cycle      6537216
    Average L1 Active Cycles         cycle    109031.11
    Total L1 Elapsed Cycles          cycle     14951706
    Average L2 Active Cycles         cycle     97915.75
    Total L2 Elapsed Cycles          cycle      3762828
    Average SM Active Cycles         cycle    109031.11
    Total SM Elapsed Cycles          cycle     14951706
    Average SMSP Active Cycles       cycle    108312.32
    Total SMSP Elapsed Cycles        cycle     59806824
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.485%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.88% above the average, while the minimum instance value is 22.57% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.245%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.66% above the average, while the minimum instance value is 18.15% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.485%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.88% above the average, while the minimum instance value is 22.57% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32539
    Memory Throughput                   %        65.88
    DRAM Throughput                     %        65.88
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.39
    L2 Cache Throughput                 %        28.53
    SM Active Cycles                cycle     27800.99
    Compute (SM) Throughput             %        16.91
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.30
    Achieved Active Warps Per SM           warp        11.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.4%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98388
    Total DRAM Elapsed Cycles        cycle      1792000
    Average L1 Active Cycles         cycle     27800.99
    Total L1 Elapsed Cycles          cycle      4101646
    Average L2 Active Cycles         cycle     22953.14
    Total L2 Elapsed Cycles          cycle      1030932
    Average SM Active Cycles         cycle     27800.99
    Total SM Elapsed Cycles          cycle      4101646
    Average SMSP Active Cycles       cycle     27070.67
    Total SMSP Elapsed Cycles        cycle     16406584
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.657%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.52% above the average, while the minimum instance value is 16.04% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.208%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.53% above the average, while the minimum instance value is 21.24% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.657%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.52% above the average, while the minimum instance value is 16.04% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.11
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9732
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.93
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      4020.40
    Compute (SM) Throughput             %         9.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.69
    Achieved Active Warps Per SM           warp        11.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.63%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       333.33
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      4020.40
    Total L1 Elapsed Cycles          cycle      1215596
    Average L2 Active Cycles         cycle        84.08
    Total L2 Elapsed Cycles          cycle       307764
    Average SM Active Cycles         cycle      4020.40
    Total SM Elapsed Cycles          cycle      1215596
    Average SMSP Active Cycles       cycle      3472.58
    Total SMSP Elapsed Cycles        cycle      4862384
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.164%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.29% above the average, while the minimum instance value is 23.74% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.118%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.47% above the average, while the minimum instance value is 27.58% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.164%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.29% above the average, while the minimum instance value is 23.74% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32009
    Memory Throughput                   %        66.14
    DRAM Throughput                     %        66.14
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.98
    L2 Cache Throughput                 %        28.83
    SM Active Cycles                cycle     27233.07
    Compute (SM) Throughput             %        16.77
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.74
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.52%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27233.07
    Total L1 Elapsed Cycles          cycle      4136680
    Average L2 Active Cycles         cycle     23074.03
    Total L2 Elapsed Cycles          cycle      1020276
    Average SM Active Cycles         cycle     27233.07
    Total SM Elapsed Cycles          cycle      4136680
    Average SMSP Active Cycles       cycle     27307.90
    Total SMSP Elapsed Cycles        cycle     16546720
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.765%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.84% above the average, while the minimum instance value is 12.90% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.812%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.88% above the average, while the minimum instance value is 13.60% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.765%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.84% above the average, while the minimum instance value is 12.90% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32008
    Memory Throughput                   %        65.99
    DRAM Throughput                     %        65.99
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.18
    L2 Cache Throughput                 %        28.85
    SM Active Cycles                cycle     27024.64
    Compute (SM) Throughput             %        17.06
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.96
    Achieved Active Warps Per SM           warp        11.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.09%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1788928
    Average L1 Active Cycles         cycle     27024.64
    Total L1 Elapsed Cycles          cycle      4066650
    Average L2 Active Cycles         cycle     23023.64
    Total L2 Elapsed Cycles          cycle      1019700
    Average SM Active Cycles         cycle     27024.64
    Total SM Elapsed Cycles          cycle      4066650
    Average SMSP Active Cycles       cycle     27297.48
    Total SMSP Elapsed Cycles        cycle     16266600
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.434%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.39% above the average, while the minimum instance value is 13.50% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.916%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.89% above the average, while the minimum instance value is 10.93% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.434%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.39% above the average, while the minimum instance value is 13.50% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31979
    Memory Throughput                   %        66.49
    DRAM Throughput                     %        66.49
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.83
    L2 Cache Throughput                 %        28.95
    SM Active Cycles                cycle     27390.58
    Compute (SM) Throughput             %        17.12
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.63
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.74%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1775616
    Average L1 Active Cycles         cycle     27390.58
    Total L1 Elapsed Cycles          cycle      4052634
    Average L2 Active Cycles         cycle     23072.08
    Total L2 Elapsed Cycles          cycle      1016208
    Average SM Active Cycles         cycle     27390.58
    Total SM Elapsed Cycles          cycle      4052634
    Average SMSP Active Cycles       cycle     27035.96
    Total SMSP Elapsed Cycles        cycle     16210536
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.964%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.98% above the average, while the minimum instance value is 18.45% below the average.      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       120239
    Memory Throughput                   %        89.75
    DRAM Throughput                     %        89.75
    Duration                      usecond        53.86
    L1/TEX Cache Throughput             %        10.36
    L2 Cache Throughput                 %        38.74
    SM Active Cycles                cycle    111268.98
    Compute (SM) Throughput             %        10.02
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.86
    Achieved Active Warps Per SM           warp        43.61
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       494428
    Total DRAM Elapsed Cycles        cycle      6610944
    Average L1 Active Cycles         cycle    111268.98
    Total L1 Elapsed Cycles          cycle     15039730
    Average L2 Active Cycles         cycle     98163.28
    Total L2 Elapsed Cycles          cycle      3806244
    Average SM Active Cycles         cycle    111268.98
    Total SM Elapsed Cycles          cycle     15039730
    Average SMSP Active Cycles       cycle    109003.54
    Total SMSP Elapsed Cycles        cycle     60158920
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.008%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.29% above the average, while the minimum instance value is 16.36% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.772%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.22% above the average, while the minimum instance value is 13.88% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.008%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.29% above the average, while the minimum instance value is 16.36% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.14
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9751
    Memory Throughput                   %         5.91
    DRAM Throughput                     %         0.76
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.92
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4023.34
    Compute (SM) Throughput             %         9.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       338.67
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      4023.34
    Total L1 Elapsed Cycles          cycle      1213886
    Average L2 Active Cycles         cycle        83.69
    Total L2 Elapsed Cycles          cycle       308520
    Average SM Active Cycles         cycle      4023.34
    Total SM Elapsed Cycles          cycle      1213886
    Average SMSP Active Cycles       cycle      3459.61
    Total SMSP Elapsed Cycles        cycle      4855544
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.368%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 17.37% above the average, while the minimum instance value is 23.99% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.454%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 20.43% above the average, while the minimum instance value is 26.26% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.368%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 17.37% above the average, while the minimum instance value is 23.99% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32407
    Memory Throughput                   %        65.21
    DRAM Throughput                     %        65.21
    Duration                      usecond        14.78
    L1/TEX Cache Throughput             %        28.23
    L2 Cache Throughput                 %        28.50
    SM Active Cycles                cycle     26984.20
    Compute (SM) Throughput             %        16.90
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.38%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1810432
    Average L1 Active Cycles         cycle     26984.20
    Total L1 Elapsed Cycles          cycle      4104944
    Average L2 Active Cycles         cycle     23001.03
    Total L2 Elapsed Cycles          cycle      1032048
    Average SM Active Cycles         cycle     26984.20
    Total SM Elapsed Cycles          cycle      4104944
    Average SMSP Active Cycles       cycle     27310.73
    Total SMSP Elapsed Cycles        cycle     16419776
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.764%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.04% above the average, while the minimum instance value is 17.34% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.173%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.07% above the average, while the minimum instance value is 11.10% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.764%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.04% above the average, while the minimum instance value is 17.34% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32683
    Memory Throughput                   %        65.10
    DRAM Throughput                     %        65.10
    Duration                      usecond        14.82
    L1/TEX Cache Throughput             %        27.97
    L2 Cache Throughput                 %        28.32
    SM Active Cycles                cycle     27250.19
    Compute (SM) Throughput             %        16.54
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.67
    Achieved Active Warps Per SM           warp        11.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.66%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1813504
    Average L1 Active Cycles         cycle     27250.19
    Total L1 Elapsed Cycles          cycle      4194518
    Average L2 Active Cycles         cycle     22894.75
    Total L2 Elapsed Cycles          cycle      1038852
    Average SM Active Cycles         cycle     27250.19
    Total SM Elapsed Cycles          cycle      4194518
    Average SMSP Active Cycles       cycle     27042.65
    Total SMSP Elapsed Cycles        cycle     16778072
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.175%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.43% above the average, while the minimum instance value is 17.82% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.301%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.42% above the average, while the minimum instance value is 12.35% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.175%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.43% above the average, while the minimum instance value is 17.82% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32454
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        27.74
    L2 Cache Throughput                 %        28.56
    SM Active Cycles                cycle     27460.62
    Compute (SM) Throughput             %        16.62
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.55
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.91%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     27460.62
    Total L1 Elapsed Cycles          cycle      4175186
    Average L2 Active Cycles         cycle     22969.08
    Total L2 Elapsed Cycles          cycle      1030068
    Average SM Active Cycles         cycle     27460.62
    Total SM Elapsed Cycles          cycle      4175186
    Average SMSP Active Cycles       cycle     27233.30
    Total SMSP Elapsed Cycles        cycle     16700744
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.013%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.14% above the average, while the minimum instance value is 13.09% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.506%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.59% above the average, while the minimum instance value is 10.59% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.013%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.14% above the average, while the minimum instance value is 13.09% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32020
    Memory Throughput                   %        66.76
    DRAM Throughput                     %        66.76
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        27.85
    L2 Cache Throughput                 %        28.99
    SM Active Cycles                cycle     27358.30
    Compute (SM) Throughput             %        17.19
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.66
    Achieved Active Warps Per SM           warp        11.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.69%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1768448
    Average L1 Active Cycles         cycle     27358.30
    Total L1 Elapsed Cycles          cycle      4034962
    Average L2 Active Cycles         cycle     22838.50
    Total L2 Elapsed Cycles          cycle      1014804
    Average SM Active Cycles         cycle     27358.30
    Total SM Elapsed Cycles          cycle      4034962
    Average SMSP Active Cycles       cycle     27037.69
    Total SMSP Elapsed Cycles        cycle     16139848
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.909%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.81% above the average, while the minimum instance value is 13.32% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.822%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.95% above the average, while the minimum instance value is 17.98% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.909%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.81% above the average, while the minimum instance value is 13.32% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117612
    Memory Throughput                   %        91.07
    DRAM Throughput                     %        91.07
    Duration                      usecond        52.77
    L1/TEX Cache Throughput             %        10.66
    L2 Cache Throughput                 %        39.58
    SM Active Cycles                cycle    108127.31
    Compute (SM) Throughput             %        10.07
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        93.84
    Achieved Active Warps Per SM           warp        45.04
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491689.33
    Total DRAM Elapsed Cycles        cycle      6478848
    Average L1 Active Cycles         cycle    108127.31
    Total L1 Elapsed Cycles          cycle     14968326
    Average L2 Active Cycles         cycle     98289.42
    Total L2 Elapsed Cycles          cycle      3725820
    Average SM Active Cycles         cycle    108127.31
    Total SM Elapsed Cycles          cycle     14968326
    Average SMSP Active Cycles       cycle    108651.17
    Total SMSP Elapsed Cycles        cycle     59873304
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.063%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.48% above the average, while the minimum instance value is 19.15% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.063%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.48% above the average, while the minimum instance value is 19.15% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31657
    Memory Throughput                   %        66.60
    DRAM Throughput                     %        66.60
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        28.11
    L2 Cache Throughput                 %        29.13
    SM Active Cycles                cycle     27100.17
    Compute (SM) Throughput             %        16.70
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.74
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.52%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1772544
    Average L1 Active Cycles         cycle     27100.17
    Total L1 Elapsed Cycles          cycle      4153348
    Average L2 Active Cycles         cycle     23213.94
    Total L2 Elapsed Cycles          cycle      1009908
    Average SM Active Cycles         cycle     27100.17
    Total SM Elapsed Cycles          cycle      4153348
    Average SMSP Active Cycles       cycle     27145.81
    Total SMSP Elapsed Cycles        cycle     16613392
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.155%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.17% above the average, while the minimum instance value is 19.43% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.228%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.64% above the average, while the minimum instance value is 16.62% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.155%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.17% above the average, while the minimum instance value is 19.43% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32491
    Memory Throughput                   %        64.95
    DRAM Throughput                     %        64.95
    Duration                      usecond        14.85
    L1/TEX Cache Throughput             %        28.23
    L2 Cache Throughput                 %        28.39
    SM Active Cycles                cycle     26994.84
    Compute (SM) Throughput             %        17.16
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.91
    Achieved Active Warps Per SM           warp        11.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.19%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1817600
    Average L1 Active Cycles         cycle     26994.84
    Total L1 Elapsed Cycles          cycle      4043748
    Average L2 Active Cycles         cycle     23011.72
    Total L2 Elapsed Cycles          cycle      1036224
    Average SM Active Cycles         cycle     26994.84
    Total SM Elapsed Cycles          cycle      4043748
    Average SMSP Active Cycles       cycle     27094.34
    Total SMSP Elapsed Cycles        cycle     16174992
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.132%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.35% above the average, while the minimum instance value is 16.91% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.592%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.52% above the average, while the minimum instance value is 18.46% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.132%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.35% above the average, while the minimum instance value is 16.91% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32422
    Memory Throughput                   %        65.54
    DRAM Throughput                     %        65.54
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        28.15
    L2 Cache Throughput                 %        28.56
    SM Active Cycles                cycle     27079.61
    Compute (SM) Throughput             %        16.76
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.04
    Achieved Active Warps Per SM           warp        12.02
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.93%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1801216
    Average L1 Active Cycles         cycle     27079.61
    Total L1 Elapsed Cycles          cycle      4138656
    Average L2 Active Cycles         cycle     22881.42
    Total L2 Elapsed Cycles          cycle      1029960
    Average SM Active Cycles         cycle     27079.61
    Total SM Elapsed Cycles          cycle      4138656
    Average SMSP Active Cycles       cycle     26892.33
    Total SMSP Elapsed Cycles        cycle     16554624
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.356%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.78% above the average, while the minimum instance value is 13.79% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.029%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.25% above the average, while the minimum instance value is 20.99% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.356%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.78% above the average, while the minimum instance value is 13.79% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32132
    Memory Throughput                   %        66.60
    DRAM Throughput                     %        66.60
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.65
    L2 Cache Throughput                 %        28.89
    SM Active Cycles                cycle     27572.55
    Compute (SM) Throughput             %        17.11
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.60
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.8%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1772544
    Average L1 Active Cycles         cycle     27572.55
    Total L1 Elapsed Cycles          cycle      4054994
    Average L2 Active Cycles         cycle     22969.50
    Total L2 Elapsed Cycles          cycle      1018368
    Average SM Active Cycles         cycle     27572.55
    Total SM Elapsed Cycles          cycle      4054994
    Average SMSP Active Cycles       cycle     27137.48
    Total SMSP Elapsed Cycles        cycle     16219976
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.67%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.51% above the average, while the minimum instance value is 15.01% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.39%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.46% above the average, while the minimum instance value is 23.22% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.67%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.51% above the average, while the minimum instance value is 15.01% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32548
    Memory Throughput                   %        65.58
    DRAM Throughput                     %        65.58
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.74
    L2 Cache Throughput                 %        28.47
    SM Active Cycles                cycle     27453.78
    Compute (SM) Throughput             %        16.87
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.38
    Achieved Active Warps Per SM           warp        12.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.25%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1800192
    Average L1 Active Cycles         cycle     27453.78
    Total L1 Elapsed Cycles          cycle      4112806
    Average L2 Active Cycles         cycle     22924.53
    Total L2 Elapsed Cycles          cycle      1033236
    Average SM Active Cycles         cycle     27453.78
    Total SM Elapsed Cycles          cycle      4112806
    Average SMSP Active Cycles       cycle     26810.79
    Total SMSP Elapsed Cycles        cycle     16451224
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.438%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.54% above the average, while the minimum instance value is 18.32% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.984%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.17% above the average, while the minimum instance value is 20.66% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.438%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.54% above the average, while the minimum instance value is 18.32% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117492
    Memory Throughput                   %        91.13
    DRAM Throughput                     %        91.13
    Duration                      usecond        52.74
    L1/TEX Cache Throughput             %        10.57
    L2 Cache Throughput                 %        39.62
    SM Active Cycles                cycle    109100.04
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.11
    Achieved Active Warps Per SM           warp        44.21
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491804
    Total DRAM Elapsed Cycles        cycle      6475776
    Average L1 Active Cycles         cycle    109100.04
    Total L1 Elapsed Cycles          cycle     14981450
    Average L2 Active Cycles         cycle     97956.69
    Total L2 Elapsed Cycles          cycle      3722112
    Average SM Active Cycles         cycle    109100.04
    Total SM Elapsed Cycles          cycle     14981450
    Average SMSP Active Cycles       cycle    108634.87
    Total SMSP Elapsed Cycles        cycle     59925800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.546%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.97% above the average, while the minimum instance value is 20.62% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31514
    Memory Throughput                   %        67.15
    DRAM Throughput                     %        67.15
    Duration                      usecond        14.37
    L1/TEX Cache Throughput             %        28.18
    L2 Cache Throughput                 %        29.30
    SM Active Cycles                cycle     27030.25
    Compute (SM) Throughput             %        17.23
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp        11.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.41%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1758208
    Average L1 Active Cycles         cycle     27030.25
    Total L1 Elapsed Cycles          cycle      4025416
    Average L2 Active Cycles         cycle        22889
    Total L2 Elapsed Cycles          cycle      1003788
    Average SM Active Cycles         cycle     27030.25
    Total SM Elapsed Cycles          cycle      4025416
    Average SMSP Active Cycles       cycle     27400.25
    Total SMSP Elapsed Cycles        cycle     16101664
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32053
    Memory Throughput                   %        65.88
    DRAM Throughput                     %        65.88
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.79
    L2 Cache Throughput                 %        28.79
    SM Active Cycles                cycle     27414.95
    Compute (SM) Throughput             %        16.91
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.46
    Achieved Active Warps Per SM           warp        11.74
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.07%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1792000
    Average L1 Active Cycles         cycle     27414.95
    Total L1 Elapsed Cycles          cycle      4103716
    Average L2 Active Cycles         cycle     22873.22
    Total L2 Elapsed Cycles          cycle      1021824
    Average SM Active Cycles         cycle     27414.95
    Total SM Elapsed Cycles          cycle      4103716
    Average SMSP Active Cycles       cycle     27205.87
    Total SMSP Elapsed Cycles        cycle     16414864
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.041%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.12% above the average, while the minimum instance value is 19.29% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32960
    Memory Throughput                   %        64.16
    DRAM Throughput                     %        64.16
    Duration                      usecond        15.01
    L1/TEX Cache Throughput             %        27.95
    L2 Cache Throughput                 %        28.01
    SM Active Cycles                cycle     27255.03
    Compute (SM) Throughput             %        16.97
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.60
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.79%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1840128
    Average L1 Active Cycles         cycle     27255.03
    Total L1 Elapsed Cycles          cycle      4087606
    Average L2 Active Cycles         cycle     22788.11
    Total L2 Elapsed Cycles          cycle      1050048
    Average SM Active Cycles         cycle     27255.03
    Total SM Elapsed Cycles          cycle      4087606
    Average SMSP Active Cycles       cycle     26753.88
    Total SMSP Elapsed Cycles        cycle     16350424
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.072%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.46% above the average, while the minimum instance value is 16.95% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.012%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.56% above the average, while the minimum instance value is 19.94% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.072%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.46% above the average, while the minimum instance value is 16.95% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31611
    Memory Throughput                   %        67.71
    DRAM Throughput                     %        67.71
    Duration                      usecond        14.24
    L1/TEX Cache Throughput             %        27.74
    L2 Cache Throughput                 %        29.35
    SM Active Cycles                cycle     27474.91
    Compute (SM) Throughput             %        16.96
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.47
    Achieved Active Warps Per SM           warp        11.75
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.06%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98393.33
    Total DRAM Elapsed Cycles        cycle      1743872
    Average L1 Active Cycles         cycle     27474.91
    Total L1 Elapsed Cycles          cycle      4090424
    Average L2 Active Cycles         cycle     22869.72
    Total L2 Elapsed Cycles          cycle      1002168
    Average SM Active Cycles         cycle     27474.91
    Total SM Elapsed Cycles          cycle      4090424
    Average SMSP Active Cycles       cycle     27144.13
    Total SMSP Elapsed Cycles        cycle     16361696
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle         9742
    Memory Throughput                   %         5.89
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.38
    L1/TEX Cache Throughput             %        14.01
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3995.97
    Compute (SM) Throughput             %         9.13
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.93
    Achieved Active Warps Per SM           warp        11.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.15%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       330.67
    Total DRAM Elapsed Cycles        cycle       536576
    Average L1 Active Cycles         cycle      3995.97
    Total L1 Elapsed Cycles          cycle      1216222
    Average L2 Active Cycles         cycle       139.17
    Total L2 Elapsed Cycles          cycle       308412
    Average SM Active Cycles         cycle      3995.97
    Total SM Elapsed Cycles          cycle      1216222
    Average SMSP Active Cycles       cycle      3468.85
    Total SMSP Elapsed Cycles        cycle      4864888
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.16%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.40% above the average, while the minimum instance value is 24.45% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.953%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.05% above the average, while the minimum instance value is 27.15% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.16%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.40% above the average, while the minimum instance value is 24.45% below the      
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       118673
    Memory Throughput                   %        90.70
    DRAM Throughput                     %        90.70
    Duration                      usecond        53.25
    L1/TEX Cache Throughput             %        10.42
    L2 Cache Throughput                 %        39.23
    SM Active Cycles                cycle    110643.71
    Compute (SM) Throughput             %        10.00
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.89
    Achieved Active Warps Per SM           warp        43.63
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494085.33
    Total DRAM Elapsed Cycles        cycle      6537216
    Average L1 Active Cycles         cycle    110643.71
    Total L1 Elapsed Cycles          cycle     15077744
    Average L2 Active Cycles         cycle     97937.50
    Total L2 Elapsed Cycles          cycle      3758508
    Average SM Active Cycles         cycle    110643.71
    Total SM Elapsed Cycles          cycle     15077744
    Average SMSP Active Cycles       cycle    108489.15
    Total SMSP Elapsed Cycles        cycle     60310976
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.031%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.46% above the average, while the minimum instance value is 20.03% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32470
    Memory Throughput                   %        65.14
    DRAM Throughput                     %        65.14
    Duration                      usecond        14.82
    L1/TEX Cache Throughput             %        27.85
    L2 Cache Throughput                 %        28.47
    SM Active Cycles                cycle     27348.19
    Compute (SM) Throughput             %        17.14
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.57
    Achieved Active Warps Per SM           warp        11.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.87%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1812480
    Average L1 Active Cycles         cycle     27348.19
    Total L1 Elapsed Cycles          cycle      4047132
    Average L2 Active Cycles         cycle     22867.17
    Total L2 Elapsed Cycles          cycle      1033380
    Average SM Active Cycles         cycle     27348.19
    Total SM Elapsed Cycles          cycle      4047132
    Average SMSP Active Cycles       cycle     27079.98
    Total SMSP Elapsed Cycles        cycle     16188528
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.146%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.11% above the average, while the minimum instance value is 15.59% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.901%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.89% above the average, while the minimum instance value is 14.73% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.146%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.11% above the average, while the minimum instance value is 15.59% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.18
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32259
    Memory Throughput                   %        65.92
    DRAM Throughput                     %        65.92
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        28.13
    L2 Cache Throughput                 %        28.69
    SM Active Cycles                cycle     27087.77
    Compute (SM) Throughput             %        17.08
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.85
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.3%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1790976
    Average L1 Active Cycles         cycle     27087.77
    Total L1 Elapsed Cycles          cycle      4060946
    Average L2 Active Cycles         cycle     22780.44
    Total L2 Elapsed Cycles          cycle      1025388
    Average SM Active Cycles         cycle     27087.77
    Total SM Elapsed Cycles          cycle      4060946
    Average SMSP Active Cycles       cycle     26788.17
    Total SMSP Elapsed Cycles        cycle     16243784
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.6%                                                                                            
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.73% above the average, while the minimum instance value is 14.32% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.208%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.35% above the average, while the minimum instance value is 22.03% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.6%                                                                                            
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.73% above the average, while the minimum instance value is 14.32% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32009
    Memory Throughput                   %        66.76
    DRAM Throughput                     %        66.76
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        27.59
    L2 Cache Throughput                 %        28.98
    SM Active Cycles                cycle     27586.38
    Compute (SM) Throughput             %        17.14
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.55
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.91%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98384
    Total DRAM Elapsed Cycles        cycle      1768448
    Average L1 Active Cycles         cycle     27586.38
    Total L1 Elapsed Cycles          cycle      4047376
    Average L2 Active Cycles         cycle     22837.64
    Total L2 Elapsed Cycles          cycle      1015128
    Average SM Active Cycles         cycle     27586.38
    Total SM Elapsed Cycles          cycle      4047376
    Average SMSP Active Cycles       cycle     26889.24
    Total SMSP Elapsed Cycles        cycle     16189504
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.769%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.78% above the average, while the minimum instance value is 16.16% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.14
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9742
    Memory Throughput                   %         5.89
    DRAM Throughput                     %         0.76
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.06
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3982.68
    Compute (SM) Throughput             %         9.11
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.08
    Achieved Active Warps Per SM           warp        12.04
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.83%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          340
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      3982.68
    Total L1 Elapsed Cycles          cycle      1217904
    Average L2 Active Cycles         cycle        82.39
    Total L2 Elapsed Cycles          cycle       308160
    Average SM Active Cycles         cycle      3982.68
    Total SM Elapsed Cycles          cycle      1217904
    Average SMSP Active Cycles       cycle      3433.78
    Total SMSP Elapsed Cycles        cycle      4871616
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.814%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 21.06% above the average, while the minimum instance value is 23.37% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.724%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.63% above the average, while the minimum instance value is 26.84% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.814%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 21.06% above the average, while the minimum instance value is 23.37% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31868
    Memory Throughput                   %        66.49
    DRAM Throughput                     %        66.49
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.95
    L2 Cache Throughput                 %        29.00
    SM Active Cycles                cycle     27233.02
    Compute (SM) Throughput             %        16.52
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.76
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.47%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1775616
    Average L1 Active Cycles         cycle     27233.02
    Total L1 Elapsed Cycles          cycle      4199266
    Average L2 Active Cycles         cycle     22958.69
    Total L2 Elapsed Cycles          cycle      1014408
    Average SM Active Cycles         cycle     27233.02
    Total SM Elapsed Cycles          cycle      4199266
    Average SMSP Active Cycles       cycle     27423.66
    Total SMSP Elapsed Cycles        cycle     16797064
    -------------------------- ----------- ------------

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117572
    Memory Throughput                   %        91.20
    DRAM Throughput                     %        91.20
    Duration                      usecond        52.67
    L1/TEX Cache Throughput             %        10.59
    L2 Cache Throughput                 %        39.61
    SM Active Cycles                cycle    108894.07
    Compute (SM) Throughput             %        10.04
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.76
    Achieved Active Warps Per SM           warp        44.05
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491622.67
    Total DRAM Elapsed Cycles        cycle      6468608
    Average L1 Active Cycles         cycle    108894.07
    Total L1 Elapsed Cycles          cycle     15009542
    Average L2 Active Cycles         cycle     98109.81
    Total L2 Elapsed Cycles          cycle      3722508
    Average SM Active Cycles         cycle    108894.07
    Total SM Elapsed Cycles          cycle     15009542
    Average SMSP Active Cycles       cycle    108509.08
    Total SMSP Elapsed Cycles        cycle     60038168
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.067%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.48% above the average, while the minimum instance value is 23.17% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32298
    Memory Throughput                   %        66.07
    DRAM Throughput                     %        66.07
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.76
    L2 Cache Throughput                 %        28.71
    SM Active Cycles                cycle     27464.85
    Compute (SM) Throughput             %        17.16
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.48
    Achieved Active Warps Per SM           warp        11.75
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.05%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1786880
    Average L1 Active Cycles         cycle     27464.85
    Total L1 Elapsed Cycles          cycle      4042108
    Average L2 Active Cycles         cycle     22874.64
    Total L2 Elapsed Cycles          cycle      1024668
    Average SM Active Cycles         cycle     27464.85
    Total SM Elapsed Cycles          cycle      4042108
    Average SMSP Active Cycles       cycle     26832.06
    Total SMSP Elapsed Cycles        cycle     16168432
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.488%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.46% above the average, while the minimum instance value is 9.54% below the average.       
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.072%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.32% above the average, while the minimum instance value is 22.38% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.488%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.46% above the average, while the minimum instance value is 9.54% below the        
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32001
    Memory Throughput                   %        66.76
    DRAM Throughput                     %        66.76
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        27.96
    L2 Cache Throughput                 %        28.99
    SM Active Cycles                cycle     27240.87
    Compute (SM) Throughput             %        16.80
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.76
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.49%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1768448
    Average L1 Active Cycles         cycle     27240.87
    Total L1 Elapsed Cycles          cycle      4130658
    Average L2 Active Cycles         cycle     22883.11
    Total L2 Elapsed Cycles          cycle      1014660
    Average SM Active Cycles         cycle     27240.87
    Total SM Elapsed Cycles          cycle      4130658
    Average SMSP Active Cycles       cycle     26849.47
    Total SMSP Elapsed Cycles        cycle     16522632
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.186%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.14% above the average, while the minimum instance value is 19.76% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.111%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.35% above the average, while the minimum instance value is 21.59% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.186%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.14% above the average, while the minimum instance value is 19.76% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.09
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9799
    Memory Throughput                   %         5.79
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.45
    L1/TEX Cache Throughput             %        13.92
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4024.16
    Compute (SM) Throughput             %         8.97
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.84
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.33%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       538624
    Average L1 Active Cycles         cycle      4024.16
    Total L1 Elapsed Cycles          cycle      1236934
    Average L2 Active Cycles         cycle        81.22
    Total L2 Elapsed Cycles          cycle       309816
    Average SM Active Cycles         cycle      4024.16
    Total SM Elapsed Cycles          cycle      1236934
    Average SMSP Active Cycles       cycle      3431.98
    Total SMSP Elapsed Cycles        cycle      4947736
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.033%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.29% above the average, while the minimum instance value is 23.31% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.97%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.63% above the average, while the minimum instance value is 26.49% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.033%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.29% above the average, while the minimum instance value is 23.31% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31714
    Memory Throughput                   %        66.64
    DRAM Throughput                     %        66.64
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        28.22
    L2 Cache Throughput                 %        29.11
    SM Active Cycles                cycle     27000.53
    Compute (SM) Throughput             %        17.10
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1771520
    Average L1 Active Cycles         cycle     27000.53
    Total L1 Elapsed Cycles          cycle      4056512
    Average L2 Active Cycles         cycle     22739.31
    Total L2 Elapsed Cycles          cycle      1010592
    Average SM Active Cycles         cycle     27000.53
    Total SM Elapsed Cycles          cycle      4056512
    Average SMSP Active Cycles       cycle     26973.45
    Total SMSP Elapsed Cycles        cycle     16226048
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.182%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.08% above the average, while the minimum instance value is 12.10% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.165%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.42% above the average, while the minimum instance value is 14.55% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.182%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.08% above the average, while the minimum instance value is 12.10% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31908
    Memory Throughput                   %        66.30
    DRAM Throughput                     %        66.30
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        28.29
    L2 Cache Throughput                 %        28.97
    SM Active Cycles                cycle     26923.54
    Compute (SM) Throughput             %        17.08
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.72
    Achieved Active Warps Per SM           warp        11.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1780736
    Average L1 Active Cycles         cycle     26923.54
    Total L1 Elapsed Cycles          cycle      4061088
    Average L2 Active Cycles         cycle     22705.44
    Total L2 Elapsed Cycles          cycle      1015524
    Average SM Active Cycles         cycle     26923.54
    Total SM Elapsed Cycles          cycle      4061088
    Average SMSP Active Cycles       cycle     26690.13
    Total SMSP Elapsed Cycles        cycle     16244352
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.119%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.03% above the average, while the minimum instance value is 17.15% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.025%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.35% above the average, while the minimum instance value is 11.32% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.119%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.03% above the average, while the minimum instance value is 17.15% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117695
    Memory Throughput                   %        91.37
    DRAM Throughput                     %        91.37
    Duration                      usecond        52.74
    L1/TEX Cache Throughput             %        10.52
    L2 Cache Throughput                 %        39.58
    SM Active Cycles                cycle    109576.37
    Compute (SM) Throughput             %         9.96
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.66
    Achieved Active Warps Per SM           warp        44.00
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       492844
    Total DRAM Elapsed Cycles        cycle      6472704
    Average L1 Active Cycles         cycle    109576.37
    Total L1 Elapsed Cycles          cycle     15129476
    Average L2 Active Cycles         cycle     98247.31
    Total L2 Elapsed Cycles          cycle      3725712
    Average SM Active Cycles         cycle    109576.37
    Total SM Elapsed Cycles          cycle     15129476
    Average SMSP Active Cycles       cycle    107971.54
    Total SMSP Elapsed Cycles        cycle     60517904
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.418%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.93% above the average, while the minimum instance value is 20.02% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32289
    Memory Throughput                   %        66.18
    DRAM Throughput                     %        66.18
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.60
    L2 Cache Throughput                 %        28.71
    SM Active Cycles                cycle     27596.11
    Compute (SM) Throughput             %        17.07
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.46
    Achieved Active Warps Per SM           warp        11.74
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.09%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1783808
    Average L1 Active Cycles         cycle     27596.11
    Total L1 Elapsed Cycles          cycle      4063694
    Average L2 Active Cycles         cycle     22827.44
    Total L2 Elapsed Cycles          cycle      1024596
    Average SM Active Cycles         cycle     27596.11
    Total SM Elapsed Cycles          cycle      4063694
    Average SMSP Active Cycles       cycle     26822.19
    Total SMSP Elapsed Cycles        cycle     16254776
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.742%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.61% above the average, while the minimum instance value is 18.10% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.036%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.14% above the average, while the minimum instance value is 22.53% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.742%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.61% above the average, while the minimum instance value is 18.10% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.18
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle         9763
    Memory Throughput                   %         5.93
    DRAM Throughput                     %         0.76
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.99
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4002.72
    Compute (SM) Throughput             %         9.18
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.86
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.28%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          340
    Total DRAM Elapsed Cycles        cycle       539648
    Average L1 Active Cycles         cycle      4002.72
    Total L1 Elapsed Cycles          cycle      1209230
    Average L2 Active Cycles         cycle        82.94
    Total L2 Elapsed Cycles          cycle       308700
    Average SM Active Cycles         cycle      4002.72
    Total SM Elapsed Cycles          cycle      1209230
    Average SMSP Active Cycles       cycle      3486.11
    Total SMSP Elapsed Cycles        cycle      4836920
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.148%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 16.87% above the average, while the minimum instance value is 23.65% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.654%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.03% above the average, while the minimum instance value is 26.45% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.148%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 16.87% above the average, while the minimum instance value is 23.65% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31979
    Memory Throughput                   %        66.03
    DRAM Throughput                     %        66.03
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.18
    L2 Cache Throughput                 %        28.88
    SM Active Cycles                cycle     27035.86
    Compute (SM) Throughput             %        17.04
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.94
    Achieved Active Warps Per SM           warp        11.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.13%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1787904
    Average L1 Active Cycles         cycle     27035.86
    Total L1 Elapsed Cycles          cycle      4070316
    Average L2 Active Cycles         cycle     23062.81
    Total L2 Elapsed Cycles          cycle      1018548
    Average SM Active Cycles         cycle     27035.86
    Total SM Elapsed Cycles          cycle      4070316
    Average SMSP Active Cycles       cycle     27298.80
    Total SMSP Elapsed Cycles        cycle     16281264
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.398%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.53% above the average, while the minimum instance value is 14.40% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.677%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.61% above the average, while the minimum instance value is 17.28% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.398%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.53% above the average, while the minimum instance value is 14.40% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31886
    Memory Throughput                   %        67.07
    DRAM Throughput                     %        67.07
    Duration                      usecond        14.37
    L1/TEX Cache Throughput             %        27.86
    L2 Cache Throughput                 %        29.10
    SM Active Cycles                cycle     27360.59
    Compute (SM) Throughput             %        17.10
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.61
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.78%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1760256
    Average L1 Active Cycles         cycle     27360.59
    Total L1 Elapsed Cycles          cycle      4056140
    Average L2 Active Cycles         cycle     22941.33
    Total L2 Elapsed Cycles          cycle      1010952
    Average SM Active Cycles         cycle     27360.59
    Total SM Elapsed Cycles          cycle      4056140
    Average SMSP Active Cycles       cycle     27079.61
    Total SMSP Elapsed Cycles        cycle     16224560
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.355%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.27% above the average, while the minimum instance value is 22.27% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32362
    Memory Throughput                   %        66.04
    DRAM Throughput                     %        66.04
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.71
    L2 Cache Throughput                 %        28.65
    SM Active Cycles                cycle     27500.44
    Compute (SM) Throughput             %        16.80
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.72
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.57%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98396
    Total DRAM Elapsed Cycles        cycle      1787904
    Average L1 Active Cycles         cycle     27500.44
    Total L1 Elapsed Cycles          cycle      4129338
    Average L2 Active Cycles         cycle     22988.06
    Total L2 Elapsed Cycles          cycle      1026576
    Average SM Active Cycles         cycle     27500.44
    Total SM Elapsed Cycles          cycle      4129338
    Average SMSP Active Cycles       cycle     27272.66
    Total SMSP Elapsed Cycles        cycle     16517352
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.489%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.44% above the average, while the minimum instance value is 18.65% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.428%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.60% above the average, while the minimum instance value is 22.01% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.489%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.44% above the average, while the minimum instance value is 18.65% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117969
    Memory Throughput                   %        91.37
    DRAM Throughput                     %        91.37
    Duration                      usecond        52.83
    L1/TEX Cache Throughput             %        10.44
    L2 Cache Throughput                 %        39.48
    SM Active Cycles                cycle    110470.09
    Compute (SM) Throughput             %        10.05
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.22
    Achieved Active Warps Per SM           warp        43.78
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494014.67
    Total DRAM Elapsed Cycles        cycle      6488064
    Average L1 Active Cycles         cycle    110470.09
    Total L1 Elapsed Cycles          cycle     14998944
    Average L2 Active Cycles         cycle     98006.17
    Total L2 Elapsed Cycles          cycle      3734748
    Average SM Active Cycles         cycle    110470.09
    Total SM Elapsed Cycles          cycle     14998944
    Average SMSP Active Cycles       cycle    109184.98
    Total SMSP Elapsed Cycles        cycle     59995776
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.03
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle         9770
    Memory Throughput                   %         5.89
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.45
    L1/TEX Cache Throughput             %        13.91
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4024.92
    Compute (SM) Throughput             %         9.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.38%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      4024.92
    Total L1 Elapsed Cycles          cycle      1216438
    Average L2 Active Cycles         cycle        82.44
    Total L2 Elapsed Cycles          cycle       308844
    Average SM Active Cycles         cycle      4024.92
    Total SM Elapsed Cycles          cycle      1216438
    Average SMSP Active Cycles       cycle      3444.33
    Total SMSP Elapsed Cycles        cycle      4865752
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.763%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 20.69% above the average, while the minimum instance value is 23.48% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.056%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.47% above the average, while the minimum instance value is 27.07% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.763%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 20.69% above the average, while the minimum instance value is 23.48% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32057
    Memory Throughput                   %        66.37
    DRAM Throughput                     %        66.37
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.95
    L2 Cache Throughput                 %        28.86
    SM Active Cycles                cycle     27258.91
    Compute (SM) Throughput             %        16.93
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.74
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.52%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1778688
    Average L1 Active Cycles         cycle     27258.91
    Total L1 Elapsed Cycles          cycle      4098938
    Average L2 Active Cycles         cycle     22923.36
    Total L2 Elapsed Cycles          cycle      1019124
    Average SM Active Cycles         cycle     27258.91
    Total SM Elapsed Cycles          cycle      4098938
    Average SMSP Active Cycles       cycle     27104.90
    Total SMSP Elapsed Cycles        cycle     16395752
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.261%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.40% above the average, while the minimum instance value is 10.08% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32354
    Memory Throughput                   %        65.66
    DRAM Throughput                     %        65.66
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.79
    L2 Cache Throughput                 %        28.59
    SM Active Cycles                cycle     27426.50
    Compute (SM) Throughput             %        17.00
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.55
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.91%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1798144
    Average L1 Active Cycles         cycle     27426.50
    Total L1 Elapsed Cycles          cycle      4081334
    Average L2 Active Cycles         cycle     22822.94
    Total L2 Elapsed Cycles          cycle      1028700
    Average SM Active Cycles         cycle     27426.50
    Total SM Elapsed Cycles          cycle      4081334
    Average SMSP Active Cycles       cycle     26781.43
    Total SMSP Elapsed Cycles        cycle     16325336
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.406%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.29% above the average, while the minimum instance value is 17.36% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.447%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.68% above the average, while the minimum instance value is 20.24% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.406%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.29% above the average, while the minimum instance value is 17.36% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle        32967
    Memory Throughput                   %        65.17
    DRAM Throughput                     %        65.17
    Duration                      usecond        14.78
    L1/TEX Cache Throughput             %        27.55
    L2 Cache Throughput                 %        28.19
    SM Active Cycles                cycle     27635.44
    Compute (SM) Throughput             %        17.05
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.53
    Achieved Active Warps Per SM           warp        11.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.94%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1811456
    Average L1 Active Cycles         cycle     27635.44
    Total L1 Elapsed Cycles          cycle      4068898
    Average L2 Active Cycles         cycle     22878.44
    Total L2 Elapsed Cycles          cycle      1043352
    Average SM Active Cycles         cycle     27635.44
    Total SM Elapsed Cycles          cycle      4068898
    Average SMSP Active Cycles       cycle     27325.06
    Total SMSP Elapsed Cycles        cycle     16275592
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.874%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.91% above the average, while the minimum instance value is 15.83% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.874%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.91% above the average, while the minimum instance value is 15.83% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31435
    Memory Throughput                   %        67.19
    DRAM Throughput                     %        67.19
    Duration                      usecond        14.34
    L1/TEX Cache Throughput             %        28.04
    L2 Cache Throughput                 %        29.39
    SM Active Cycles                cycle     27156.73
    Compute (SM) Throughput             %        16.95
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.94
    Achieved Active Warps Per SM           warp        11.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.11%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98390.67
    Total DRAM Elapsed Cycles        cycle      1757184
    Average L1 Active Cycles         cycle     27156.73
    Total L1 Elapsed Cycles          cycle      4092096
    Average L2 Active Cycles         cycle     22878.56
    Total L2 Elapsed Cycles          cycle      1001016
    Average SM Active Cycles         cycle     27156.73
    Total SM Elapsed Cycles          cycle      4092096
    Average SMSP Active Cycles       cycle     27118.15
    Total SMSP Elapsed Cycles        cycle     16368384
    -------------------------- ----------- ------------

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117703
    Memory Throughput                   %        90.94
    DRAM Throughput                     %        90.94
    Duration                      usecond        52.83
    L1/TEX Cache Throughput             %        10.60
    L2 Cache Throughput                 %        39.53
    SM Active Cycles                cycle    108732.09
    Compute (SM) Throughput             %         9.97
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.73
    Achieved Active Warps Per SM           warp        44.51
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491693.33
    Total DRAM Elapsed Cycles        cycle      6488064
    Average L1 Active Cycles         cycle    108732.09
    Total L1 Elapsed Cycles          cycle     15124632
    Average L2 Active Cycles         cycle     97974.22
    Total L2 Elapsed Cycles          cycle      3729924
    Average SM Active Cycles         cycle    108732.09
    Total SM Elapsed Cycles          cycle     15124632
    Average SMSP Active Cycles       cycle    108149.73
    Total SMSP Elapsed Cycles        cycle     60498528
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.424%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.93% above the average, while the minimum instance value is 18.33% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32138
    Memory Throughput                   %        65.99
    DRAM Throughput                     %        65.99
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        28.04
    L2 Cache Throughput                 %        28.77
    SM Active Cycles                cycle     27159.66
    Compute (SM) Throughput             %        16.73
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.96
    Achieved Active Warps Per SM           warp        11.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.08%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1788928
    Average L1 Active Cycles         cycle     27159.66
    Total L1 Elapsed Cycles          cycle      4146688
    Average L2 Active Cycles         cycle     22945.53
    Total L2 Elapsed Cycles          cycle      1022580
    Average SM Active Cycles         cycle     27159.66
    Total SM Elapsed Cycles          cycle      4146688
    Average SMSP Active Cycles       cycle     27035.74
    Total SMSP Elapsed Cycles        cycle     16586752
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.975%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.13% above the average, while the minimum instance value is 21.41% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.101%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.31% above the average, while the minimum instance value is 15.16% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.975%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.13% above the average, while the minimum instance value is 21.41% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31891
    Memory Throughput                   %        66.91
    DRAM Throughput                     %        66.91
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.97
    L2 Cache Throughput                 %        29.04
    SM Active Cycles                cycle     27246.98
    Compute (SM) Throughput             %        17.21
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.00
    Achieved Active Warps Per SM           warp        12.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.01%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1764352
    Average L1 Active Cycles         cycle     27246.98
    Total L1 Elapsed Cycles          cycle      4032016
    Average L2 Active Cycles         cycle     22985.61
    Total L2 Elapsed Cycles          cycle      1013004
    Average SM Active Cycles         cycle     27246.98
    Total SM Elapsed Cycles          cycle      4032016
    Average SMSP Active Cycles       cycle     26841.68
    Total SMSP Elapsed Cycles        cycle     16128064
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.827%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.74% above the average, while the minimum instance value is 20.07% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.494%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.62% above the average, while the minimum instance value is 19.51% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.827%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.74% above the average, while the minimum instance value is 20.07% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32351
    Memory Throughput                   %        65.96
    DRAM Throughput                     %        65.96
    Duration                      usecond        14.62
    L1/TEX Cache Throughput             %        27.68
    L2 Cache Throughput                 %        28.64
    SM Active Cycles                cycle     27522.72
    Compute (SM) Throughput             %        16.63
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.62
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.76%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1789952
    Average L1 Active Cycles         cycle     27522.72
    Total L1 Elapsed Cycles          cycle      4171188
    Average L2 Active Cycles         cycle     23157.75
    Total L2 Elapsed Cycles          cycle      1027224
    Average SM Active Cycles         cycle     27522.72
    Total SM Elapsed Cycles          cycle      4171188
    Average SMSP Active Cycles       cycle     27210.64
    Total SMSP Elapsed Cycles        cycle     16684752
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.402%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.58% above the average, while the minimum instance value is 14.67% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.437%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.91% above the average, while the minimum instance value is 16.01% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.402%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.58% above the average, while the minimum instance value is 14.67% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31849
    Memory Throughput                   %        66.23
    DRAM Throughput                     %        66.23
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        27.79
    L2 Cache Throughput                 %        28.98
    SM Active Cycles                cycle     27421.69
    Compute (SM) Throughput             %        16.80
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.86
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.28%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98397.33
    Total DRAM Elapsed Cycles        cycle      1782784
    Average L1 Active Cycles         cycle     27421.69
    Total L1 Elapsed Cycles          cycle      4129248
    Average L2 Active Cycles         cycle     23057.22
    Total L2 Elapsed Cycles          cycle      1015128
    Average SM Active Cycles         cycle     27421.69
    Total SM Elapsed Cycles          cycle      4129248
    Average SMSP Active Cycles       cycle     26977.72
    Total SMSP Elapsed Cycles        cycle     16516992
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.914%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.27% above the average, while the minimum instance value is 16.23% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32033
    Memory Throughput                   %        65.81
    DRAM Throughput                     %        65.81
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        28.24
    L2 Cache Throughput                 %        28.79
    SM Active Cycles                cycle     26981.18
    Compute (SM) Throughput             %        16.63
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.85
    Achieved Active Warps Per SM           warp        11.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.3%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1794048
    Average L1 Active Cycles         cycle     26981.18
    Total L1 Elapsed Cycles          cycle      4171922
    Average L2 Active Cycles         cycle     23088.81
    Total L2 Elapsed Cycles          cycle      1021752
    Average SM Active Cycles         cycle     26981.18
    Total SM Elapsed Cycles          cycle      4171922
    Average SMSP Active Cycles       cycle     27179.68
    Total SMSP Elapsed Cycles        cycle     16687688
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.824%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.24% above the average, while the minimum instance value is 13.93% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.968%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.55% above the average, while the minimum instance value is 23.96% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.824%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.24% above the average, while the minimum instance value is 13.93% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle       117412
    Memory Throughput                   %        91.22
    DRAM Throughput                     %        91.22
    Duration                      usecond        52.67
    L1/TEX Cache Throughput             %        10.57
    L2 Cache Throughput                 %        39.65
    SM Active Cycles                cycle    109043.48
    Compute (SM) Throughput             %        10.02
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.82
    Achieved Active Warps Per SM           warp        44.07
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       491808
    Total DRAM Elapsed Cycles        cycle      6469632
    Average L1 Active Cycles         cycle    109043.48
    Total L1 Elapsed Cycles          cycle     15040398
    Average L2 Active Cycles         cycle     97876.81
    Total L2 Elapsed Cycles          cycle      3719304
    Average SM Active Cycles         cycle    109043.48
    Total SM Elapsed Cycles          cycle     15040398
    Average SMSP Active Cycles       cycle    108777.89
    Total SMSP Elapsed Cycles        cycle     60161592
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        32040
    Memory Throughput                   %        66.30
    DRAM Throughput                     %        66.30
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.98
    L2 Cache Throughput                 %        28.89
    SM Active Cycles                cycle     27226.02
    Compute (SM) Throughput             %        17.20
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.61
    Achieved Active Warps Per SM           warp        11.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.77%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1780736
    Average L1 Active Cycles         cycle     27226.02
    Total L1 Elapsed Cycles          cycle      4032698
    Average L2 Active Cycles         cycle     22824.94
    Total L2 Elapsed Cycles          cycle      1018080
    Average SM Active Cycles         cycle     27226.02
    Total SM Elapsed Cycles          cycle      4032698
    Average SMSP Active Cycles       cycle     27016.76
    Total SMSP Elapsed Cycles        cycle     16130792
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.412%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.26% above the average, while the minimum instance value is 14.05% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.412%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.26% above the average, while the minimum instance value is 14.05% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle        32774
    Memory Throughput                   %        65.63
    DRAM Throughput                     %        65.63
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        27.39
    L2 Cache Throughput                 %        28.36
    SM Active Cycles                cycle     27807.06
    Compute (SM) Throughput             %        17.06
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.33
    Achieved Active Warps Per SM           warp        11.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.35%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98393.33
    Total DRAM Elapsed Cycles        cycle      1799168
    Average L1 Active Cycles         cycle     27807.06
    Total L1 Elapsed Cycles          cycle      4065656
    Average L2 Active Cycles         cycle     23024.92
    Total L2 Elapsed Cycles          cycle      1037088
    Average SM Active Cycles         cycle     27807.06
    Total SM Elapsed Cycles          cycle      4065656
    Average SMSP Active Cycles       cycle     27372.91
    Total SMSP Elapsed Cycles        cycle     16262624
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.497%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.42% above the average, while the minimum instance value is 16.75% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.767%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.69% above the average, while the minimum instance value is 13.19% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.497%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.42% above the average, while the minimum instance value is 16.75% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31580
    Memory Throughput                   %        66.87
    DRAM Throughput                     %        66.87
    Duration                      usecond        14.43
    L1/TEX Cache Throughput             %        28.11
    L2 Cache Throughput                 %        29.22
    SM Active Cycles                cycle     27084.23
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.37%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1765376
    Average L1 Active Cycles         cycle     27084.23
    Total L1 Elapsed Cycles          cycle      4072726
    Average L2 Active Cycles         cycle     22844.36
    Total L2 Elapsed Cycles          cycle      1006524
    Average SM Active Cycles         cycle     27084.23
    Total SM Elapsed Cycles          cycle      4072726
    Average SMSP Active Cycles       cycle     27337.18
    Total SMSP Elapsed Cycles        cycle     16290904
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31799
    Memory Throughput                   %        66.49
    DRAM Throughput                     %        66.49
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.91
    L2 Cache Throughput                 %        29.05
    SM Active Cycles                cycle     27286.17
    Compute (SM) Throughput             %        16.74
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp        11.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.44%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98384
    Total DRAM Elapsed Cycles        cycle      1775616
    Average L1 Active Cycles         cycle     27286.17
    Total L1 Elapsed Cycles          cycle      4143312
    Average L2 Active Cycles         cycle     22768.67
    Total L2 Elapsed Cycles          cycle      1012752
    Average SM Active Cycles         cycle     27286.17
    Total SM Elapsed Cycles          cycle      4143312
    Average SMSP Active Cycles       cycle     27319.09
    Total SMSP Elapsed Cycles        cycle     16573248
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.14
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9739
    Memory Throughput                   %         5.91
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.83
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      4049.76
    Compute (SM) Throughput             %         9.16
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.73
    Achieved Active Warps Per SM           warp        12.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.54%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       330.67
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      4049.76
    Total L1 Elapsed Cycles          cycle      1213428
    Average L2 Active Cycles         cycle        82.47
    Total L2 Elapsed Cycles          cycle       308052
    Average SM Active Cycles         cycle      4049.76
    Total SM Elapsed Cycles          cycle      1213428
    Average SMSP Active Cycles       cycle      3443.71
    Total SMSP Elapsed Cycles        cycle      4853712
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.277%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.38% above the average, while the minimum instance value is 24.42% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.732%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 18.53% above the average, while the minimum instance value is 26.97% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.277%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.38% above the average, while the minimum instance value is 24.42% below the      
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118004
    Memory Throughput                   %        91.37
    DRAM Throughput                     %        91.37
    Duration                      usecond        52.83
    L1/TEX Cache Throughput             %        10.36
    L2 Cache Throughput                 %        39.47
    SM Active Cycles                cycle    111254.85
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.18
    Achieved Active Warps Per SM           warp        43.77
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494073.33
    Total DRAM Elapsed Cycles        cycle      6489088
    Average L1 Active Cycles         cycle    111254.85
    Total L1 Elapsed Cycles          cycle     14987692
    Average L2 Active Cycles         cycle     97859.36
    Total L2 Elapsed Cycles          cycle      3735720
    Average SM Active Cycles         cycle    111254.85
    Total SM Elapsed Cycles          cycle     14987692
    Average SMSP Active Cycles       cycle    109256.75
    Total SMSP Elapsed Cycles        cycle     59950768
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        31929
    Memory Throughput                   %        67.19
    DRAM Throughput                     %        67.19
    Duration                      usecond        14.37
    L1/TEX Cache Throughput             %        27.77
    L2 Cache Throughput                 %        29.08
    SM Active Cycles                cycle     27429.98
    Compute (SM) Throughput             %        16.67
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.65
    Achieved Active Warps Per SM           warp        11.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.7%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1757184
    Average L1 Active Cycles         cycle     27429.98
    Total L1 Elapsed Cycles          cycle      4162430
    Average L2 Active Cycles         cycle     22971.17
    Total L2 Elapsed Cycles          cycle      1011564
    Average SM Active Cycles         cycle     27429.98
    Total SM Elapsed Cycles          cycle      4162430
    Average SMSP Active Cycles       cycle     27218.95
    Total SMSP Elapsed Cycles        cycle     16649720
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.04%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.97% above the average, while the minimum instance value is 20.03% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.467%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 10.12% above the average, while the minimum instance value is 17.08% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.04%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.97% above the average, while the minimum instance value is 20.03% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32480
    Memory Throughput                   %        65.03
    DRAM Throughput                     %        65.03
    Duration                      usecond        14.82
    L1/TEX Cache Throughput             %        27.99
    L2 Cache Throughput                 %        28.42
    SM Active Cycles                cycle     27213.63
    Compute (SM) Throughput             %        17.06
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.88
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.24%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1815552
    Average L1 Active Cycles         cycle     27213.63
    Total L1 Elapsed Cycles          cycle      4066404
    Average L2 Active Cycles         cycle     22973.28
    Total L2 Elapsed Cycles          cycle      1034964
    Average SM Active Cycles         cycle     27213.63
    Total SM Elapsed Cycles          cycle      4066404
    Average SMSP Active Cycles       cycle     27125.95
    Total SMSP Elapsed Cycles        cycle     16265616
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.693%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.81% above the average, while the minimum instance value is 11.03% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.518%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.46% above the average, while the minimum instance value is 17.40% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.693%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.81% above the average, while the minimum instance value is 11.03% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31718
    Memory Throughput                   %        66.68
    DRAM Throughput                     %        66.68
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        28.00
    L2 Cache Throughput                 %        29.11
    SM Active Cycles                cycle     27197.19
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.49
    Achieved Active Warps Per SM           warp        11.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.01%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1770496
    Average L1 Active Cycles         cycle     27197.19
    Total L1 Elapsed Cycles          cycle      4073034
    Average L2 Active Cycles         cycle     22961.92
    Total L2 Elapsed Cycles          cycle      1010484
    Average SM Active Cycles         cycle     27197.19
    Total SM Elapsed Cycles          cycle      4073034
    Average SMSP Active Cycles       cycle     27058.54
    Total SMSP Elapsed Cycles        cycle     16292136
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.703%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.06% above the average, while the minimum instance value is 17.02% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.16
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle         9791
    Memory Throughput                   %         5.90
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        13.85
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4043.12
    Compute (SM) Throughput             %         9.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.62
    Achieved Active Warps Per SM           warp        11.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.76%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       538624
    Average L1 Active Cycles         cycle      4043.12
    Total L1 Elapsed Cycles          cycle      1214290
    Average L2 Active Cycles         cycle       145.53
    Total L2 Elapsed Cycles          cycle       309672
    Average SM Active Cycles         cycle      4043.12
    Total SM Elapsed Cycles          cycle      1214290
    Average SMSP Active Cycles       cycle      3431.57
    Total SMSP Elapsed Cycles        cycle      4857160
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.087%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 18.98% above the average, while the minimum instance value is 23.47% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.276%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 17.35% above the average, while the minimum instance value is 26.45% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.087%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 18.98% above the average, while the minimum instance value is 23.47% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle        31675
    Memory Throughput                   %        67.07
    DRAM Throughput                     %        67.07
    Duration                      usecond        14.37
    L1/TEX Cache Throughput             %        27.92
    L2 Cache Throughput                 %        29.21
    SM Active Cycles                cycle     27293.16
    Compute (SM) Throughput             %        16.81
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.96
    Achieved Active Warps Per SM           warp        11.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.08%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1760256
    Average L1 Active Cycles         cycle     27293.16
    Total L1 Elapsed Cycles          cycle      4125984
    Average L2 Active Cycles         cycle     22894.08
    Total L2 Elapsed Cycles          cycle      1007064
    Average SM Active Cycles         cycle     27293.16
    Total SM Elapsed Cycles          cycle      4125984
    Average SMSP Active Cycles       cycle     27271.88
    Total SMSP Elapsed Cycles        cycle     16503936
    -------------------------- ----------- ------------

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       117736
    Memory Throughput                   %        91.15
    DRAM Throughput                     %        91.15
    Duration                      usecond        52.74
    L1/TEX Cache Throughput             %        10.55
    L2 Cache Throughput                 %        39.57
    SM Active Cycles                cycle    109287.55
    Compute (SM) Throughput             %         9.99
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.29
    Achieved Active Warps Per SM           warp        43.82
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491630.67
    Total DRAM Elapsed Cycles        cycle      6472704
    Average L1 Active Cycles         cycle    109287.55
    Total L1 Elapsed Cycles          cycle     15095920
    Average L2 Active Cycles         cycle     97993.08
    Total L2 Elapsed Cycles          cycle      3726936
    Average SM Active Cycles         cycle    109287.55
    Total SM Elapsed Cycles          cycle     15095920
    Average SMSP Active Cycles       cycle    108396.34
    Total SMSP Elapsed Cycles        cycle     60383680
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32283
    Memory Throughput                   %        65.55
    DRAM Throughput                     %        65.55
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        28.17
    L2 Cache Throughput                 %        28.60
    SM Active Cycles                cycle     27049.45
    Compute (SM) Throughput             %        16.85
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.89
    Achieved Active Warps Per SM           warp        11.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.21%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98389.33
    Total DRAM Elapsed Cycles        cycle      1801216
    Average L1 Active Cycles         cycle     27049.45
    Total L1 Elapsed Cycles          cycle      4117778
    Average L2 Active Cycles         cycle     22871.86
    Total L2 Elapsed Cycles          cycle      1028700
    Average SM Active Cycles         cycle     27049.45
    Total SM Elapsed Cycles          cycle      4117778
    Average SMSP Active Cycles       cycle     27111.25
    Total SMSP Elapsed Cycles        cycle     16471112
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.195%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.37% above the average, while the minimum instance value is 20.88% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.195%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.37% above the average, while the minimum instance value is 20.88% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31796
    Memory Throughput                   %        66.53
    DRAM Throughput                     %        66.53
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        28.28
    L2 Cache Throughput                 %        29.04
    SM Active Cycles                cycle     26941.24
    Compute (SM) Throughput             %        16.65
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.70
    Achieved Active Warps Per SM           warp        11.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.61%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     26941.24
    Total L1 Elapsed Cycles          cycle      4166060
    Average L2 Active Cycles         cycle     22881.61
    Total L2 Elapsed Cycles          cycle      1012896
    Average SM Active Cycles         cycle     26941.24
    Total SM Elapsed Cycles          cycle      4166060
    Average SMSP Active Cycles       cycle     27155.07
    Total SMSP Elapsed Cycles        cycle     16664240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.977%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.22% above the average, while the minimum instance value is 20.09% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.094%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.11% above the average, while the minimum instance value is 11.47% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.977%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.22% above the average, while the minimum instance value is 20.09% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle         9752
    Memory Throughput                   %         5.89
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.38
    L1/TEX Cache Throughput             %        13.86
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      4039.91
    Compute (SM) Throughput             %         9.17
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        26.65
    Achieved Active Warps Per SM           warp        12.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 46.71%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       537600
    Average L1 Active Cycles         cycle      4039.91
    Total L1 Elapsed Cycles          cycle      1216124
    Average L2 Active Cycles         cycle        86.14
    Total L2 Elapsed Cycles          cycle       308520
    Average SM Active Cycles         cycle      4039.91
    Total SM Elapsed Cycles          cycle      1216124
    Average SMSP Active Cycles       cycle      3445.09
    Total SMSP Elapsed Cycles        cycle      4864496
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 8.336%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 19.60% above the average, while the minimum instance value is 24.06% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.289%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 17.34% above the average, while the minimum instance value is 27.40% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.336%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 19.60% above the average, while the minimum instance value is 24.06% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        31945
    Memory Throughput                   %        66.95
    DRAM Throughput                     %        66.95
    Duration                      usecond        14.40
    L1/TEX Cache Throughput             %        27.95
    L2 Cache Throughput                 %        29.03
    SM Active Cycles                cycle     27260.93
    Compute (SM) Throughput             %        16.92
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.74
    Achieved Active Warps Per SM           warp        11.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.52%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1763328
    Average L1 Active Cycles         cycle     27260.93
    Total L1 Elapsed Cycles          cycle      4099758
    Average L2 Active Cycles         cycle     22805.11
    Total L2 Elapsed Cycles          cycle      1013400
    Average SM Active Cycles         cycle     27260.93
    Total SM Elapsed Cycles          cycle      4099758
    Average SMSP Active Cycles       cycle     27067.22
    Total SMSP Elapsed Cycles        cycle     16399032
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.382%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.32% above the average, while the minimum instance value is 14.24% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.382%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.32% above the average, while the minimum instance value is 14.24% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32198
    Memory Throughput                   %        66.45
    DRAM Throughput                     %        66.45
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.75
    L2 Cache Throughput                 %        28.79
    SM Active Cycles                cycle     27461.18
    Compute (SM) Throughput             %        17.05
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.74
    Achieved Active Warps Per SM           warp        11.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.53%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98386.67
    Total DRAM Elapsed Cycles        cycle      1776640
    Average L1 Active Cycles         cycle     27461.18
    Total L1 Elapsed Cycles          cycle      4068014
    Average L2 Active Cycles         cycle     22814.83
    Total L2 Elapsed Cycles          cycle      1021572
    Average SM Active Cycles         cycle     27461.18
    Total SM Elapsed Cycles          cycle      4068014
    Average SMSP Active Cycles       cycle     27046.83
    Total SMSP Elapsed Cycles        cycle     16272056
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.012%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.80% above the average, while the minimum instance value is 21.40% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.192%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.28% above the average, while the minimum instance value is 18.93% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.012%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.80% above the average, while the minimum instance value is 21.40% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118264
    Memory Throughput                   %        90.82
    DRAM Throughput                     %        90.82
    Duration                      usecond        53.02
    L1/TEX Cache Throughput             %        10.65
    L2 Cache Throughput                 %        39.37
    SM Active Cycles                cycle    108292.19
    Compute (SM) Throughput             %        10.10
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        93.02
    Achieved Active Warps Per SM           warp        44.65
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       492808
    Total DRAM Elapsed Cycles        cycle      6511616
    Average L1 Active Cycles         cycle    108292.19
    Total L1 Elapsed Cycles          cycle     14927556
    Average L2 Active Cycles         cycle     98172.03
    Total L2 Elapsed Cycles          cycle      3745728
    Average SM Active Cycles         cycle    108292.19
    Total SM Elapsed Cycles          cycle     14927556
    Average SMSP Active Cycles       cycle    108382.67
    Total SMSP Elapsed Cycles        cycle     59710224
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.335%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.75% above the average, while the minimum instance value is 21.93% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.045%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 5.43% above the average, while the minimum instance value is 20.08% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.335%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.75% above the average, while the minimum instance value is 21.93% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.21
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31794
    Memory Throughput                   %        66.45
    DRAM Throughput                     %        66.45
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.97
    L2 Cache Throughput                 %        29.03
    SM Active Cycles                cycle     27243.21
    Compute (SM) Throughput             %        16.97
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.19
    Achieved Active Warps Per SM           warp        11.61
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.62%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98380
    Total DRAM Elapsed Cycles        cycle      1776640
    Average L1 Active Cycles         cycle     27243.21
    Total L1 Elapsed Cycles          cycle      4088152
    Average L2 Active Cycles         cycle     22919.92
    Total L2 Elapsed Cycles          cycle      1013184
    Average SM Active Cycles         cycle     27243.21
    Total SM Elapsed Cycles          cycle      4088152
    Average SMSP Active Cycles       cycle     27121.01
    Total SMSP Elapsed Cycles        cycle     16352608
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.001%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.86% above the average, while the minimum instance value is 19.60% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.753%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.78% above the average, while the minimum instance value is 17.43% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.001%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.86% above the average, while the minimum instance value is 19.60% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.11
    SM Frequency            cycle/nsecond         2.20
    Elapsed Cycles                  cycle         9720
    Memory Throughput                   %         5.93
    DRAM Throughput                     %         0.74
    Duration                      usecond         4.42
    L1/TEX Cache Throughput             %        14.04
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle      3987.46
    Compute (SM) Throughput             %         9.19
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.89
    Achieved Active Warps Per SM           warp        11.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.21%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle          332
    Total DRAM Elapsed Cycles        cycle       535552
    Average L1 Active Cycles         cycle      3987.46
    Total L1 Elapsed Cycles          cycle      1208458
    Average L2 Active Cycles         cycle        96.83
    Total L2 Elapsed Cycles          cycle       307440
    Average SM Active Cycles         cycle      3987.46
    Total SM Elapsed Cycles          cycle      1208458
    Average SMSP Active Cycles       cycle      3457.47
    Total SMSP Elapsed Cycles        cycle      4833832
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.526%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 17.82% above the average, while the minimum instance value is 23.89% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.237%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 19.76% above the average, while the minimum instance value is 27.26% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.526%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 17.82% above the average, while the minimum instance value is 23.89% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32109
    Memory Throughput                   %        66.53
    DRAM Throughput                     %        66.53
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.91
    L2 Cache Throughput                 %        28.86
    SM Active Cycles                cycle     27291.99
    Compute (SM) Throughput             %        17.04
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.84
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.33%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     27291.99
    Total L1 Elapsed Cycles          cycle      4071078
    Average L2 Active Cycles         cycle     22939.94
    Total L2 Elapsed Cycles          cycle      1019088
    Average SM Active Cycles         cycle     27291.99
    Total SM Elapsed Cycles          cycle      4071078
    Average SMSP Active Cycles       cycle     27079.94
    Total SMSP Elapsed Cycles        cycle     16284312
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.938%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.92% above the average, while the minimum instance value is 15.33% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.64%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.62% above the average, while the minimum instance value is 21.16% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.938%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.92% above the average, while the minimum instance value is 15.33% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.19
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32416
    Memory Throughput                   %        66.14
    DRAM Throughput                     %        66.14
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        27.80
    L2 Cache Throughput                 %        28.64
    SM Active Cycles                cycle     27398.80
    Compute (SM) Throughput             %        17.00
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.70
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.59%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1784832
    Average L1 Active Cycles         cycle     27398.80
    Total L1 Elapsed Cycles          cycle      4080512
    Average L2 Active Cycles         cycle     23023.06
    Total L2 Elapsed Cycles          cycle      1027116
    Average SM Active Cycles         cycle     27398.80
    Total SM Elapsed Cycles          cycle      4080512
    Average SMSP Active Cycles       cycle     27062.99
    Total SMSP Elapsed Cycles        cycle     16322048
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.883%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.01% above the average, while the minimum instance value is 16.43% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.738%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.94% above the average, while the minimum instance value is 16.10% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.883%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.01% above the average, while the minimum instance value is 16.43% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32806
    Memory Throughput                   %        64.52
    DRAM Throughput                     %        64.52
    Duration                      usecond        14.94
    L1/TEX Cache Throughput             %        27.89
    L2 Cache Throughput                 %        28.15
    SM Active Cycles                cycle     27315.56
    Compute (SM) Throughput             %        15.86
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp        11.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1829888
    Average L1 Active Cycles         cycle     27315.56
    Total L1 Elapsed Cycles          cycle      4374060
    Average L2 Active Cycles         cycle     22917.42
    Total L2 Elapsed Cycles          cycle      1045008
    Average SM Active Cycles         cycle     27315.56
    Total SM Elapsed Cycles          cycle      4374060
    Average SMSP Active Cycles       cycle     27056.94
    Total SMSP Elapsed Cycles        cycle     17496240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.921%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.66% above the average, while the minimum instance value is 16.35% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.218%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.12% above the average, while the minimum instance value is 16.62% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.921%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.66% above the average, while the minimum instance value is 16.35% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.23
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118998
    Memory Throughput                   %        90.52
    DRAM Throughput                     %        90.52
    Duration                      usecond        53.38
    L1/TEX Cache Throughput             %        10.44
    L2 Cache Throughput                 %        39.12
    SM Active Cycles                cycle    110469.27
    Compute (SM) Throughput             %        10.06
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.99
    Achieved Active Warps Per SM           warp        44.16
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    494418.67
    Total DRAM Elapsed Cycles        cycle      6554624
    Average L1 Active Cycles         cycle    110469.27
    Total L1 Elapsed Cycles          cycle     14990354
    Average L2 Active Cycles         cycle     98009.61
    Total L2 Elapsed Cycles          cycle      3769272
    Average SM Active Cycles         cycle    110469.27
    Total SM Elapsed Cycles          cycle     14990354
    Average SMSP Active Cycles       cycle    108909.86
    Total SMSP Elapsed Cycles        cycle     59961416
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.05
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle         9762
    Memory Throughput                   %         5.89
    DRAM Throughput                     %         0.75
    Duration                      usecond         4.45
    L1/TEX Cache Throughput             %        13.91
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle      4024.57
    Compute (SM) Throughput             %         9.12
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.87
    Achieved Active Warps Per SM           warp        11.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.26%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle       333.33
    Total DRAM Elapsed Cycles        cycle       536576
    Average L1 Active Cycles         cycle      4024.57
    Total L1 Elapsed Cycles          cycle      1216318
    Average L2 Active Cycles         cycle        83.03
    Total L2 Elapsed Cycles          cycle       308988
    Average SM Active Cycles         cycle      4024.57
    Total SM Elapsed Cycles          cycle      1216318
    Average SMSP Active Cycles       cycle      3463.32
    Total SMSP Elapsed Cycles        cycle      4865272
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.743%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 18.28% above the average, while the minimum instance value is 24.02% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.493%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 17.81% above the average, while the minimum instance value is 26.46% below the average.     
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.743%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 18.28% above the average, while the minimum instance value is 24.02% below the      
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.21
    Elapsed Cycles                  cycle        32109
    Memory Throughput                   %        66.53
    DRAM Throughput                     %        66.53
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        27.70
    L2 Cache Throughput                 %        28.88
    SM Active Cycles                cycle     27501.44
    Compute (SM) Throughput             %        17.06
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.55
    Achieved Active Warps Per SM           warp        11.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.9%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     27501.44
    Total L1 Elapsed Cycles          cycle      4066526
    Average L2 Active Cycles         cycle     22915.83
    Total L2 Elapsed Cycles          cycle      1018476
    Average SM Active Cycles         cycle     27501.44
    Total SM Elapsed Cycles          cycle      4066526
    Average SMSP Active Cycles       cycle     27021.76
    Total SMSP Elapsed Cycles        cycle     16266104
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.03%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 5.81% above the average, while the minimum instance value is 11.18% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.139%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.22% above the average, while the minimum instance value is 15.81% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.03%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 5.81% above the average, while the minimum instance value is 11.18% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32266
    Memory Throughput                   %        66.37
    DRAM Throughput                     %        66.37
    Duration                      usecond        14.53
    L1/TEX Cache Throughput             %        27.53
    L2 Cache Throughput                 %        28.77
    SM Active Cycles                cycle     27664.20
    Compute (SM) Throughput             %        16.78
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.51
    Achieved Active Warps Per SM           warp        11.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.99%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1778688
    Average L1 Active Cycles         cycle     27664.20
    Total L1 Elapsed Cycles          cycle      4135424
    Average L2 Active Cycles         cycle     22832.50
    Total L2 Elapsed Cycles          cycle      1022364
    Average SM Active Cycles         cycle     27664.20
    Total SM Elapsed Cycles          cycle      4135424
    Average SMSP Active Cycles       cycle     27052.35
    Total SMSP Elapsed Cycles        cycle     16541696
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.659%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 6.76% above the average, while the minimum instance value is 16.16% below the average.      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32134
    Memory Throughput                   %        66.68
    DRAM Throughput                     %        66.68
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.60
    L2 Cache Throughput                 %        28.89
    SM Active Cycles                cycle     27611.37
    Compute (SM) Throughput             %        16.65
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.68
    Achieved Active Warps Per SM           warp        11.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.65%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1770496
    Average L1 Active Cycles         cycle     27611.37
    Total L1 Elapsed Cycles          cycle      4167938
    Average L2 Active Cycles         cycle     23037.08
    Total L2 Elapsed Cycles          cycle      1018044
    Average SM Active Cycles         cycle     27611.37
    Total SM Elapsed Cycles          cycle      4167938
    Average SMSP Active Cycles       cycle     27353.41
    Total SMSP Elapsed Cycles        cycle     16671752
    -------------------------- ----------- ------------

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        31826
    Memory Throughput                   %        66.53
    DRAM Throughput                     %        66.53
    Duration                      usecond        14.50
    L1/TEX Cache Throughput             %        28.03
    L2 Cache Throughput                 %        29.02
    SM Active Cycles                cycle     27159.30
    Compute (SM) Throughput             %        17.13
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.96
    Achieved Active Warps Per SM           warp        11.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.08%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1774592
    Average L1 Active Cycles         cycle     27159.30
    Total L1 Elapsed Cycles          cycle      4050762
    Average L2 Active Cycles         cycle     22810.97
    Total L2 Elapsed Cycles          cycle      1013688
    Average SM Active Cycles         cycle     27159.30
    Total SM Elapsed Cycles          cycle      4050762
    Average SMSP Active Cycles       cycle     27279.75
    Total SMSP Elapsed Cycles        cycle     16203048
    -------------------------- ----------- ------------

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118333
    Memory Throughput                   %        90.60
    DRAM Throughput                     %        90.60
    Duration                      usecond        53.02
    L1/TEX Cache Throughput             %        10.64
    L2 Cache Throughput                 %        39.36
    SM Active Cycles                cycle    108351.58
    Compute (SM) Throughput             %        10.08
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        93.45
    Achieved Active Warps Per SM           warp        44.86
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491685.33
    Total DRAM Elapsed Cycles        cycle      6512640
    Average L1 Active Cycles         cycle    108351.58
    Total L1 Elapsed Cycles          cycle     14954954
    Average L2 Active Cycles         cycle        98042
    Total L2 Elapsed Cycles          cycle      3746268
    Average SM Active Cycles         cycle    108351.58
    Total SM Elapsed Cycles          cycle     14954954
    Average SMSP Active Cycles       cycle    108563.28
    Total SMSP Elapsed Cycles        cycle     59819816
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.837%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.29% above the average, while the minimum instance value is 18.18% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.837%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.29% above the average, while the minimum instance value is 18.18% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.19
    Elapsed Cycles                  cycle        32224
    Memory Throughput                   %        65.84
    DRAM Throughput                     %        65.84
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        27.81
    L2 Cache Throughput                 %        28.71
    SM Active Cycles                cycle     27398.03
    Compute (SM) Throughput             %        17.03
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.48
    Achieved Active Warps Per SM           warp        11.75
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.03%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1793024
    Average L1 Active Cycles         cycle     27398.03
    Total L1 Elapsed Cycles          cycle      4074626
    Average L2 Active Cycles         cycle     22937.64
    Total L2 Elapsed Cycles          cycle      1024668
    Average SM Active Cycles         cycle     27398.03
    Total SM Elapsed Cycles          cycle      4074626
    Average SMSP Active Cycles       cycle     27018.22
    Total SMSP Elapsed Cycles        cycle     16298504
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.603%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.51% above the average, while the minimum instance value is 14.42% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.167%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.27% above the average, while the minimum instance value is 20.04% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.603%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.51% above the average, while the minimum instance value is 14.42% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.22
    Elapsed Cycles                  cycle        32909
    Memory Throughput                   %        64.99
    DRAM Throughput                     %        64.99
    Duration                      usecond        14.82
    L1/TEX Cache Throughput             %        27.82
    L2 Cache Throughput                 %        28.21
    SM Active Cycles                cycle     27382.09
    Compute (SM) Throughput             %        16.85
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.84
    Achieved Active Warps Per SM           warp        11.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.31%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1816576
    Average L1 Active Cycles         cycle     27382.09
    Total L1 Elapsed Cycles          cycle      4117968
    Average L2 Active Cycles         cycle     23090.31
    Total L2 Elapsed Cycles          cycle      1042668
    Average SM Active Cycles         cycle     27382.09
    Total SM Elapsed Cycles          cycle      4117968
    Average SMSP Active Cycles       cycle     27254.14
    Total SMSP Elapsed Cycles        cycle     16471872
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.806%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 9.17% above the average, while the minimum instance value is 19.75% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.512%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 8.87% above the average, while the minimum instance value is 18.81% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.806%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 9.17% above the average, while the minimum instance value is 19.75% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31695
    Memory Throughput                   %        66.57
    DRAM Throughput                     %        66.57
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        27.95
    L2 Cache Throughput                 %        29.10
    SM Active Cycles                cycle     27270.51
    Compute (SM) Throughput             %        16.68
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.07
    Achieved Active Warps Per SM           warp        12.03
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.85%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98382.67
    Total DRAM Elapsed Cycles        cycle      1773568
    Average L1 Active Cycles         cycle     27270.51
    Total L1 Elapsed Cycles          cycle      4159496
    Average L2 Active Cycles         cycle     22982.92
    Total L2 Elapsed Cycles          cycle      1010916
    Average SM Active Cycles         cycle     27270.51
    Total SM Elapsed Cycles          cycle      4159496
    Average SMSP Active Cycles       cycle     27281.31
    Total SMSP Elapsed Cycles        cycle     16637984
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 5.141%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 6.13% above the average, while the minimum instance value is 15.21% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.141%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 6.13% above the average, while the minimum instance value is 15.21% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.20
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        32605
    Memory Throughput                   %        64.85
    DRAM Throughput                     %        64.85
    Duration                      usecond        14.88
    L1/TEX Cache Throughput             %        28.29
    L2 Cache Throughput                 %        28.32
    SM Active Cycles                cycle     26939.90
    Compute (SM) Throughput             %        16.68
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.24
    Achieved Active Warps Per SM           warp        12.12
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 49.52%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98392
    Total DRAM Elapsed Cycles        cycle      1820672
    Average L1 Active Cycles         cycle     26939.90
    Total L1 Elapsed Cycles          cycle      4159800
    Average L2 Active Cycles         cycle     23108.44
    Total L2 Elapsed Cycles          cycle      1038744
    Average SM Active Cycles         cycle     26939.90
    Total SM Elapsed Cycles          cycle      4159800
    Average SMSP Active Cycles       cycle     27372.55
    Total SMSP Elapsed Cycles        cycle     16639200
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 7.258%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 8.76% above the average, while the minimum instance value is 17.13% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.744%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 9.19% above the average, while the minimum instance value is 16.36% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.258%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 8.76% above the average, while the minimum instance value is 17.13% below the       
          average.                                                                                                      

  NTTPhase2_general(Params *, int, int, int, int, int, int, unsigned long *, unsigned long *, const unsigned long *, const unsigned long *, const DModulus *) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.22
    SM Frequency            cycle/nsecond         2.18
    Elapsed Cycles                  cycle        31954
    Memory Throughput                   %        65.99
    DRAM Throughput                     %        65.99
    Duration                      usecond        14.59
    L1/TEX Cache Throughput             %        28.09
    L2 Cache Throughput                 %        28.86
    SM Active Cycles                cycle     27107.94
    Compute (SM) Throughput             %        16.96
    ----------------------- ------------- ------------

    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    
          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       
          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  
          whether there are values you can (re)compute.                                                                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              80
    Shared Memory Configuration Size           Kbyte           65.54
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                5.33
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block            6
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           24
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.72
    Achieved Active Warps Per SM           warp        11.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 6.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 12. This kernel's theoretical occupancy (50.0%) is limited by the number of required      
          registers.                                                                                                    

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     98381.33
    Total DRAM Elapsed Cycles        cycle      1788928
    Average L1 Active Cycles         cycle     27107.94
    Total L1 Elapsed Cycles          cycle      4090144
    Average L2 Active Cycles         cycle     23063.78
    Total L2 Elapsed Cycles          cycle      1019448
    Average SM Active Cycles         cycle     27107.94
    Total SM Elapsed Cycles          cycle      4090144
    Average SMSP Active Cycles       cycle     27087.89
    Total SMSP Elapsed Cycles        cycle     16360576
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 6.518%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 7.68% above the average, while the minimum instance value is 22.82% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.255%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 7.38% above the average, while the minimum instance value is 15.79% below the average.      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.518%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 7.68% above the average, while the minimum instance value is 22.82% below the       
          average.                                                                                                      

  MultKeyAccum_8(Params *, int, int, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long *, unsigned long **) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.9

    NVTX Push/Pop Stack for Thread 39494:
     <default domain>
        <0,compute>
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        10.24
    SM Frequency            cycle/nsecond         2.23
    Elapsed Cycles                  cycle       118029
    Memory Throughput                   %        90.89
    DRAM Throughput                     %        90.89
    Duration                      usecond        52.86
    L1/TEX Cache Throughput             %        10.57
    L2 Cache Throughput                 %        39.47
    SM Active Cycles                cycle    109076.62
    Compute (SM) Throughput             %        10.03
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   4096
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             128
    Threads                                   thread          524288
    Uses Green Context                                             0
    Waves Per SM                                                2.67
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           24
    Block Limit Registers                 block           12
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           12
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        92.06
    Achieved Active Warps Per SM           warp        44.19
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle    491813.33
    Total DRAM Elapsed Cycles        cycle      6493184
    Average L1 Active Cycles         cycle    109076.62
    Total L1 Elapsed Cycles          cycle     15032550
    Average L2 Active Cycles         cycle     98026.67
    Total L2 Elapsed Cycles          cycle      3736440
    Average SM Active Cycles         cycle    109076.62
    Total SM Elapsed Cycles          cycle     15032550
    Average SMSP Active Cycles       cycle    108478.31
    Total SMSP Elapsed Cycles        cycle     60130200
    -------------------------- ----------- ------------

