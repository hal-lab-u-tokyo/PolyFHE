#include "hifive/engine/codegen/cuda_codegen.hpp"

#include "hifive/core/logger.hpp"
#include "hifive/engine/codegen/codegen_writer.hpp"

namespace hifive {
namespace engine {

std::string generate_signature(std::vector<hifive::core::VariableType> types,
                               std::string suffix = "") {
    if (types.size() == 0) {
        return "";
    }

    std::string signature = "";
    for (size_t i = 0; i < types.size(); i++) {
        hifive::core::VariableType type = types[i];
        if (type == hifive::core::VariableType::U64) {
            signature += "uint64_t " + suffix + std::to_string(i);
        } else if (type == hifive::core::VariableType::U64_PTR) {
            signature += "uint64_t *" + suffix + std::to_string(i);
        }
        signature += ", ";
    }

    // Remove the last comma and space
    if (signature.size() > 0) {
        signature.pop_back();
        signature.pop_back();
    }
    return signature;
}

void CudaCodegen::generate_kernel_defs(
    std::shared_ptr<hifive::core::Graph>& graph, const std::string& filename,
    const bool if_append) {
    LOG_INFO("Start Generate kernel definitions\n");

    // Hash map to store the kernel signature
    m_cu_kernels = std::map<std::string, std::shared_ptr<CodeUnitKernel>>();

    // Iterate the graph and generate the kernel signature
    for (auto node : graph->get_nodes()) {
        if (node == nullptr) {
            continue;
        }

        std::string op_type = node->get_op_type();
        if (m_cu_kernels.contains(op_type)) {
            continue;
        }

        std::shared_ptr<CodeUnitKernel> cu = std::make_shared<CodeUnitKernel>();
        cu->op_type = node->get_op_type();
        cu->func_name = "kernel_" + node->get_op_type();
        cu->input_signature =
            generate_signature(node->get_input_types(), "in_");
        cu->output_signature =
            generate_signature(node->get_output_types(), "out_");
        m_cu_kernels[op_type] = cu;

        CodeWriter w;
        w << "// Define kernel for node: " << node->get_op_type() << "\n";
        w << "__global__ void " << cu->func_name << "(";
        w << "DeviceContext *dc";
        if (cu->input_signature.size() > 0) {
            w << ", ";
        }
        w << cu->input_signature;
        if (cu->output_signature.size() > 0) {
            w << ", ";
        }
        w << cu->output_signature;
        w << ")";
        w.block_begin();
        w << "extern __shared__ uint64_t shared[];\n";
        w.block_end();
        w << "\n";
        w.write_to_file(filename, if_append);
    }
}

void CudaCodegen::generate_entry(std::shared_ptr<hifive::core::Graph>& graph,
                                 const std::string& filename,
                                 const bool if_append) {
    LOG_INFO("Start Generate entry kernel\n");
    CodeWriter w, w_body;
    w << "void entry_kernel(){\n";
    w.indent_inc();
    w_body.indent_inc();

    // Iterate the graph and generate the kernel signature
    const int n = graph->get_nodes().size();
    std::vector<bool> visited(n, false);
    std::vector<int> stack;

    stack.push_back(graph->get_init_node_id());

    w << "// Define each node's output edges\n\n";
    w_body << "\n// Call kernels\n";

    while (!stack.empty()) {
        int node_idx = stack.back();
        stack.pop_back();
        if (visited[node_idx]) {
            continue;
        }
        visited[node_idx] = true;
        auto node = graph->get_nodes()[node_idx];
        if (node == nullptr) {
            // Fused node is nullptr
            continue;
        }

        w << "// " << node->get_op_name() << "\n";
        w_body << "// Call " << node->get_op_type() << " for node "
               << node->get_op_name() << "\n";

        // define output edge
        int i = 0;
        for (auto edge : node->get_out_edges()) {
            auto src = edge->get_src();
            auto dst = edge->get_dst();
            std::string edge_name = "edge_" + src->get_op_name() + "_" +
                                    std::to_string(i) + "_" +
                                    dst->get_op_name();
            w << "uint64_t *" << edge_name << ";\n";
            i++;
        }

        // Update the stack
        for (auto edge : node->get_out_edges()) {
            stack.push_back(edge->get_dst()->get_id());
        }
    }
    w.indent_dec();
    w_body.indent_dec();
    w_body << "}\n\n";
    w.write_to_file(filename, if_append);
    w_body.write_to_file(filename, true);
}

void CudaCodegen::generate_include(
    std::shared_ptr<hifive::core::Graph>& /*graph*/,
    const std::string& filename, const bool if_append) {
    LOG_INFO("Start Generate include\n");
    CodeWriter w;
    w << "// This file is generated by HiFive\n";
    w << "#include <cuda.h>\n";
    w << "#include <cuda_runtime.h>\n";
    w << "#include <iostream>\n\n";
    w << "#include \"hifive/kernel/device_context.hpp\"\n\n";
    w.write_to_file(filename, if_append);
}

bool CudaCodegen::run_on_graph(std::shared_ptr<hifive::core::Graph>& graph) {
    LOG_INFO("Running CudaCodegen\n");

    std::string output_filename = "build/generated.cu";
    generate_include(graph, output_filename, /*append=*/false);
    generate_kernel_defs(graph, output_filename, /*append=*/true);
    generate_entry(graph, output_filename, /*append=*/true);

    CodeWriter w;
    w << "int main(int argc, char *argv[])";
    w.block_begin();
    w << "std::cout << \"Starting Benchmarking...\" << std::endl;\n";
    w << "DeviceContext dc;\n\n";

    w << "// Input arguments\n";
    std::shared_ptr<hifive::core::Node> init_node = graph->get_init_node();
    int i = 0;
    for (auto edge : init_node->get_out_edges()) {
        std::shared_ptr<hifive::core::Node> e = edge->get_dst();
        std::string name_h =
            "input" + std::to_string(i) + "_" + e->get_op_name() + "_h";
        std::string name_d =
            "input" + std::to_string(i) + "_" + e->get_op_name() + "_d";
        std::string name_size = "sizeof(uint64_t) * " +
                                std::to_string(edge->get_shape(0)) + " * " +
                                std::to_string(edge->get_shape(1));
        w << "// Edge: " << init_node->get_op_name() << " -> "
          << e->get_op_name() << "\n";
        w << "uint64_t *" << name_h << ";\n";
        w << "uint64_t *" << name_d << ";\n";
        w << "cudaMallocHost((void **)&" << name_h << ", " << name_size
          << ");\n";
        w << "cudaMalloc((void **)&" << name_d << ", " << name_size << ");\n";
        i++;
    }

    w << "\n// Output arguments\n";
    std::shared_ptr<hifive::core::Node> exit_node = graph->get_exit_node();
    i = 0;
    for (auto edge : exit_node->get_in_edges()) {
        std::shared_ptr<hifive::core::Node> e = edge->get_src();
        std::string name_h =
            "output" + std::to_string(i) + "_" + e->get_op_name() + "_h";
        std::string name_d =
            "output" + std::to_string(i) + "_" + e->get_op_name() + "_d";
        std::string name_size = "sizeof(uint64_t) * " +
                                std::to_string(edge->get_shape(0)) + " * " +
                                std::to_string(edge->get_shape(1));
        w << "// Edge: " << e->get_op_name() << " -> "
          << exit_node->get_op_name() << "\n";
        w << "uint64_t *" << name_h << ";\n";
        w << "uint64_t *" << name_d << ";\n";
        w << "cudaMallocHost((void **)&" << name_h << ", " << name_size
          << ");\n";
        w << "cudaMalloc((void **)&" << name_d << ", " << name_size << ");\n";
        i++;
    }

    w << "\n// Fill input arguments\n";

    w << "\n// Run the graph\n";

    w << "std::cout << \"Finished Benchmarking...\" << std::endl;\n";
    w.block_end();

    w.write_to_file(output_filename, true);
    return true;
}
} // namespace engine
} // namespace hifive